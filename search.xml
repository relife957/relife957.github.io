<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>我所讨厌的工作</title>
      <link href="/2023/06/24/wo-suo-tao-yan-de-gong-zuo/"/>
      <url>/2023/06/24/wo-suo-tao-yan-de-gong-zuo/</url>
      
        <content type="html"><![CDATA[<h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>最近关于工作有一些想法，简单的聊一下</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>我正式工作已经三年了，从事服务端研发工程师之职，前两年在做电商业务的开发，最近一年在基础架构部门做基础设施的开发。关于程序员的工作，我总是间歇性的毫无动力，我想不到我所做的工作的意义。我所从事的这份工作，也会时不时的成为我最讨厌的工作。<br>我所讨厌的并不是开发本身，而是没有意义的工作，什么是没有意义的工作呢，我的定义也很简单，就是没有产生价值的工作。这个在业务部门和基础架构部门略有不同，我分开说一下。</p><h3 id="业务部门"><a href="#业务部门" class="headerlink" title="业务部门"></a>业务部门</h3><p>我在业务部门做的时间较长，对相关的工作了解也更深一些。<br>如果你是一个追求技术的开发人员，在业务部门工作，会让你很心累。业务部门要求技术的地方较少，更多的是要求一些基础的开发经验。例如怎么避免慢查询，能不能识别出一些写法的坑点等等，这是最低的要求，但同时也是很多部门、小组的唯一要求。这就导致，如果你想推进一些技术优化点，那一方面你需要扛住日常业务需求的压力，另一方面，你要说服其他人，除非你的优化点是一次性，且不会影响到别人的开发，否则，很多东西无法推进，无法持续下去。<br>而如果你是一个对业务成就有追求的开发人员，那可能会更心累一点。目前的互联网工种很多，产品，运营，算法，开发等等，你作为一个开发人员，大多时候，很难对业务有什么话语权，你只能从系统搭建的角度提出一些需求存在的问题，而不能左右业务的走向。这导致两个问题，第一是业务的好坏和你关系不大，你也不能从业务的发展中获取什么。第二点是产品运营一些毫无意义的需求，大部分时候，你没有权利拒绝，只能接受，并且浪费一段时间。当然遇到可靠的产品运营体验会稍微好一点。</p><h3 id="基础平台"><a href="#基础平台" class="headerlink" title="基础平台"></a>基础平台</h3><p>基础平台最大的问题也有两点，分开说一下。<br>第一点就是日常的业务咨询，这也是很多公司对于基础架构部门的基础要求，所以你需要对业务的咨询予以最大的优先级支持。我所了解的，很多基础架构小组都做了业务自助查询的sop，但是效果甚微，很多人习惯于直接找人问，而不是去自己看文档，而且他会下意识地认为不是自己的问题，而是你系统的问题。这对你的工作产生较大的影响，很多时候，可能一天的时间都花费到了答疑的工作上。而答疑对你的绩效毫无帮助，你需要在其他方面做出贡献。<br>第二点就是上一步最后说的，在其他方面做出贡献。在基础架构，至少是我司，你不能脱离业务做任何事情，这也是对的。但面对的问题就是，并没有那么多事情给你做，你需要在一段时间内，给出一些可见的成果，并且推进业务使用，这给到开发的压力就很大。同时我认为，很多人做的事情毫无意义。 </p><h3 id="讨厌的和喜欢的"><a href="#讨厌的和喜欢的" class="headerlink" title="讨厌的和喜欢的"></a>讨厌的和喜欢的</h3><p>我工作了这些时间，没有遇到特别喜欢的工作，因为我总觉得很多事情都没有必要做，也不需要这么多人，并不是从老板的角度说出这些话，而是一个开发工程师的角度。人多带来的问题很多，首先是沟通效率，其次是无所事事的人会想方设法的搞事情，搞一些工作以外的事，让你心身俱疲。<br>我所喜欢的工作，是那种大家都有明确的，相同的前进的方向，不断地去创造新的内容。就像一些热门游戏，我们要每个版本推出一些新的内容，让玩家喜欢的内容，大家一起为了这个项目的发展做贡献，项目好了大家也可以一起受益，也可以为了一些玩家体验做出技术上的突破。而不是从上到下的由绩效推动的内容产出，产品绞尽脑汁的想一些毫无意义的需求，开发花费时间做一些注定没人用或者马上要下线的需求。如果只是为了工资，无可厚非，但是总有人想要追求一些价值和意义，这也是我的想法。  </p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写作的重要性</title>
      <link href="/2023/06/04/xie-zuo-de-chong-yao-xing/"/>
      <url>/2023/06/04/xie-zuo-de-chong-yao-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="写这篇文章的原因"><a href="#写这篇文章的原因" class="headerlink" title="写这篇文章的原因"></a>写这篇文章的原因</h2><p>中午的时候，看了一个视频，是两个人文社科的教授给学生们的建议，他们的核心都是建议写作，写作可以锻炼你的思维，让你在可以很好的表达自己的想法，可以让你走的更远更高。我对于写作一直也是这个看法，我很早就有一个观点，在脑袋里的不能算是你的观点，只有写下来才算。下面也会简单说一下我对与此时的看法。</p><h2 id="文章正文"><a href="#文章正文" class="headerlink" title="文章正文"></a>文章正文</h2><h3 id="写作为什么可以锻炼思维"><a href="#写作为什么可以锻炼思维" class="headerlink" title="写作为什么可以锻炼思维"></a>写作为什么可以锻炼思维</h3><p>写下这个标题的时候，我首先是回想了一下视频中两位教授的表达，可能是因为时间太短，两位教授并没有对 “写作为什么可以锻炼思维” 这件事做出过多的论述，不过还是可以总结出一两点。我记得其中一位教授说了自己的经历，他说，“我在写第一本书的时候，基本上每一句话都会写出近50中表达，然后仔细比对这些语句的好坏，然后选出一个最好的，最适合的，然后这样选出一个段落，一个章节”。从这位教授的经历中可以窥见一二。首先，你想表达自己的想法，有很多方式，如果只是我们在脑中想，最多可以在三四种想法中斟酌，而写作可以让你在数十种想法中对比，然后总结出一个最好的，最合适的。我对此深有体会，从我自己的经历说起吧。我自认是一个喜欢思考的人，经常在看到一些社会事件的时候，我都会有一些自己的看法，但是一般我都是自己在脑袋中想，如果有自己特别满意的观点的时候，我会想把它写下来，发到相关的论坛。但是当我准备写下来的时候，我会发现很多问题。有时候，我会突然觉得自己的想法很幼稚，有时候，我找不到一种合适的文字，词汇，句子来表达我的想法，还有些时候，当我写下来自己阅读时，我会觉得自己的文字没有力量，会产生“别人会认可我的想法吗”，“别人应该会很轻松的反驳我的论点吧”等等这些想法。这些在我的脑袋中是做不到的，只有当我写下来的时候，才会发现这些问题。<br>所以，写作为什么可以锻炼思维，我认为有亮点。第一，写作可以让你不断的去斟酌自己的想法。有时候你想的时候觉得自己的论点很完美，但是当你写下来的时候，就会发现其中的问题。第二，写作可以锻炼你的文字，表达。你的论点可以就一种，但是表达方式有很多种，用什么词，什么句子，需不需要用修辞手法等等。当你不断去斟酌自己的表达，你才能让自己的想法变得犀利，可以用你的论述说服别人。  </p><h3 id="如何坚持写作"><a href="#如何坚持写作" class="headerlink" title="如何坚持写作"></a>如何坚持写作</h3><p>其实关于这一点，我是没有什么资格的，因为我自己就没有坚持写作，但是我可以从反面总结一二。<br>第一点，自问为什么我没办法坚持下去，工作忙到没有精力或许是其中一个，这个暂时没办法解决，但是总是会有有时间精力的时候，那个时候我是怎么想的呢，更多的时候，是一种眼高手低，就好像我高中的时候，当时我很自信，很多题都是看一眼，觉得自己会做，就不写了，长此以往，等到了高考的时候，我才发现自己很多题想不到解法，很多公式也不会了。放到现在，更多时候我认为自己的想法很完美，我看着论坛其他人的讨论，会觉得自己的论点比他们高级，不屑去评论，这是一种很不好的想法，我已经在高中吃过一次亏了，这次一定会改掉。<br>第二点，我认为写作不应该拘于形式。怎么理解呢，还是拿高中举例，高中很多人都很讨厌写作为，为什么？我认为最重要的就是字数限制。很多作文题目，其实是很简单的道理，真的需要800字去论述吗，这一点我一直存疑。800字这个限制，要求很多人没办法去斟酌自己的表达，精简自己的表达，习惯性的去说车轱辘话，豆腐三碗，三碗豆腐，长此以往，言语表达也变成这样了，我们会发现很多人很喜欢重复说一句话，而且说的话又臭又长。当我们在日常写随笔的时候，就不需要去给自己这么多限制，能用100字表达清楚，当然不用去写200字，300字。<br>第三点，我认为写作不应该强制。这一点不是专门针对写作的，也可以延伸到生活的方方面面。举个例子，我强制自己每天至少写一篇文章，这样好吗？我认为是不好的，写作更应该顺应内心，能做到把自己的想法写下来，而不是只是在脑中想，我认为就够了。不能说没想法也要强行写，这就像没有尿意也一定要在厕所待着。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CURL 使用</title>
      <link href="/2022/07/26/curl-shi-yong/"/>
      <url>/2022/07/26/curl-shi-yong/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>最近在使用跳板机，对于curl需求比较大，系统记录一下使用笔记</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><code>curl -[选项] [URL]</code></p><h3 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h3><h4 id="v"><a href="#v" class="headerlink" title="-v"></a><strong>-v</strong></h4><p>-v == –verbose 可以追踪url的连接信息，包含域名解析过程，请求头信息，响应信息等<br><code>curl -v www.baidu.com</code>  </p><h4 id="i"><a href="#i" class="headerlink" title="-i"></a><strong>-i</strong></h4><p>-i == –include 返回响应的头信息，是-v的子集<br><code>curl -i www.baidu.com</code></p><h4 id="I"><a href="#I" class="headerlink" title="-I"></a><strong>-I</strong></h4><p>-I == –head 只显示响应的头信息<br><code>curl -I www.baidu.com</code></p><h4 id="u"><a href="#u" class="headerlink" title="-u"></a><strong>-u</strong></h4><p>可以传递用户名和密码，访问带用户校验的URL</p><h4 id="d"><a href="#d" class="headerlink" title="-d"></a><strong>-d</strong></h4><p>传递请求参数<br><code>curl -d &#39;user=xxx&amp;age=24&#39; http://10.22.130.2</code><br><code>curl -d &#39;{&quot;user&quot;:&quot;xxx&quot;, &quot;age&quot;:24}&#39; http://10.22.130.2</code></p><h4 id="X"><a href="#X" class="headerlink" title="-X"></a><strong>-X</strong></h4><p>指定请求方式， 包含GET PUT POST DELETE<br><code>curl -X POST &#39;{&quot;user&quot;:&quot;xxx&quot;}&#39; http://10.22.130.2</code></p><h4 id="x"><a href="#x" class="headerlink" title="-x"></a><strong>-x</strong></h4><p>添加代理</p><h4 id="H"><a href="#H" class="headerlink" title="-H"></a><strong>-H</strong></h4><p>传递header信息，注意每个kv都需要一个-H<br><code>curl -H &#39;k:v&#39; -H &#39;kk:vv&#39; http://10.22.130.2</code></p><h4 id="o"><a href="#o" class="headerlink" title="-o"></a><strong>-o</strong></h4><p>抓取页面到一个文件中<br><code>curl -o index.html www.baidu.com</code></p><h4 id="O"><a href="#O" class="headerlink" title="-O"></a><strong>-O</strong></h4><p>抓取（下载）具体的文件</p><h4 id="e"><a href="#e" class="headerlink" title="-e"></a><strong>-e</strong></h4><p>伪装来源地址<br><code>curl -e http://localhost www.baidu.com</code></p><h4 id="r"><a href="#r" class="headerlink" title="-r"></a><strong>-r</strong></h4><p>分段下载大文件<br><code>curl -r 0-100 www.baidu.com</code></p><h4 id="C"><a href="#C" class="headerlink" title="-C"></a><strong>-C</strong></h4><p>断点续传</p><h4 id="c"><a href="#c" class="headerlink" title="-c"></a><strong>-c</strong></h4><p>保存cookie信息</p><h4 id="F"><a href="#F" class="headerlink" title="-F"></a><strong>-F</strong></h4><p>传递表单信息<br><code>curl -F user=xxx -F age=25 http://10.22.180.2</code></p><h4 id="f"><a href="#f" class="headerlink" title="-f"></a><strong>-f</strong></h4><p>显示抓取错误</p><h3 id="其他选项"><a href="#其他选项" class="headerlink" title="其他选项"></a>其他选项</h3><pre><code>   -a/--append 上传文件时，附加到目标文件   -A/--user-agent &lt;string&gt;  设置用户代理发送给服务器   -b/--cookie &lt;name=string/file&gt; cookie字符串或文件读取位置　　-B/--use-ascii 使用ASCII /文本传输　　-c/--cookie-jar &lt;file&gt; 操作结束后把cookie写入到这个文件中　　-C/--continue-at &lt;offset&gt;  断点续转　　-d/--data &lt;data&gt;   HTTP POST方式传送数据　　--data-ascii &lt;data&gt;  以ascii的方式post数据　　--data-binary &lt;data&gt; 以二进制的方式post数据　　--negotiate     使用HTTP身份验证　　--digest        使用数字身份验证　　--disable-eprt  禁止使用EPRT或LPRT　　--disable-epsv  禁止使用EPSV　　-D/--dump-header &lt;file&gt; 把header信息写入到该文件中　　--egd-file &lt;file&gt; 为随机数据(SSL)设置EGD socket路径　　--tcp-nodelay   使用TCP_NODELAY选项　　-e/--referer 来源网址　　-E/--cert &lt;cert[:passwd]&gt; 客户端证书文件和密码 (SSL)　　--cert-type &lt;type&gt; 证书文件类型 (DER/PEM/ENG) (SSL)　　--key &lt;key&gt;     私钥文件名 (SSL)　　--key-type &lt;type&gt; 私钥文件类型 (DER/PEM/ENG) (SSL)　　--pass  &lt;pass&gt;  私钥密码 (SSL)　　--engine &lt;eng&gt;  加密引擎使用 (SSL). &quot;--engine list&quot; for list　　--cacert &lt;file&gt; CA证书 (SSL)　　--capath &lt;directory&gt; CA目录 (made using c_rehash) to verify peer against (SSL)　　--ciphers &lt;list&gt;  SSL密码　　--compressed    要求返回是压缩的形势 (using deflate or gzip)　　--connect-timeout &lt;seconds&gt; 设置最大请求时间　　--create-dirs   建立本地目录的目录层次结构　　--crlf          上传是把LF转变成CRLF　　-f/--fail          连接失败时不显示http错误　　--ftp-create-dirs 如果远程目录不存在，创建远程目录　　--ftp-method [multicwd/nocwd/singlecwd] 控制CWD的使用　　--ftp-pasv      使用 PASV/EPSV 代替端口　　--ftp-skip-pasv-ip 使用PASV的时候,忽略该IP地址　　--ftp-ssl       尝试用 SSL/TLS 来进行ftp数据传输　　--ftp-ssl-reqd  要求用 SSL/TLS 来进行ftp数据传输　　-F/--form &lt;name=content&gt; 模拟http表单提交数据　　-form-string &lt;name=string&gt; 模拟http表单提交数据　　-g/--globoff 禁用网址序列和范围使用{}和[]　　-G/--get 以get的方式来发送数据　　-h/--help 帮助　　-H/--header &lt;line&gt;自定义头信息传递给服务器　　--ignore-content-length  忽略的HTTP头信息的长度　　-i/--include 输出时包括protocol头信息　　-I/--head  只显示文档信息　　从文件中读取-j/--junk-session-cookies忽略会话Cookie　　- 界面&lt;interface&gt;指定网络接口/地址使用　　- krb4 &lt;级别&gt;启用与指定的安全级别krb4　　-j/--junk-session-cookies 读取文件进忽略session cookie　　--interface &lt;interface&gt; 使用指定网络接口/地址　　--krb4 &lt;level&gt;  使用指定安全级别的krb4　　-k/--insecure 允许不使用证书到SSL站点　　-K/--config  指定的配置文件读取　　-l/--list-only 列出ftp目录下的文件名称　　--limit-rate &lt;rate&gt; 设置传输速度　　--local-port&lt;NUM&gt; 强制使用本地端口号　　-m/--max-time &lt;seconds&gt; 设置最大传输时间　　--max-redirs &lt;num&gt; 设置最大读取的目录数　　--max-filesize &lt;bytes&gt; 设置最大下载的文件总量　　-M/--manual  显示全手动　　-n/--netrc 从netrc文件中读取用户名和密码　　--netrc-optional 使用 .netrc 或者 URL来覆盖-n　　--ntlm          使用 HTTP NTLM 身份验证　　-N/--no-buffer 禁用缓冲输出　　-o/--output 把输出写到该文件中　　-O/--remote-name 把输出写到该文件中，保留远程文件的文件名　　-p/--proxytunnel   使用HTTP代理　　--proxy-anyauth 选择任一代理身份验证方法　　--proxy-basic   在代理上使用基本身份验证　　--proxy-digest  在代理上使用数字身份验证　　--proxy-ntlm    在代理上使用ntlm身份验证　　-P/--ftp-port &lt;address&gt; 使用端口地址，而不是使用PASV　　-Q/--quote &lt;cmd&gt;文件传输前，发送命令到服务器　　-r/--range &lt;range&gt;检索来自HTTP/1.1或FTP服务器字节范围　　--range-file 读取（SSL）的随机文件　　-R/--remote-time   在本地生成文件时，保留远程文件时间　　--retry &lt;num&gt;   传输出现问题时，重试的次数　　--retry-delay &lt;seconds&gt;  传输出现问题时，设置重试间隔时间　　--retry-max-time &lt;seconds&gt; 传输出现问题时，设置最大重试时间　　-s/--silent静音模式。不输出任何东西　　-S/--show-error   显示错误　　--socks4 &lt;host[:port]&gt; 用socks4代理给定主机和端口　　--socks5 &lt;host[:port]&gt; 用socks5代理给定主机和端口　　--stderr &lt;file&gt;   -t/--telnet-option &lt;OPT=val&gt; Telnet选项设置　　--trace &lt;file&gt;  对指定文件进行debug　　--trace-ascii &lt;file&gt; Like --跟踪但没有hex输出　　--trace-time    跟踪/详细输出时，添加时间戳　　-T/--upload-file &lt;file&gt; 上传文件　　--url &lt;URL&gt;     Spet URL to work with　　-u/--user &lt;user[:password]&gt;设置服务器的用户和密码　　-U/--proxy-user &lt;user[:password]&gt;设置代理用户名和密码　　-v/--verbose　　-V/--version 显示版本信息　　-w/--write-out [format]什么输出完成后　　-x/--proxy &lt;host[:port]&gt;在给定的端口上使用HTTP代理　　-X/--request &lt;command&gt;指定什么命令　　-y/--speed-time 放弃限速所要的时间。默认为30　　-Y/--speed-limit 停止传输速度的限制，速度时间&#39;秒　　-z/--time-cond  传送时间设置　　-0/--http1.0  使用HTTP 1.0　　-1/--tlsv1  使用TLSv1（SSL）　　-2/--sslv2 使用SSLv2的（SSL）　　-3/--sslv3         使用的SSLv3（SSL）　　--3p-quote      like -Q for the source URL for 3rd party transfer　　--3p-url        使用url，进行第三方传送　　--3p-user       使用用户名和密码，进行第三方传送　　-4/--ipv4   使用IP4　　-6/--ipv6   使用IP6　　-#/--progress-bar 用进度条显示当前的传送状态　　-a/--append 上传文件时，附加到目标文件　　-A/--user-agent &lt;string&gt;  设置用户代理发送给服务器　　- anyauth   可以使用“任何”身份验证方法　　-b/--cookie &lt;name=string/file&gt; cookie字符串或文件读取位置　　- basic 使用HTTP基本验证　　-B/--use-ascii 使用ASCII /文本传输　　-c/--cookie-jar &lt;file&gt; 操作结束后把cookie写入到这个文件中　　-C/--continue-at &lt;offset&gt;  断点续转　　-d/--data &lt;data&gt;   HTTP POST方式传送数据　　--data-ascii &lt;data&gt;  以ascii的方式post数据　　--data-binary &lt;data&gt; 以二进制的方式post数据　　--negotiate     使用HTTP身份验证　　--digest        使用数字身份验证　　--disable-eprt  禁止使用EPRT或LPRT　　--disable-epsv  禁止使用EPSV　　-D/--dump-header &lt;file&gt; 把header信息写入到该文件中　　--egd-file &lt;file&gt; 为随机数据(SSL)设置EGD socket路径　　--tcp-nodelay   使用TCP_NODELAY选项　　-e/--referer 来源网址　　-E/--cert &lt;cert[:passwd]&gt; 客户端证书文件和密码 (SSL)　　--cert-type &lt;type&gt; 证书文件类型 (DER/PEM/ENG) (SSL)　　--key &lt;key&gt;     私钥文件名 (SSL)　　--key-type &lt;type&gt; 私钥文件类型 (DER/PEM/ENG) (SSL)　　--pass  &lt;pass&gt;  私钥密码 (SSL)　　--engine &lt;eng&gt;  加密引擎使用 (SSL). &quot;--engine list&quot; for list　　--cacert &lt;file&gt; CA证书 (SSL)　　--capath &lt;directory&gt; CA目录 (made using c_rehash) to verify peer against (SSL)　　--ciphers &lt;list&gt;  SSL密码　　--compressed    要求返回是压缩的形势 (using deflate or gzip)　　--connect-timeout &lt;seconds&gt; 设置最大请求时间　　--create-dirs   建立本地目录的目录层次结构　　--crlf          上传是把LF转变成CRLF　　-f/--fail          连接失败时不显示http错误　　--ftp-create-dirs 如果远程目录不存在，创建远程目录　　--ftp-method [multicwd/nocwd/singlecwd] 控制CWD的使用　　--ftp-pasv      使用 PASV/EPSV 代替端口　　--ftp-skip-pasv-ip 使用PASV的时候,忽略该IP地址　　--ftp-ssl       尝试用 SSL/TLS 来进行ftp数据传输　　--ftp-ssl-reqd  要求用 SSL/TLS 来进行ftp数据传输　　-F/--form &lt;name=content&gt; 模拟http表单提交数据　　-form-string &lt;name=string&gt; 模拟http表单提交数据　　-g/--globoff 禁用网址序列和范围使用{}和[]　　-G/--get 以get的方式来发送数据　　-h/--help 帮助　　-H/--header &lt;line&gt;自定义头信息传递给服务器　　--ignore-content-length  忽略的HTTP头信息的长度　　-i/--include 输出时包括protocol头信息　　-I/--head  只显示文档信息　　从文件中读取-j/--junk-session-cookies忽略会话Cookie　　- 界面&lt;interface&gt;指定网络接口/地址使用　　- krb4 &lt;级别&gt;启用与指定的安全级别krb4　　-j/--junk-session-cookies 读取文件进忽略session cookie　　--interface &lt;interface&gt; 使用指定网络接口/地址　　--krb4 &lt;level&gt;  使用指定安全级别的krb4　　-k/--insecure 允许不使用证书到SSL站点　　-K/--config  指定的配置文件读取　　-l/--list-only 列出ftp目录下的文件名称　　--limit-rate &lt;rate&gt; 设置传输速度　　--local-port&lt;NUM&gt; 强制使用本地端口号　　-m/--max-time &lt;seconds&gt; 设置最大传输时间　　--max-redirs &lt;num&gt; 设置最大读取的目录数　　--max-filesize &lt;bytes&gt; 设置最大下载的文件总量    -M/--manual  显示全手动　　-n/--netrc 从netrc文件中读取用户名和密码　　--netrc-optional 使用 .netrc 或者 URL来覆盖-n　　--ntlm          使用 HTTP NTLM 身份验证　　-N/--no-buffer 禁用缓冲输出　　-o/--output 把输出写到该文件中　　-O/--remote-name 把输出写到该文件中，保留远程文件的文件名　　-p/--proxytunnel   使用HTTP代理　　--proxy-anyauth 选择任一代理身份验证方法　　--proxy-basic   在代理上使用基本身份验证　　--proxy-digest  在代理上使用数字身份验证　　--proxy-ntlm    在代理上使用ntlm身份验证　　-P/--ftp-port &lt;address&gt; 使用端口地址，而不是使用PASV　　-Q/--quote &lt;cmd&gt;文件传输前，发送命令到服务器　　-r/--range &lt;range&gt;检索来自HTTP/1.1或FTP服务器字节范围　　--range-file 读取（SSL）的随机文件　　-R/--remote-time   在本地生成文件时，保留远程文件时间　　--retry &lt;num&gt;   传输出现问题时，重试的次数　　--retry-delay &lt;seconds&gt;  传输出现问题时，设置重试间隔时间　　--retry-max-time &lt;seconds&gt; 传输出现问题时，设置最大重试时间　　-s/--silent静音模式。不输出任何东西　　-S/--show-error   显示错误　　--socks4 &lt;host[:port]&gt; 用socks4代理给定主机和端口　　--socks5 &lt;host[:port]&gt; 用socks5代理给定主机和端口　　--stderr &lt;file&gt;　　-t/--telnet-option &lt;OPT=val&gt; Telnet选项设置　　--trace &lt;file&gt;  对指定文件进行debug　　--trace-ascii &lt;file&gt; Like --跟踪但没有hex输出　　--trace-time    跟踪/详细输出时，添加时间戳　　-T/--upload-file &lt;file&gt; 上传文件　　--url &lt;URL&gt;     Spet URL to work with　　-u/--user &lt;user[:password]&gt;设置服务器的用户和密码　　-U/--proxy-user &lt;user[:password]&gt;设置代理用户名和密码　　-v/--verbose　　-V/--version 显示版本信息　　-w/--write-out [format]什么输出完成后　　-x/--proxy &lt;host[:port]&gt;在给定的端口上使用HTTP代理　　-X/--request &lt;command&gt;指定什么命令　　-y/--speed-time 放弃限速所要的时间。默认为30　　-Y/--speed-limit 停止传输速度的限制，速度时间&#39;秒　　-z/--time-cond  传送时间设置　　-0/--http1.0  使用HTTP 1.0　　-1/--tlsv1  使用TLSv1（SSL）　　-2/--sslv2 使用SSLv2的（SSL）　　-3/--sslv3         使用的SSLv3（SSL）　　--3p-quote      like -Q for the source URL for 3rd party transfer　　--3p-url        使用url，进行第三方传送　　--3p-user       使用用户名和密码，进行第三方传送　　-4/--ipv4   使用IP4　　-6/--ipv6   使用IP6　　-#/--progress-bar 用进度条显示当前的传送状态</code></pre>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些碎片化思考</title>
      <link href="/2022/07/01/yi-xie-sui-pian-hua-si-kao/"/>
      <url>/2022/07/01/yi-xie-sui-pian-hua-si-kao/</url>
      
        <content type="html"><![CDATA[<h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><ul><li><p>建议<br>我认为提建议的最好的方法就是，告诉对方一些自己过去的经验，如果没有相关的经验，就简单说一下自己对这方面的理解，同时强调这是自己的理解，自己没有经历过。<br>为什么要这样，很多人，尤其是长辈，习惯为年轻人做决定，理由自然是诸如，“我吃的盐比你吃的饭还多”，“我这是为你好”之类的，长辈们总是很自信，这是人性的弱点，我认为这也属于好为人师的一种，他们自认已经走过了大半辈子，经历过人生大部分的事情。当然这也是事实，但是时代在变，每个人的性格，能力也不同，任何事都没有通解，需要结合自己的情况和自己对这件事的理解而做决定，这个时候确实需要长辈的经验，从他们的经历经验中总结出一些客观事实，不受自身和时代背景影响的东西，这些会对你做决定有所帮助。</p></li><li><p>朋友<br>人是需要朋友的。<br>年轻的时候，我认为人是不需要那么多朋友的，有一个两个真心的朋友就好了。<br>到最近，我的想法发生了变化，我有女朋友一起住，也有家人的关心，有稳定高薪的工作，友善的同事，但是我还是感到孤独，我想我是需要朋友了。<br>我可能需要朋友们一起吃吃饭，聊聊天，一起打打游戏。<br>我想了想这是一种什么情感，我想不太明白，就是感觉我需要。<br>我最近状态很差，陷入到了整体比较悲观的状态，这并不是单纯的缺少朋友导致的，但是我想有朋友在我会好一点。<br>人是需要朋友的。</p></li><li><p>说服<br>说服大众不需要深究一个道理，区辩证这个道理的对错，只需要证明这个道理和地位低的有关，那大众就会认为他是假的，反之亦然，如果想辩证一个道理是真的，只需要证明它和地位高的人相关即可。</p></li><li><p>情感怯懦<br>上面说到，我想要朋友，我很想和我的朋友们联系，但是我又不敢，我甚至不明确我不敢的原因，直观的感受是，我不知道打完招呼后说些什么，也不知道我眼中的好朋友是不是同样认为我是他们的好朋友，好到可以抽一些可怜的休息时间和他聊天。</p></li><li><p>基础设施开发<br>互联网公司做基础设施的开发人员，很多人拥有傲慢和自大，傲慢体现在对其他人方案的随意质疑，很多人甚至不愿意自己去看，去理解这样设计的原因，只要和自己的想法不同，就提出意见，并且固执己见，不愿意听取别人的解释，最后落下一句，随你吧。自大体现在，对于用户体验的自以为是，口口声声这样是为了用户体验，但是自己脱离业务多年，或者根本没有做过业务，认为自己的设计完美无缺，不愿意听取用户的声音，所谓脱离群众。</p></li><li><p>感情羁绊/成本<br>一对情侣在一起多年，两个人之前会存在一些帮助两个人在一起的东西，这些东西往浪漫了说，叫做感情羁绊，往现实了说，叫做感情成本。<br>不仅仅是说法的不同，也在于不同人的不同看法。例如羁绊是性格乐观一些且感性的人的看法，他认为这些东西联系了我们彼此，我们熟知对方的性格和习惯，我们同时也愿意去包容对方的缺点和不不好的习惯。而成本是就是性格悲观一些且理性的人的看法，他或许会认为这些东西是我们对彼此的妥协，他并没有真正的，打心底觉得对方的不好已经没什么了，而是压抑自己的不满，然后逐渐形成习惯，最后可能会改变自己的想法，之所以称之为感情成本，也是因为这是针对你当前另一半的，换另一个人就又要重新开始，而这个过程是痛苦且漫长的。</p></li><li><p>书籍和人生观<br>当我写完上面一段话的时候，我重新阅读了几遍，做了一些文字的修改，并且产生了一些其他的想法。<br>我的思考是源于我的生活，并且收到我性格和经历的影响。我上面写下的思考，如果有人看到的话，可能会嗤之以鼻，也可能有人会深以为然，这也取决于看的人的性格和经历。<br>接着我想到，如果这段话是我在书上看到的，会不会对我的人生观有一些影响，我的性格是悲观的，所以我会觉得后者是对的。<br>再想到我之前看过的书，其中不乏很多类似的语句，对我产生了什么影响吗，我有没有把一句话当作我的人生信条呢，我仔细回忆了下，没有印象深刻的。<br>联想到其他人，总会听到很多人说自己的人生信条是什么什么，用别人的一句话，当作自己的人生信条是好的吗，这是个值得思考和讨论的事情，我总是认为，这世上没有适用于所有人的道理，甚至没有完全适用于一个人一生的道理，任何道理应该是对一个人的人生的一段时间适用。<br>我大抵上是不会用别的的一句话当作自己的人生信条，最多结合这句话和自己的经历经验做一些”本土化“，这或许也是一个好一些，对自己更负责的事情吧。</p></li><li><p>虚荣<br>今天突然意识到，我自己有点可悲，我很少有真正喜欢的事情，从小到大，做的很多事情都是为了虚荣，可以脱颖而出，与众不同。<br>小时候，总是喜欢报各种竞赛，结果最后一个奖都没拿到，因为我没有认真的去学过，报名竞赛一般会有专门的培训，有些时候是在假期，有些时候是在自习课的时候，这个时候大家都在玩或者上自习，你拿着书，在众目睽睽之下走了出去，我似乎一直很享受这种感觉。<br>长大一点，一会儿去做这个，一会儿去弄那个，好像都是因为可以让别人知道的时候，感叹一句，原来你会这个呀，日语是，围棋是，很多都是。<br>在我心中，这样是可悲的，也不应该活成这个样子。爱慕虚荣的原因还是自卑，不重视自身的价值，而只关注别人的目光和评价。<br>我应该做出一些改变了。</p></li><li><p>天赋<br>刚才看到一句话，能够不纠结为什么去做一件事的能力，就是你的天赋。<br>不能说这句话就是天赋这个词的定义，我觉得是对这个天赋这个词的一个方面的解读。或者说是对将这样一种能力归于个人的天赋。<br>在上学的时候，学习的好坏很大程度上取决于你对学习是否热爱，其中很多学习不好的同学有一个共同的特性，就是看不进去书，这一类人也总是自说或者被说成不是学习的料，因为他们确实是完全不热爱，甚至都不会去纠结一下为什么要去学习，就像他不会去纠结为什么要去玩一样。也有相反的人，他们就是喜欢看书学习，不需要理由，这样的人也许就是那些所谓的天才。当然还有绝大多数人，就是普通人，没有这种天赋，或是为了父母的期盼，或是为了改变命运等等。<br>这样的能力也可以映射为你在某一方面的天赋，学习只是其中一方面。  </p></li><li><p>电锯人<br>最近看完了电锯人，本来以为是一部经典的jump热血漫，看下来却是令我蛮惊喜的。<br>其中比较新奇的设定是所谓的恶魔，就是人们心中对某一个事物的恐惧所化成的，所以前期一直宣扬的最强，最可怕的恶魔就是枪之恶魔，我认为作者是想表达世界上的部分国家的枪支管理以及枪支犯罪事件带给世界的恐惧以及对人们的伤害。<br>后期比较强的是支配恶魔，其中支配恶魔本身想让电锯人杀掉他，这样世界就会失去支配，但是各国政府不同意，对于政府来说，他们最不能失去的不是枪支，二是对人们的支配。<br>整体的立意是蛮新的，作者是个蛮有想法的人，感觉也是一个热爱和平正义的人。、</p></li><li><p>三体<br>最近三体电视剧播出了，重新看了一些三体的相关讨论，对一些讨论的看法记录一下</p><ul><li>人类不感谢罗辑<br>这个点我之前没有多想，最近看到了，也有了一些看法。小说中，罗辑将执剑人的权柄交给程心之后，被带走了，罪名是涉嫌毁灭人类之类的，为什么人类会对一个救世主般的人这样呢，网上关于这部分的讨论很多，结论都是指向罗辑将自己、三体世界以及人类三者绑到了一起，虽然威胁了三体，但是人类也受到了威胁，是死的威胁。<br>我对这块暂时也没有新的想法，只是觉得大刘的细节很多，真的没有放弃任何一个可以输出观点的地方，按照一般的剧情，罗辑会被当成救世主一样供奉起来，这个剧情放在小说里很正常，但是在现实就很不正常了。科幻小说却不乏现实主义。</li></ul></li><li><p>壳子<br>我想说的是每个人身上的壳子，或者说是人设，几乎所有人都会在真实的自己外套上很多层壳子。<br>真实的自己并不美好，我觉得应该没有多少人的真实体会让人喜欢，例如情侣夫妻生活久了，逐渐褪去壳子，用真实的自己在家里生活，你觉得女朋友会喜欢懒惰的你，不爱说情话的你，不爱准备浪漫的你吗。<br>我们的壳子越来越多，能用真实面对的人也越来越少，小时候有父母，但是长大后，却连家里人也无法真实面对了。</p></li><li><p>论迹不论心<br>书中的意思是，为善孝，论心不论迹，为恶，论迹不论心。道理也很简单，孝顺善良是要从心出发的，不能说有钱的人为父母做的多，就比穷人什么都不做孝顺，而是要看心中的孝顺；关于作恶，要看这个人做了什么，再去判他的罪，而不是他心里是怎么想的。<br>这是古人的话，私以为放到今天的社会已经不通用了。首先是关于孝顺，父母怎么感受的到你的孝顺，这个很那说，大部分还是要看迹，到最后，可能是论迹又论心。然后是关于善事，有个很明显的例子，一个人做慈善，他确实是捐了很多钱，帮到了很多人，但是他内心根本没有对这些需要帮助的人有任何同情，他只是为了名气，或者为了企业名声，或者是借助这个事情获取其他东西，我们能说这个事情是不好的吗，还是论迹不论心。最后关于做恶事，这个就是现代法律，没什么变化。</p></li><li><p>认知的不同程度<br>最近在看一些计算机领域的文章的时候，产生了一些关于认知的思考。<br>与我而言，我比较喜欢可以读懂，理解的比较顺畅的文章。管中窥豹，作者的水平也可见一斑。这让我想到自己，上大学的时候，收到学长的影响，喜欢写一些技术博客，一开始只敢写一些自己很了解的事情，写作的过程也比较缓慢，很多语句都需要斟酌。随着心中的那股气慢慢泻掉，同时也被一些网站的数据蒙住双眼后，写作就开始滥竽充数，开始写一些自己一知半解的东西，内容也是东拼西凑的东西，这个博客中有一些就是这种类型的文章。<br>我认为，能写出一篇让入门者和资深人员都有所收获的文章是相当难的，一定是对相关领域有所建树，至少也是掌握了全貌，有自己的理解在其中的。如果遇到读不懂的文章，也不用怀疑自己的能力，很有可能是作者就是一知半解。</p></li><li><p>沉浸后的空虚<br>已经很久没有这种感觉了，我总是在沉浸一个故事，从故事回到现实后，感到无尽的空虚感。这种空虚感的来源，我想一部分来自于对故事的不舍，我似乎真的是故事中的一员，身临其境的参与了整个故事。另一部分是故事与现实的割裂，故事是那么美好，现实又是如此的无趣。可能还有很多说不上来的原因，我现在还无法总结出来。<br>我想，作为一个创作者，能创作出一个故事，让别人产生这种脱离后的空虚感，都是作为创作者最大的成就，这似乎也能成为我的追求，我的心之所愿。  </p></li><li><p>互联网与评论<br>有意无意之间，我变得不再在互联网上做任何评论，甚至不观看别人的评论，当然，也可以称为别人的争吵。<br>并不是我自恃清高，也不是我不喜欢做评论，相反，我是一个喜欢思考和评论的人，只是如今的互联网，很难找出一个可以和平发表观点的地方。<br>我记得自己在上学期间是一个积极参与互联网各种论坛讨论的人，我第一次下载百度贴吧的时候，我还是个高中生，我惊奇的发现，在这个地方可以看到太多东西了，几乎你能想到的事物，在这里都有讨论，我还非常欣喜的与姐姐分享，她也附和了我。我并没有玩太久，因为太费时间，就卸载了。后来是上大学后，我当时喜欢玩英雄联盟，下载了微博，主要关注一些电竞比赛的新闻和讨论，第一次感受到论坛的另一面也是在微博，印象中，我和另一个人因为对一个事物的看法在一个帖子下面争吵了很久，一开始称得上讨论，然后在产生一些冲突点后，开始了帖子内容外的争吵，最后也是升级成了谩骂。<br>那件事后，我想了很多，我自己甚至有一段时间不愿想起，也不敢查看那段讨论，我不喜欢那样的自己，我认为我的家人，同学，朋友也不会喜欢那样的我，我当时因为这个原因，卸载了微博，并且到现在也没有下载回来。<br>时至今日，互联网的环境江河日下，目前已经发展到有相关法律介入的情景。整个互联网环境充斥着毫无逻辑，毫无意义的争吵，谩骂。大家也给各个论坛评定了很多名号，其含义是相关的舆论力量的汇集。例如大家把微博称为女权的汇集地，而虎扑是一些较为极端的男性主义的汇集地。无论讨论的对象本身是正是邪，讨论的内容都会变成阴阳怪气，反串等非恶意的评论，网络暴力就更是大行其道。<br>这些是环境，于我个人而言，我不屑于参与这些讨论，很多时候都是直接关闭相关的入口，这么做当然有一部分虚荣心，一种出淤泥而不染的虚荣心。但更多的，是不想自己变成自己看不上的人，也不想浪费时间和精力。<br>最后想说下环境的力量。现在回想当时在微博的讨论，一开始也是想单纯做观点的讨论，但是从某一条回复开始，讨论的性质就变了，它变成了一种较量，而相应的方式也就变成了不择手段，回复的内容变成了和讨论本身无关的东西，成为了互相攻击，咒骂，仿佛你输了就会被整个互联网的人看不起，所有人都在看你的笑话。环境的力量应该不止如此，这也必定是劣币驱逐良币的过程，环境在无监管或者监管较松的情况下，便会朝着坏的方向发展。并且我认为这个发展的方向并不可逆，唯有破后而立，重新建立一个强监管的环境方可解决。</p></li><li><p>自我怀疑<br>最近在准备面试，投简历的时候，发现无处可投，投出去的简历也是石沉大海，毫无音讯。不由得，我陷入了一段时间的自我怀疑。<br>首先我开始怀疑自己的能力，我自认为是一个还不错的程序员。投递的那些岗位，都是我觉得足以胜任的，但是不知道为什么，确实是没有回应。<br>然后我开始怀疑自己当初的选择。去年这个时候，我转到基础平台部门，开始做基础架构相关的工作，业务部门和基础架构部门确实是有一些不同，我当时的想法是，我做业务的能力已经足够了，我想精进自己的技术。当投简历碰壁后，我开始怀疑自己当初的选择，是不是自己搞花了自己的简历，可能从简历评估的人角度看，我是哪个方面都没有做好，什么都是半桶水，所以拒绝了我的简历。<br>最后就是无意义的胡思乱想了，我也不知道自己在想什么，总之被负面情绪包裹，整个人也没什么精神。<br>现在我想总结下这件事。第一，我的自我怀疑是自寻烦恼还是自我反思，我觉得前者多一些。最近国内的互联网都是死气沉沉，又恰逢阿里大裁员，整个招聘市场确实有一些乱，我也没有找内推，只是自己从官网投递，被选中的概率确实很小。 第二，我的能力强还是差，这一点我自己也时常反复，我觉得讨论这个没有太大的意义，评定一个人能力强弱，也不能脱离环境，场景，自说自话不会有结果的。第三，我下一步该怎么做，今天看了一些相关的问题的回答，我陷入自我怀疑的困境，主要是因为自己很长时间都只是工作，没有什么成长，进步。闲暇时间，都是在做一些消遣的事情，有时候第二天都不记得前一天做了什么，整个人浑浑噩噩的就过了这么长的时间。我还是需要找到自己热爱的事情，我必须从热爱的事情中寻找存在的意义，即使暂时不能做到，也要每天做一些小的事情，也不说成长还是进步，就是能让自己第二天可以记得住前一天干了什么，就这样。  </p></li><li><p>说不出口的话<br>突然想到一点，很多你的想法，对于问题的看法，因为各种原因无法说出口，过一段时间后，你对这个问题就失去了看法。  </p></li><li><p>性格决定命运<br>性格决定命运，随着年纪的增长，对这句话的理解就会越深。<br>我认为性格决定你命运的原因有以下几点：  </p><ul><li>很多机会是其他人带给你的，一个坏的性格会让你损失掉这些机会，没有人会喜欢一个性格恶劣的人，除非你有超越所有人的能力。  </li><li>你的性格会让你面对很多机会时，做出一个错误的选择。</li></ul><p>主要是以上两点，性格真的很难改变，除非是发生了什么巨变。<br>我25岁的时候，意识到了这个问题，希望不晚，我要尽力去改变这一点。  </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 碎片化思考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 碎片化思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mac 随笔</title>
      <link href="/2022/04/21/mac-sui-bi/"/>
      <url>/2022/04/21/mac-sui-bi/</url>
      
        <content type="html"><![CDATA[<h2 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h2><h3 id="node"><a href="#node" class="headerlink" title="node"></a>node</h3><ul><li>更新npm<br><code>sudo npm install -g npm</code></li><li>更新node<br><code>sudo npm install -g n &amp;&amp; sudo n stable</code></li></ul><h3 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h3><ul><li>关闭所有nginx服务<br><code>kill -9 $(ps aux | grep &#39;nginx&#39; | grep -v grep | tr -s &#39; &#39;| cut -d &#39; &#39; -f 2)</code></li></ul><h3 id="git"><a href="#git" class="headerlink" title="git"></a>git</h3><ul><li><p>git tag<br><code>git tag -a v1.0.0 -m &quot;v1.0.0&quot;</code><br><code>git push origin v1.0.0</code></p></li><li><p>修改commit<br>修改历史的commit，找到这个commit前一个commit的hash值，使用<code>git rebase -i ${commit_hash}</code>,然后在修改界面将要修改的commit前<code>pick</code> 改为<code>reword</code>，接着wq，然后逐个修改commit message即可。</p></li><li><p>合并commit<br>合并一个分支的多个commit，使用<code>git rebase -i ${branch}</code>,branch为你要合并的分支，然后将对应commit前的<code>pick</code>改为 <code>squash</code>，squash为合并当前commit到上一个commit。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8s学习笔记</title>
      <link href="/2022/04/05/k8s-xue-xi-bi-ji/"/>
      <url>/2022/04/05/k8s-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>最近开始学习k8s，在这里记录一下学习过程</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="k8s架构图"><a href="#k8s架构图" class="headerlink" title="k8s架构图"></a>k8s架构图</h3><p><img src="1.png" alt="k8s架构图"></p><ul><li>apiserver : 所有服务访问的统一入口</li><li>replication controller： 维持副本期望数量</li><li>scheduler ： 负责介绍任务，选择合适的节点执行任务</li><li>etcd ： 键值对存储</li><li>kubelet： 与容器引擎（docker）交互，实现容器的生命周期管理</li><li>kubeproxy： 负责写入规则至ipvs，iptables实现服务映射访问</li></ul><h3 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h3><ul><li>coreDns ： 为集群中的一个svc创建一个域名ip的对应关系解析</li><li>dashboard ： k8s管理访问</li><li>ingress contoller ： 实现7层代理</li><li>fedetation : 提供跨集群的多k8s的统一管理</li><li>prometheus : 监控能力</li><li>elk ： 日志统一分析介入平台</li></ul><h3 id="pod"><a href="#pod" class="headerlink" title="pod"></a>pod</h3><ul><li>自主式pod</li><li>控制器管理pod</li></ul><p>pod的创建，更新通过rc或者rs来实现，一个rs下面有预期的pod数量，当滚动更新时，重新创建一个rs，然后启动一个新版本的pod，关闭一个旧版本的pod。<br>hpa用于动态的创建pod维持系统可用性，根据系统负载新增或减少pod数量至指定值</p><h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>etcd在k8s中的最大作用就是使其高可用，强一致性的键值性存储以及监听机制<br>在apiserver接收到请求经过一系列的处理后，最终如果是集群所需要存储的信息，就会存储至etcd中。一般存储的是集群的状态信息和元信息。</p><ul><li>使用代码 ： <code>staging/src/k8s.io/apiserver/pkg/server/options/etcd.go</code></li><li>查看etcd命令<code>kubectl -n kube-system get pods | grep etcd</code>  </li><li>进入etcd容器<code>kuvectl -n kube-system exec -it etcd-minikube sh</code>  </li></ul><h3 id="controller-manager"><a href="#controller-manager" class="headerlink" title="controller manager"></a>controller manager</h3><blockquote><p>controller manager 分为kube-controller-manager 和 cloud-controller-manager,其中cloud-controller-manager是为各家云厂商提供一种抽象规范，便于让各家使用各自的provider  </p></blockquote><p>kube-controller-manager是嵌入k8s核心控制循环的守护进程，嵌入的意思是内置了相关逻辑，可以独立部署</p><ul><li>工作原理： <code>cmd/kube-controller-manager/app/controllermanager.go</code> &amp;&amp; <code>cmd/kube-controller-manager/app/core.go</code></li><li>查看详情命令： <code>kubectl -n kube-system describe -l component=kube-controller-manager</code></li><li>作用 ： 根据apiserver提供的数据持续监控集群，并且将集群调整为预期状态<ul><li>当我们创建一个deloyment，设置副本数为1，当我们把pod删除之后，控制器会创建一个pod</li></ul></li><li>查看日志命令： <code>kubectl -n kube-system logs -l component=kube-controller-manager --tail=5</code></li></ul><h3 id="schedule"><a href="#schedule" class="headerlink" title="schedule"></a>schedule</h3><blockquote><p>kube-schedule是一个策略丰富，拓扑感知的调度程序，会显著提升可用性，性能和容量<br>作用是将预期的pod资源调度到指定的node上，进而完成启动，通过定时请求apiserver获取信息，然后进行处理  </p></blockquote><ul><li>工作原理： <code>pkg/scheduler/core/generic_scheduler.go</code></li><li>处理阶段：主要分为三个阶段，computing predicate， prioritizing，selecting host<ul><li>computing predicate主要解决的问题是pod是否能调度到集群的node上，主要通过一个<code>podOnFirstNode</code>的函数，处理时会检查缓存和pod是否是可调度的，以防有pod affinity（亲和性）的出现</li><li>prioritizing主要解决的问题是，在上一个阶段的处理结果filteredNodeList中判断优先级，得出一个按优先级排序的队列，优先级的判断是根据各种计算出的分数之和</li><li>selecting host则是最终选择调度到那台机器上</li></ul></li></ul><h3 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h3><blockquote><p>按照一般架构设计的原则，kubelet应该属于agent，负责node和pod的管理任务</p></blockquote><ul><li>节点管理 ： 通常agent的作用就是让节点能注册，让集群知道他的存在，这就是节点管理，kubelet会上报自己的元信息以及对应机器的信息</li><li>pod管理 ： kubelet保证了pod在node按照预期启动并且保持工作，主要做了两件事，健康检查和资源监控</li><li>工作原理 ： <code>cmd/kubelet/app/server.go</code></li></ul><h3 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h3><blockquote><p>kube-proxy是每个node上的网络代理组件，支持tcp和udp的连接和转发</p><ul><li>工作方式： 分为三种，userspace（早期，效率不足，不推荐使用），iptables（默认，效率比userspace高，但会生成很多iptables规则，ipvs为了解决iptables的性能问题，采用增量的形式更新</li></ul></blockquote><h3 id="container-runtime（docker）"><a href="#container-runtime（docker）" class="headerlink" title="container runtime（docker）"></a>container runtime（docker）</h3><blockquote><p>容器运行时，由于容器化技术的发展，为了统一工业标准，避免k8s与特定的容器化绑定，成立了oci，致力于将容器运行时和容器镜像化标准化</p></blockquote><ul><li>docker最初是一个容器管理平台，用于快速创建，发布，运行容器，后来添加了很多功能，成为标准的容器运行时的工具集</li><li>cri： 自k8s1.5开始，新增了一个容器运行时的插件api，成为cri，同步cri可以支持kubelet使用不同的容器运行时，而不需要编译， cri主要是基于grpc实现了RuntimeService和ImageService，接口定义为<code>pkg/kubelet/apis/cri/runtime/v1alpha2/api.proto</code>，</li><li>基本命令<ul><li>部署一个服务，<code>kubectl run redis --image=redis</code></li><li>查看详情， <code>kubectl describe pod名</code><ul><li>调度 ： <code>Normal  Scheduled  7m    ...</code> 查看pod调度到哪一个node上</li><li>pull镜像 ： <pre><code>Normal  Pulling    7m    kubelet, node01    pulling image &quot;redis&quot;  Normal  Pulled     7m    kubelet, node01    Successfully pulled image &quot;redis&quot;</code></pre></li><li>创建并启动 ： <pre><code>Normal  Created    7m    kubelet, node01    Created containerNormal  Started    7m    kubelet, node01    Started container</code></pre>创建后登陆到对应node即可通过docker查看容器详情</li></ul></li><li></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> k8s </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>慢查询总结</title>
      <link href="/2022/03/16/man-cha-xun-zong-jie/"/>
      <url>/2022/03/16/man-cha-xun-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>总结一下出现慢查询的原因，参考《高性能Mysql》</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>慢查询的具体原因很多，但是最基本的原因就是查询访问的数据太多，其中包括检索了过多的列和过多的行，或者mysql服务器层分析了大量不需要的数据</p><h4 id="请求了不需要的数据"><a href="#请求了不需要的数据" class="headerlink" title="请求了不需要的数据"></a>请求了不需要的数据</h4><ol><li>查询了不需要的记录<br> 这里书中举例的场景是搜索大量数据，然后取出前面的N行，而不是从sql中直接limit，这个问题一般不会犯。</li><li>多表关联时返回全部列 &amp;&amp; 总是取出全部列<br> 这两个场景类似，也就是说不要<code>select *</code> ，取出自己需要的列就可以了。</li><li>查询重复的数据<br> 一般是说业务中没有加缓存，重复执行相同的语句，返回相同的数据，这一点不是再说慢查询，是从数据库性能出发的。</li></ol><h4 id="Mysql是否扫描了额外的记录"><a href="#Mysql是否扫描了额外的记录" class="headerlink" title="Mysql是否扫描了额外的记录"></a>Mysql是否扫描了额外的记录</h4><p>这部分有三个指标</p><ul><li>响应时间</li><li>扫描的行数</li><li>返回的行数<br>其中响应时间是指mysql执行sql的时间和等待资源（io和行锁）的时间。<br>理想情况下，扫描的行数应该和返回的行数相同，但是一般很难做到。这部分的解决方案就是加合适的索引。<br>对于一般的where条件，我们从执行计划可以看到，最好的是在索引中直接使用where条件过滤，其次是使用覆盖索引，不需要回表查询数据（using index)，直接返回命中结果，最后就是从数据表中返回数据，然后过滤不满足条件的记录。</li></ul><h5 id="这里额外说一下Mysql的服务器层和引擎层"><a href="#这里额外说一下Mysql的服务器层和引擎层" class="headerlink" title="这里额外说一下Mysql的服务器层和引擎层"></a>这里额外说一下Mysql的服务器层和引擎层</h5><p>首先是服务层，服务层是向上对外提供查询能力，向下调用引擎读写数据。首先是连接器，接收客户端请求，建立连接，然后是查询缓存，是语句和结果的kv缓存，如果命中直接返回，接着是分析器，会对语句进行词法分析和语法分析，例如查询不存在的列就是这个阶段报错，接着是优化器，决定使用哪个引擎，或者join表的顺序，接下来就是执行器，根据语句调用引擎读写。<br>引擎层就是具体的innoDb这样的提供读写接口的引擎。</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ol><li>拆分复杂查询为多个简单查询，</li><li>切分查询，一次性执行一个大的sql（删除大量数据），会锁住很多数据，耗尽系统资源，阻塞小sql，所以可以拆分，多次执行。</li><li>分解关联查询，在工程中，一般都不会使用join，都是在应用层代码中完成聚合逻辑，一个是使得缓存的命中变高，因为聚合多表查询条件，查询组合就会变得很多，缓存命中率就会下降，同时在应用层更容易扩展且容易复用，对于引擎层，多个小的查询也可以降低锁粒度</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统（一）</title>
      <link href="/2022/03/10/fen-bu-shi-xi-tong-yi/"/>
      <url>/2022/03/10/fen-bu-shi-xi-tong-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>我还是想简单记录一下raft算法，很多分布式系统都用到了，至于paxos就算了，没理解</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="raft算法"><a href="#raft算法" class="headerlink" title="raft算法"></a>raft算法</h3><p>raft算法在我的理解中，主要用于管理分布式中多副本的情况，即系统有多个节点，其中有一个节点进行读写，其他节点只进行读或者只负责同步，当主节点下线后，需要选举出一个新的节点，当然这是具体的用处了，raft的定义中，将它的功能分为多个子问题，leader选举，日志同步，安全性，日志压缩，成员变更。</p><h3 id="成员"><a href="#成员" class="headerlink" title="成员"></a>成员</h3><p>raft中的角色分为3种， leader， follower， candidate</p><ul><li>leader负责接收客户端请求，并向follower同步请求日志，当日志同步到大多数节点后告诉follower提交日志</li><li>follower接收并持久化同步的日志，在leader告知后提交后，提交日志</li><li>candidate，选举过程中的历史角色<h3 id="状态转换"><a href="#状态转换" class="headerlink" title="状态转换"></a>状态转换</h3>当follower超时没有收到leader的消息，它会变成candidate开始leader选举，收到大多数服务器投票的成为新的leader。<br>raft算法有任期（term）的概念，多个任期之间是leader选举，如果选举失败会跳过这个任期<h3 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h3>raft通过心跳出发leader选举，当服务器启动时，初始时follower，leader定期向follower发送心跳，如果follower超时没有收到心跳，就会等待随机时间发器一次选举。<br>首先将自己的任期+1，然后转换为candidate，首先给自己投一票，并且给其他节点发送“拉票”请求，其他节点收到请求会，会有3个原则</li></ul><ol><li>每个任期每个节点只有一票</li><li>候选人知道的信息不能比自己少（日志提交记录）</li><li>先到先得，只能给先来的那个<br>当candidate发送请求后，会得到3种结果，</li><li>得票超过一半（majority），赢得选举，成为leader，向其他节点发送心跳说明</li><li>被告知别人当选，自己切换到follower</li><li>没有收到足够的票，重新发出选举，任期+1<br>如果发生平票，则会等待然后重新进入选举，降低了系统可用性，所以每个节点发出选举请求时会等待随机时间，然后节点数量时奇数，尽量减少平票。</li></ol><h3 id="日志同步"><a href="#日志同步" class="headerlink" title="日志同步"></a>日志同步</h3><p>当有leader后，就开始接收客户端请求，leader把请求作为日志驾到日志中，然后向其他服务器发送AppendEntries复制日志条目，当大多数服务器复制成功后，leader提交该日志并向客户端返回。<br>对于没有复制成功的服务器，leader会不断重试。</p><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><p>raft新增两条限制保证安全性</p><ol><li>拥有最新提交的节点才有资格成为leader，发送拉票请求时，会带上自己的提交index和任期，目标机器会先比较任期，然后比较index，然后投票</li><li>leader只会推进当前任期已经复制到大多数的服务器的日志</li></ol><p>###<br>todo…</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统（二）</title>
      <link href="/2022/03/10/fen-bu-shi-xi-tong-er/"/>
      <url>/2022/03/10/fen-bu-shi-xi-tong-er/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>总结一下各种分布式系统对于分布式理论的应用</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="正前"><a href="#正前" class="headerlink" title="正前"></a>正前</h3><p>从一些几个方面来介绍</p><ol><li>主从同步</li><li>分片</li><li>协调中心</li></ol><h3 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h3><p>主从同步的作用主要是保证高可用，将一份数据复制多份到多个节点，分为主节点、从节点或者leader和follower，其中的的问题主要是主从同步延迟导致的数据不一致问题。<br>其中主从同步和分片一般来说都是结合的，有些中间件是将二者合并的，有些是分离的</p><ul><li>redis<ul><li>redis是读写分离的，主节点接收读写请求，从节点只接收读请求</li><li>数据同步有全量同步和增量同步，（2.8版本之前只有全量同步），全量同步时发送RDB文件进行同步，增量同步是在全量同步的基础上，将新的命令发送过来。</li><li>2.8版本后有无磁盘复制模式，使用这种模式，可以通过子进程将直接将RDB文件发送到从服务器。</li><li>如果有多个从服务器，全部由主服务器来同步，会造成fork的子进程太多，主服务器的响应应用程序会比较受影响，所以有主-从-从的配置，由已经同步的从服务器来进行分配。</li><li>读写分离的问题<ul><li>延迟与不一致 ： 前置： 优化网络，同机房，监控延迟量，通知应用不再从该节点读取数据</li><li>数据过期问题 ： 主节点会进行惰性删除+定时删除， 从节点不会主动删除，而是主节点来控制，所以可能会出现读取过期数据的问题，升级到3.2后，从节点接收读请求时会判断是否过期。</li><li>故障切换 ： 没有哨兵的情况下，需要及时修改应用程序来切换</li></ul></li><li>redis-cluster的分片会有不同，但是逻辑上上类似</li><li>一般来说redis主从同步配合redis-sentinel使用，redis-cluster是二者功能的结合并升级</li></ul></li><li>kafka<ul><li>kafka对应的概念是副本，即每个topic的多个分片都会有多个副本（副本数可配置）来保证数据可靠性</li><li>kafka的副本集为replica，其中有一个leader，来进行读写请求的处理，当leader挂掉之后，由集群controller从ISR中选举出一个新的leader（也可以设置允许从不同步的副本里选举，为脏选举），leader写入消息后，由其他副本进行拉取同步</li><li>ISR（in-sync replica）即同步中的副本，isr的判断是根据一个参数，即和leader的时间差距，在这个范围内的都认为是同步中的。所以isr是一个动态的集合</li><li>因为kafka只对已提交的消息进行有限度的持久化保证，所以需要保证这个已提交，在生产端可以通过重试和acks这个参数来控制，这个参数的意思是，leader写入后，多少个副本都提交后才认为写成功</li><li>其中高水位是对于消费者来说，被允许读到的对大消息偏移，同时高水位也是以提交消息和未提交消息的界限</li></ul></li><li>zookeeper<ul><li>zk的的主从，是节点级别的，集群节点分为leader，follower，observer，其中leader负责读写请求，follower负责读请求，observer负责分担读请求，不参与选举</li><li>对于写请求，都会有leader来处理，leader内部会有一个队列来处理，每个事件都有事务id，leader处理后，会广播给follower进行同步，当半数以上节点同步成功，提交事务</li><li>对于读请求，因为可能会有部分节点同步较慢，所以无法保证强一致性，但是会保证最终一致性</li></ul></li><li>es<ul><li>es的主从，也是分片层面的，每个分片都有副本分片，对于每个写请求，都要同步给所有副本才成功， 对于读请求，会读取副本分片进行负载均衡</li></ul></li><li>mysql<ul><li>mysql的主从同步</li><li>过程 ： 首先从库连接到主库时会创建一个io线程，泳衣请求主库更新的binlog，并且把收到的binlog写到一个relay log日志文件里，主库会创建一个log dump线程发送binlog，同时从库启动一个sql线程读取relay log日志文件，在从库里回放，实现最终一致性</li></ul></li></ul><h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p>分片主要为了水平扩展，将数据分片，扩展了读请求的并发量。</p><ul><li>redis<ul><li>redis分片主要是redis cluster中的hash槽，redis-cluster同时还负责主从同步和主从的选举</li><li>redis-cluster引用了哈希槽的概念，一般由2^14 = 16384个槽，每个key通过crc16校验后对16383取模来决定放置哪个槽。集群中每个节点负责一部分hash槽。</li><li>当增加一个节点后，需要把每个节点的一部分槽和数据迁移到新的节点，每个节点负责的槽为变少了。</li><li>当下线一个节点时，需要先把该节点的槽位迁移到其他节点，然后关闭对应节点</li><li>集群模式下，redis接收任何命令都是线计算槽为，然后找到对应的节点，如果节点时自身，则处理命令，否则恢复moved重定向错误，通知客户端请求正确的节点<ul><li>命令行下可以加-c自动重定向</li></ul></li><li>当集群正在发生迁移时，接收到命令后，可能发生槽的一部分数据在原来的节点，一部分在当前节点，这个时候先在自己的本地查找，如果没有找到，发送ask重定向到原来的节点。</li></ul></li><li>kafka<ul><li>kafka的分片是用于扩展集群吞吐量的，对于生产者来说，每次写入时，会通过负载均衡（轮训，随机，hash）写入其中一个分片，对于消费者来说，一个分片只能被一个实例所消费。</li><li>一个topic的分区尽量会分布到不同的broker中</li><li>一个topic的每一条消息，对于一个消费组来说，只能消费一次，放到分片层面，就是一个分片只能被消费组中的一个消费者消费</li><li>当消费组订阅的topic数量，topic的分片数量，topic的消费者发生变化时，会触发rebalance，重新分配消费者</li></ul></li><li>zookeeper<ul><li>zk没有分片的概念，因为存储的数据都是轻量的</li></ul></li><li>es<ul><li>es的分片机制，es在创建索引时就会设置分片数量，</li><li>对于读请求，首先到一个协调节点，通过文档id确定分片，然后通过轮训副本分片负载均衡，读取对应的副本分片，然后将结果返回给协调节点</li><li>对于写请求， 到达协调节点后，会根据文档id确定分片，然后找到主分片所在的节点进行操作，成功后，通知到协调节点，返回给客户端</li></ul></li><li>mysql<ul><li>mysql的分片主要是分库分表，</li></ul></li></ul><h3 id="协调中心"><a href="#协调中心" class="headerlink" title="协调中心"></a>协调中心</h3><p>协调中心主要用于主从的选举和监控协调。</p><ul><li>redis<ul><li>redis的协调中心是redis-sentinel，主要是用于主节点的自动故障转移，因为在单机的主从同步下，主节点出现故障只能自己切换</li><li>哨兵也是一个集群，主要通过redis的pub/sub机制，在主库上有一个<em>_sentinel</em>:hello频道，哨兵1发布自己的的ip和端口号，哨兵2和哨兵3订阅，就可以拿到ip端口号然后进行通信，就主库下线的事情进行判断和协商</li><li>哨兵向主库发送info信息，主库回复从库列表，接着，哨兵和所有从库建立连接，同时其他哨兵也会进行连接</li><li>判断主库下线<ul><li>主观下线，每个哨兵和主库的连接情况判断</li><li>客观下线，哨兵集群对节点的判断。</li><li>当有一个哨兵判断主库主观下线后，会让其他哨兵判断，其他哨兵根据自己的连接情况进行判断，当赞成票&gt;=哨兵配置quorum（节点/2）时，标记为客观下线。</li></ul></li><li>当判断主库下线时，需要一个哨兵节点来执行主从切换，设计哨兵的选举<ul><li>还是raft算法，收到大于节点数量一半的票时，成为领导者。</li></ul></li><li>新主库的选出<ul><li>过滤掉不健康的从库，（下线或者断线，没有回复ping响应）</li><li>优先级高的</li><li>复制偏移量最大的</li></ul></li></ul></li><li>kafka<ul><li>kafka的协调中心使用的是zk</li><li>kafka涉及选举的有两个，<ul><li>一个是broker的controller，它主要负责集群元数据的记录，broker的管理，主题创建，副本leader选举。controller的选举比较简单，就是多个broker取zk上创建/controller临时节点，第一个创建成功的就是controller，同时没有成功的节点会在这个节点下创建watcher，当对应broker挂了，其他节点就可以收到消息进行新的选举</li><li>另一个时副本分片的选举，这个介绍的不多，大部分说的都是由controller来从ISR中进行选举</li></ul></li></ul></li><li>zookeeper<ul><li>zk本身就是作为协调中心存在的，所以这里主要介绍它的选举机制</li><li>zk使用的是zab协议，zab主要有两个模式，崩溃恢复和广播通知</li><li>崩溃恢复<ul><li>当leader服务器发生网络中断，宕机等异常情况时，zk集群会进入恢复模式，当选举出新的leader，并且已经有半数以上机器和leader的数据同步，退出恢复模式</li></ul></li><li>消息广播<ul><li>退出恢复模式后，进入消息广播模式，leader接收到读请求后，会讲消息广播出去，follower和observer会进行同步，当超过一般机器ack后，提交消息</li><li>leader会对其他节点创建一个队列，保证数据同步</li></ul></li><li>选举详情<ul><li>当进入恢复状态后，每台机器首先会把票投给自己，然后将投票信息发出去，投票信息为（myid，zxid）myid时机器的id，zxid是当前机器最新同步的事务id，当机器收到其他机器的投票信息，会比较投票信息，首先比较zxid，大优先，然后比较myid，也是大优先，如果发现目标机器比自己更适合，就会讲投票信息更改为目标机器再次广播出去，当目标机器发现自己收到票超过半数，就成为leader，将信息同步出去。</li><li>zk的节点数都是奇数，因为如果超过半数机器挂掉，集群就不可用了，那么偶数机器效果一样，还多部署一台机器，造成浪费。</li><li>当follwer挂掉后，只要挂掉的机器没有超过一半，集群就是可用的，leader后面会继续同步数据</li><li>当leader挂掉后，集群会停止服务，进行选举</li></ul></li></ul></li><li>es<ul><li>es在7.x之前使用的是bully算法，7.x之后使用raft算法</li><li>es有两种节点，主节点和数据节点，客户端节点<ul><li>主节点， 主节点负责创建索引，删除索引，分配分片，用户请求可以发往任何一个节点，并由该节点分发请求，收集结果等操作，而并不需要经过主节点转发</li><li>数据节点， 数据节点主要负责数据的存储和相关操作，比如索引数据的创建，修改，删除，搜索，数据节对机器配置要求比较高</li><li>客户端节点， 即不做候选节点也不做数据节点的节点，只负责请求的分法，汇总，就是协调节点</li><li>协调节点，逻辑上的，任何节点都可以当，当一个节点收到请求后，会把查询语句分法到其他节点，并合并各个节点的查询结果，然后返回给用户</li></ul></li><li>es的选举算法是zen directory，不过最新的已经换了，采用集群协调模块代替旧版</li><li>zen directory的主要流程时， 由master-eligoble节点发起选举，当满足一下条件后发起<ul><li>当前eligoble节点不是master</li><li>连接不到master</li><li>超过一定数量的节点认为没有master时</li></ul></li><li>每个eligoble会根据closterStateVersion和节点id排序， 然后选举出一个它认为的master，然后向它发送join请求，目标节点如果已经是master，就将它加入，并发布新的cluster state， 如果目标节点正在竞选，就会把这个join当作一个选票，如果目标节点认为自己选不上，就拒绝这个join请求，</li><li>当收到半数以上的票后，就成为master节点。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper简述</title>
      <link href="/2022/02/28/zookeeper-jian-shu/"/>
      <url>/2022/02/28/zookeeper-jian-shu/</url>
      
        <content type="html"><![CDATA[<h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="zk是什么"><a href="#zk是什么" class="headerlink" title="zk是什么"></a>zk是什么</h3><p>zk是一个分布式协调器，在分布式系统中充当一个中间层的东西，例如在dubbo中做注册中心，协调生产者和消费者的路由，例如在分布式服务中做分布式锁，做第三方锁工具，还有在kafka中做broker的选举功能。</p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>内部是一个多叉树结构，每个节点都可以存储数据，没有节点都可以有多个子节点，每个字节点被称为znode，是zk中的最小单元，节点分为四大类</p><ol><li>持久节点，一直存在</li><li>临时节点，会话内存在</li><li>持久顺序节点，持久节点，子节点名称有顺序</li><li>持久临时节点，临时节点，字节点名称有顺序<br>节点拥有版本信息，有三种，子节点版本，数据节点版本，acl版本，分别都由变更而变更<br>acl为zk的权限管控<br>watcher为监听器，可以监听指定事件，例如删除节点的事件。<br>会话为zk客户端和服务端的tcp长连接，客户端通过心跳保持链接</li></ol><h3 id="zk集群和选举"><a href="#zk集群和选举" class="headerlink" title="zk集群和选举"></a>zk集群和选举</h3><p>zk使用的是zab算法（paxos简化），主要包括崩溃恢复和消息广播，前者是当leader发生意外中断时，集群快速选举一个新的leader，恢复服务，后者是所有的写请求打到leader，由leader广播给所有flowers进行同步，超过一半ack就提交事物</p><h4 id="集群节点类型"><a href="#集群节点类型" class="headerlink" title="集群节点类型"></a>集群节点类型</h4><p>leader ： 处理读写请求，对写请求进行排序编号，保证处理消息的先进先出<br>follower： 只处理读请求，参加选举<br>observer： 分担读请求。</p><h4 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h4><p>假设集群由3台机器，选举过程如下</p><ol><li>server启动后，进入选举，首先投票给自己，投票格式为（myid，zxid），（前者是自己的id，后者是全局事务id，事务id就是leader收到写请求后，生成的，然后广播给followers，所以zxid大的代表收到的事务更新），然后会把投票信息广播出去，例如server1的是（1，0），当server2启动后，也生成了投票信息，（2，0），然后又收到了server1的广播，这个时候有一个票的优先级，zxid大的优先，myid大的优先，所以server2不改动，还是把（2，0），广播出去，server1收到后发现比自己优先，就更新投票信息广播，这个时候server3启动，发现server2已经有两票了，那么集群已经结束选举了，自己直接变成follower.<br>如果follower挂掉了，只要没有超过半数，集群就没问题，对应机器不提供服务即可<br>但是leader挂掉了，就需要重新选举leader</li></ol><h3 id="zk的强一致性"><a href="#zk的强一致性" class="headerlink" title="zk的强一致性"></a>zk的强一致性</h3><p>直接结论，zk的写是强一致的，读不是，<br>对于写来说，所有写请求都会到leader，由leader广播，而且生成zxid，所以即使follower挂掉重启，也是保持一致的<br>但是读来说，因为写请求，如果有一半以上的节点ack了，就commit事务，所以有部分节点会慢一点，就不是强一致了。当然可以使用sync read。直接读leader，就是一致了。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo核心流程</title>
      <link href="/2022/02/27/dubbo-he-xin-liu-cheng/"/>
      <url>/2022/02/27/dubbo-he-xin-liu-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>最近在看dubbo源码，记录一下dubbo的核心流程，即服务暴露和服务引用</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="服务暴露"><a href="#服务暴露" class="headerlink" title="服务暴露"></a>服务暴露</h3><p>服务暴露的入口在<code>ServiceConfig#export()</code>，经过一系列的读取配置后进入<code>doExportUrls()</code>方法，<br>在该方法中，先加载注册中心的URL，然后进入<code>doExportUrlsFor1Protocol()</code>方法中，<br>该方法中，首先进行对应服务接口的方法的配置，然后跳过一系列的校验判断，到达服务暴露的部分，首先是遍历注册中心url，每一个url生成一个Invoker，创建Exporter，添加到全局变量数组中。<br>上述创建invoker的代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 使用 ProxyFactory 创建 Invoker 对象</span>    Invoker<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> invoker <span class="token operator">=</span> proxyFactory<span class="token punctuation">.</span><span class="token function">getInvoker</span><span class="token punctuation">(</span>ref<span class="token punctuation">,</span> <span class="token punctuation">(</span>Class<span class="token punctuation">)</span> interfaceClass<span class="token punctuation">,</span> registryURL<span class="token punctuation">.</span><span class="token function">addParameterAndEncoded</span><span class="token punctuation">(</span>Constants<span class="token punctuation">.</span>EXPORT_KEY<span class="token punctuation">,</span> url<span class="token punctuation">.</span><span class="token function">toFullString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 创建 DelegateProviderMetaDataInvoker 对象</span>    DelegateProviderMetaDataInvoker wrapperInvoker <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DelegateProviderMetaDataInvoker</span><span class="token punctuation">(</span>invoker<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 使用 Protocol 暴露 Invoker 对象</span>    Exporter<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> exporter <span class="token operator">=</span> protocol<span class="token punctuation">.</span><span class="token function">export</span><span class="token punctuation">(</span>wrapperInvoker<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 添加到 `exporters`</span>    exporters<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>exporter<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用protocal暴露invoker对象"><a href="#使用protocal暴露invoker对象" class="headerlink" title="使用protocal暴露invoker对象"></a>使用protocal暴露invoker对象</h4><p>protocol是接口Protocol的实现类，这个接口比较核心，接口内容如下</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@SPI</span><span class="token punctuation">(</span><span class="token string">"dubbo"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Protocol</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/**     * Get default port when user doesn't config the port.     *     * @return default port     */</span>    <span class="token keyword">int</span> <span class="token function">getDefaultPort</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * Export service for remote invocation: &lt;br>     * 1. Protocol should record request source address after receive a request:     * RpcContext.getContext().setRemoteAddress();&lt;br>     * 2. export() must be idempotent, that is, there's no difference between invoking once and invoking twice when     * export the same URL&lt;br>     * 3. Invoker instance is passed in by the framework, protocol needs not to care &lt;br>     *     * @param &lt;T>     Service type     * @param invoker Service invoker     * @return exporter reference for exported service, useful for unexport the service later     * @throws RpcException thrown when error occurs during export the service, for example: port is occupied     */</span>    <span class="token comment" spellcheck="true">/**     * 暴露远程服务：&lt;br>     * 1. 协议在接收请求时，应记录请求来源方地址信息：RpcContext.getContext().setRemoteAddress();&lt;br>     * 2. export() 必须是幂等的，也就是暴露同一个 URL 的 Invoker 两次，和暴露一次没有区别。&lt;br>     * 3. export() 传入的 Invoker 由框架实现并传入，协议不需要关心。&lt;br>     *     * @param &lt;T>     服务的类型     * @param invoker 服务的执行体     * @return exporter 暴露服务的引用，用于取消暴露     * @throws RpcException 当暴露服务出错时抛出，比如端口已占用     */</span>     <span class="token annotation punctuation">@Adaptive</span>    <span class="token operator">&lt;</span>T<span class="token operator">></span> Exporter<span class="token operator">&lt;</span>T<span class="token operator">></span> <span class="token function">export</span><span class="token punctuation">(</span>Invoker<span class="token operator">&lt;</span>T<span class="token operator">></span> invoker<span class="token punctuation">)</span> <span class="token keyword">throws</span> RpcException<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * Refer a remote service: &lt;br>     * 1. When user calls `invoke()` method of `Invoker` object which's returned from `refer()` call, the protocol     * needs to correspondingly execute `invoke()` method of `Invoker` object &lt;br>     * 2. It's protocol's responsibility to implement `Invoker` which's returned from `refer()`. Generally speaking,     * protocol sends remote request in the `Invoker` implementation. &lt;br>     * 3. When there's check=false set in URL, the implementation must not throw exception but try to recover when     * connection fails.     *     * @param &lt;T>  Service type     * @param type Service class     * @param url  URL address for the remote service     * @return invoker service's local proxy     * @throws RpcException when there's any error while connecting to the service provider     */</span>    <span class="token comment" spellcheck="true">/**     * 引用远程服务：&lt;br>     * 1. 当用户调用 refer() 所返回的 Invoker 对象的 invoke() 方法时，协议需相应执行同 URL 远端 export() 传入的 Invoker 对象的 invoke() 方法。&lt;br>     * 2. refer() 返回的 Invoker 由协议实现，协议通常需要在此 Invoker 中发送远程请求。&lt;br>     * 3. 当 url 中有设置 check=false 时，连接失败不能抛出异常，并内部自动恢复。&lt;br>     *     * @param &lt;T>  服务的类型     * @param type 服务的类型     * @param url  远程服务的URL地址     * @return invoker 服务的本地代理     * @throws RpcException 当连接服务提供方失败时抛出     */</span>    <span class="token annotation punctuation">@Adaptive</span>    <span class="token operator">&lt;</span>T<span class="token operator">></span> Invoker<span class="token operator">&lt;</span>T<span class="token operator">></span> <span class="token function">refer</span><span class="token punctuation">(</span>Class<span class="token operator">&lt;</span>T<span class="token operator">></span> type<span class="token punctuation">,</span> URL url<span class="token punctuation">)</span> <span class="token keyword">throws</span> RpcException<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * Destroy protocol: &lt;br>     * 1. Cancel all services this protocol exports and refers &lt;br>     * 2. Release all occupied resources, for example: connection, port, etc. &lt;br>     * 3. Protocol can continue to export and refer new service even after it's destroyed.     */</span>    <span class="token comment" spellcheck="true">/**     * 释放协议：&lt;br>     * 1. 取消该协议所有已经暴露和引用的服务。&lt;br>     * 2. 释放协议所占用的所有资源，比如连接和端口。&lt;br>     * 3. 协议在释放后，依然能暴露和引用新的服务。&lt;br>     */</span>    <span class="token keyword">void</span> <span class="token function">destroy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实现中中比较重要的有<code>ProtocolFilterWrapper</code>,<code>RegistryProtocol</code>,<code>DubboProtocol</code>,第一个是一个包装类，会创建filter的调用链，或者打到refistryProtocol实例中，第二个主要处理向注册中心注册的工作，主流程在第三个中。<br>dubboProtocol中有以下几步骤</p><ol><li>创建dubboExporter，放入缓存的map中</li><li>处理本地存根的问题</li><li>启动服务器</li><li>初始化序列化优化器<br>DubboExporter内容比较简单，就是一个包装类，内部加了一个unExport()的方法<br>本地存根先不看<br>启动服务器，这里会创建一个ExchangeServer实例，然后内部创建Transport实例， 默认实例就是NettyTransport，内部是NettyServer<br>下面就是netty的通信流程类， 具体的业务接口是channelHandler，真正做业务的实现类还是在DubboProtocol里，其余实现类基本上都是装饰器作用，例如多线程的处理器（ExecutionChannelHandler），多消息处理器（MutiMessageHandler)等等。</li></ol><h4 id="nettyServer"><a href="#nettyServer" class="headerlink" title="nettyServer"></a>nettyServer</h4><p>可以看到服务暴露最后到了NettyServer（不一定，这个是默认实现），前面说到了，真正的业务处理只有一处，我们详细看下DubboProtocol业务处理方法</p><pre class="line-numbers language-java"><code class="language-java"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>核心方法是reply()方法，<br>它的invoker就是具体的逻辑，找到对应的exporter，然后拿到具体实现类的代理类invoker，调用方法，获取结果，通过netty返回相应。<br>这部分是服务引用到服务端之后的操作。</p><h3 id="服务引用"><a href="#服务引用" class="headerlink" title="服务引用"></a>服务引用</h3><p>服务引用的入口在<code>ReferenceConfig#get()</code>,进入后检查是否有引用ref，如果没有进行初始化<code>init()</code><br>init内部，首先还是一些读取配置和校验的工作，然后到<code>ref = createProxy(map)</code>，创建引用<br>方法内部主要进行url的判断和读取设置，这个url可能是直连地址的，也可以是注册中心的，然后根据获取的url拿到Invoker，最后到达<code>proxyFactory.getProxy(invoker),创建代理先不说，说拿到InvokerInvoker的获取在这一行</code>refprotocol.refer()<code>方法，refprotocol还是接口Protocol的实现类和服务暴露类似，还是经过</code>ProtocolFilterWrapper<code>,</code>RegistryProtocol<code>后到达DubboProtocol，在</code>DubboProtocol#refer`方法中，创建了一个DubboInvoker，在这个Invoker中的doInvoke进行真正的调用<br>doInvoke方法中，区分三种调用，oneway，同步，异步，根据操作都是根据传入的client实例调用request方法<br>看一下client的实例，回到DubboProtocol类，找到getClient方法，然后根据是否使用共享客户端选择进入getShardClient方法或者直接生成client<br>看一下getShardClient方法，首先在一个缓存map中寻找，找到了并且没有关闭则增加client引用计数然后返沪，关闭了则移出该client，然后走下去，下面就是加锁创建client<br>然后看一下直接生成client，该方法会创建一个ExchangeClient实例，该实例底层还是获取一个Exchanger接口的实例。<br>然后获得Transport的实例，nettyClient，调用channelHandler的方法。<br>这个channelHandler经过DecoderHandler将请求编码，到达HeaderExchangeHandler，发送消息</p><h4 id="Exchangers"><a href="#Exchangers" class="headerlink" title="Exchangers"></a>Exchangers</h4><p>这里着重说一下Exchanger接口，它有一个工厂类，是门面模式，两个主要方法bind&amp;connect，如果是服务端创建ExchangerServer，就调用bind，客户端创建ExchangerClient，就调用connect。<br>而Exchangers内部呢，就会使用Exchanger的实现类HeaderExchanger，这个类内部呢，就会创建Transport实例，服务端就是nettyServer，客户端是nettyClient</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中间件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式</title>
      <link href="/2022/02/27/she-ji-mo-shi/"/>
      <url>/2022/02/27/she-ji-mo-shi/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>记录一下我对各种设计模式的理解，不会详细介绍设计模式内容</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h3><p>外观模式的意义在于， 当存在一个复杂的子系统，子系统中有多个模块，对于<code>外界</code>来说，这些模块的意义或许很难理解，导致很难正确使用，当然只是对于不同模块难以区分时，可以使用外观模式，对外一个简单功能的类或接口，外部调用子系统功能都通过这个接口，而接口内部封装好各个模块的功能，根据入参来选择不同的模块功能。</p><h3 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h3><p>中介者模式和外观模式很难区分，因为实现基本上没有大的差别，都是使用一个接口来封装很多模块的功能，区别在我看来，在于是否对外，中介者模式是为了系统内部的不同模块之间的通信，而外观模式是对外，这一点从名称上也可见一斑。</p><h3 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h3><p>这是一个比较有趣的设计模式，最好理解的例子就是游戏，游戏中经常有大规模的重复对象，例如fps中的子弹，可能会分不同规格的子弹，但是统一规格的子弹，那数量也非常大。但是我们在内存中不能去创建这么多对象，否则一场战争下来，内存会炸。这里就是使用享元模式，也就是池化一个对象，或者称为对象池，但值得注意的是，被池化的对象本身包含的是可共享的，一般分为内在状态和外在状态，内在状态包含不变的，可在多个对象中重复使用的变量，外部状态是各个情景中不同的变量，一般由参数传递进来。<br>实现来说，享元模式就是一个工厂类，内部维持一个容器，当外界需要对应的对象时，从其中获取，如果没有对应的，就新建一个，有则直接取出使用。但是不能去修改。</p><h3 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h3><p>这个模式比较好理解的例子就是充电器转接头，现在手机的充电器有很多种，所以很多时候就没办法使用别人的，这就需要充电器转接头。而适配器模式也就是这个功能，还是比较简单的，从实现来说，一般就是有两个不同的接口，那么适配器类实现其中一个，然后内部引用另一个接口的实现类，在对应的接口方法中，转换对应的参数和返回值。</p><h3 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h3><p>这个模式比较好理解，就是为了设计模式原则中的开闭原则，面向新增开放，面向修改关闭，当有同一个接口的一个或者多个实现类需要额外的操作时，我们可以使用模版模式抽象出一个抽象类来汇聚这些额外的操作，也可以使用装饰器模式，创建一个装饰者类，接收一个实现类，在对应的接口做额外的操作前或后，再调用原来的方法。<br>这个模式我印象比较深的Dubbo里面transport层的实现，对于接口channelHandler的实现，真正处理消息的只有一个实现类，其他基本上全部时装饰者类，例如多线程的封装类，解码处理器（处理Decodeable），多消息处理器，心跳处理器等等。</p><h3 id="模版方法模式"><a href="#模版方法模式" class="headerlink" title="模版方法模式"></a>模版方法模式</h3><p>这个模式我用的还是比较多的，在业务中非常常用，也非常好用。他是为了解决同一个接口的多个实现类中有大量重复逻辑的问题<br>从实现来看，对于一个接口的多个实现类，根据重复的代码，抽象出一个抽象类，然后将实现类中不同的部分以抽象方法暴露出来，供字类实现。<br>其中有一个点时，如何决定使用哪一个实现类（当然除了明确知道的情况），一般需要在外部再封装一个实现类，根据匹配情况，调用不同的接口，这一般需要接口额外出一个match接口，各个实现类实现自己的匹配逻辑，这就要求这些匹配逻辑不能有重复的部分，不然就需要注意遍历实现类的顺序。<br>当然实现的方案有很多，比较巧妙的方式是通过动态代理的方式，实现自动注入。</p><h3 id="（抽象）工厂方法"><a href="#（抽象）工厂方法" class="headerlink" title="（抽象）工厂方法"></a>（抽象）工厂方法</h3><p>简单来说既是把对象的创建和使用分开，将创建使用一个工厂类封装，内部可以封装一些选择逻辑，这样新增一种类型时，不需要修改调用侧，只修改工厂方法即可。<br>抽象工厂是在工厂方法的基础上，如果需求有多维度的接口聚合生成一个对象，例如，我们是一个家具店，首先要创建一些家具类，有椅子，有衣柜等等，在这个基础上呢，家具又有很多风格，国风也好，意大利，欧美风什么的，那么我们就可以先创建一个家具工厂类，然后在这个类基础上，我们可以创建国风家具工厂类，欧美风家具工厂类等等。<br>然后在应用层，根据调用创建对应的工厂类。</p><h3 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h3><p>这个模式比较简单，就是克隆类，值得注意的是，要进行深拷贝。<br>这里说一下java的Cloneable接口，这是个空接口，但是如果字类要重写Object#clone方法的话，必须要实现这个接口。<br>然后说一下clone方法，这个方法在object，是native方法，访问权限是protected，字类无法访问到，必须重写。<br>一般重写会调用super.clone()，这个就是调用object的native方法，会复制一份，但是对于该对象内部的属性却是浅拷贝，如果含有引用类型的属性，只拷贝了引用，对象还是一个，所以一般需要对应引用类型的类也实现Cloneable接口，实现clone方法。<br>不过这种方式个人觉得不好，使用静态工厂方法或者工厂类，自己实现拷贝逻辑比较好，当然对于数组而言，可以使用clone。</p>]]></content>
      
      
      <categories>
          
          <category> 开发问题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring循环依赖</title>
      <link href="/2022/02/26/spring-xun-huan-yi-lai/"/>
      <url>/2022/02/26/spring-xun-huan-yi-lai/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>从源码说一下spring解决循环依赖的问题</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="循环依赖"><a href="#循环依赖" class="headerlink" title="循环依赖"></a>循环依赖</h3><p>循环依赖，在spring中比较好理解，就是不同bean之间的依赖关系形成环，例如A依赖B，B依赖C，C又依赖A，按照正常的注入，就形成了死循环，而spring为这种问题提供了解决方案。值得注意的是，构造器注入是无法解决的，这里只是解决了field的注入方式，同时，也只能解决单例bean的构造，其他作用域的无法解决。至于为什么，会在下面解释。</p><h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><p>spring解决循环依赖的入口如何找，很好理解，我们是要获取一个bean，所以就在获取bean的地方，找到加载bean的入口<code>AbstractBeanFactory#doGetBean</code>.<br>在这个方法中，在获取beanName后的第一步，就是从缓存中获取bean，这个缓存其实就是spring存放bean实例的地方。<br>找到<code>DefaultSingletonBeanRegistry#getSingleton</code>,这是从缓存中获取bean的方法</p><pre class="line-numbers language-Java"><code class="language-Java">@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) {    // 从单例缓冲中加载 bean    Object singletonObject = this.singletonObjects.get(beanName);    // 缓存中的 bean 为空，且当前 bean 正在创建    if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {        // 加锁        synchronized (this.singletonObjects) {            // 从 earlySingletonObjects 获取            singletonObject = this.earlySingletonObjects.get(beanName);            // earlySingletonObjects 中没有，且允许提前创建            if (singletonObject == null && allowEarlyReference) {                // 从 singletonFactories 中获取对应的 ObjectFactory                ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);                if (singletonFactory != null) {                    // 获得 bean                    singletonObject = singletonFactory.getObject();                    // 添加 bean 到 earlySingletonObjects 中                    this.earlySingletonObjects.put(beanName, singletonObject);                    // 从 singletonFactories 中移除对应的 ObjectFactory                    this.singletonFactories.remove(beanName);                }            }        }    }    return singletonObject;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>首先是<code>singletonObjects</code>这个类变量是一个map，存放的是beanName-&gt;单例bean实例的缓存，然后如果在这个缓存中有实例，则直接返回。<br>如果一级缓存中没有的话，并且这个bean正在创建，然后锁住一级缓存（保证只有一个线程进入即可），然后从二级缓存中获取bean实例。<br>这个二级缓存是核心，变量名是<code>earlySingletonObjects</code>，提前的单例实例，顾名思义，就是提前暴露的单例实例，什么叫提交暴露呢，很简单，就是完成了bean的构造，但是没有进行属性注入和初始化，这个可以记一下，下面详细介绍，<strong>（标记1）</strong><br>然后如果从二级缓存中也没有，并且允许提交创建，则从三级缓存中获取，三级缓存是<code>singletonFactories</code>，看名字是单例bean的工厂类，如果从三级缓存中拿到了，就从工厂类中拿到实例，放到2级缓存，删除三级缓存中的bean工厂。这里比较疑惑的点是，为什么要用三级缓存，看代码只是从工厂中拿到bean实例，那么只用二级缓存或者只用三级缓存不行吗，这个也记下，下面详细介绍，<strong>（标记2）</strong></p><h4 id="标记1"><a href="#标记1" class="headerlink" title="标记1"></a>标记1</h4><p>下面介绍下标记1的问题，找到三级缓存的来源处，可以看下面3段代码</p><pre class="line-numbers language-Java"><code class="language-Java">boolean earlySingletonExposure = (mbd.isSingleton() // 单例模式        && this.allowCircularReferences // 运行循环依赖        && isSingletonCurrentlyInCreation(beanName)); // 当前单例 bean 是否正在被创建if (earlySingletonExposure) {    if (logger.isTraceEnabled()) {        logger.trace("Eagerly caching bean '" + beanName +                "' to allow for resolving potential circular references");    }    // 提前将创建的 bean 实例加入到 singletonFactories 中    addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));}......protected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {    Assert.notNull(singletonFactory, "Singleton factory must not be null");    //加锁    synchronized (this.singletonObjects) {        if (!this.singletonObjects.containsKey(beanName)) {            this.singletonFactories.put(beanName, singletonFactory);            this.earlySingletonObjects.remove(beanName);            this.registeredSingletons.add(beanName);        }    }}......protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {    Object exposedObject = bean;    if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {        for (BeanPostProcessor bp : getBeanPostProcessors()) {            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);            }        }    }    return exposedObject;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>首先第一段代码是创建bean的时候的内容，主要的是它的位置，它位于<code>AbstractAutowireCapableBeanFactory.doCreateBean</code>方法中，前面是createBeanInstance，后面是populationBean和initializeBean，了解bean创建流程的就知道了，这个位置就是刚根据构造器创建了bean实例，但是还没有把依赖注入，也没有初始化bean。<br>然后看第二段代码，第二段代码是将提交暴露的bean工厂加入到三级缓存中，没有特别的<br>最后看第三段代码，是生成提前暴露的bean工厂。<br>这下应该解释了提前暴露的问题</p><h4 id="标记2"><a href="#标记2" class="headerlink" title="标记2"></a>标记2</h4><p>然后说标记2的问题，初步看下来，感觉二级缓存和三级缓存是有一点冲突的，这个就和spring的重要特性aop有关了，我们知道spring-aop的实现就是生成代理类，不管用动态代理还是cglib，都是生成一个代理类，那么提前暴露bean，万一这个bean是有代理的怎么办。只有两种办法，要不就是提前暴露bean的时候，就生成代理后的bean，但是循环依赖毕竟是少部分情况，而且也不是很推荐，所以没有必要，还有一种就是发生循环依赖的时候，我们再生成代理类。而spring实现的方式就是三级缓存，用工厂类来封装，如果发生了循环依赖，就调用工厂类的工厂方法，获取代理bean，也即是上面第三段代码的部分。<br>而spring选择第二种方法的原因，想来应该也是和设计原则之类的原因，毕竟两种方案其实差不太多，spring启动本来就很慢了，不差那几秒钟。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>循环依赖的解决看下来简单，但那是从代码来看的，如果从设计角度，还是很巧妙的，也很值得见鉴。<br>而一开始说的两种情况，一个是构造器的无法使用，那是因为添加提前暴露bean在构造之后，还有就是原型作用域的无法使用，因为原型作用域的bean不受spring管控，spring也没有加缓存。这两种情况发生循环依赖都会直接报错，启动失败。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java字节码</title>
      <link href="/2022/02/24/java-zi-jie-ma/"/>
      <url>/2022/02/24/java-zi-jie-ma/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>Java字节码结构看过很多遍，单总是记不太清，看的博客也是五花八门，这里还是自己总结下。<br>声明：本篇博客大部分位其他博客内容，只供自己总结使用，不是原创内容</p><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><h3 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a>字节码</h3><p>Java字节码是Java跨平台，也就是所谓“一次编译，到处运行“的根本，Java的运行容器，也就是JVM，它不是跨平台的，win和linux的JVM实现都不一样，真正跨平台的是字节码文件，因为所有字节码是同一份，不同平台的JVM虽然实现不同，但是大家都遵循着一个规范，就是JVM规范，对于字节码的识别是相同的。<br>而字节码文件（.class）并不是Java独有的，也可以理解为它适合JVM绑定的，因为不只是Java代码可以编译成字节码文件，例如scala，groovy，kotlin文件都可以编译成字节码文件，这也是这些代码可以在一个项目里存在的原因，使用不同的编译器，不同的代码文件最后都编译成同一份字节码文件。</p><h3 id="获取字节码"><a href="#获取字节码" class="headerlink" title="获取字节码"></a>获取字节码</h3><p>Java中获取字节码很简单，使用javac xxx.java 即可<br>打开字节码文件一般以16进制的形式打开（vscode用hexdunp插件）<br>一般用idea打开的字节码文件都是反编译以后的Java代码，也可以用javap反编译，结果更清晰一点</p><p>这边复制一份网上的字节码文件</p><p>java代码是 Main.java</p><pre class="line-numbers language-Java"><code class="language-Java">public class Main {    private int m;    public int inc() {        return m + 1;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字节码 Main.class</p><pre><code>  Offset: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F 00000000: CA FE BA BE 00 00 00 34 00 13 0A 00 04 00 0F 09    J~:&gt;...4........00000010: 00 03 00 10 07 00 11 07 00 12 01 00 01 6D 01 00    .............m..00000020: 01 49 01 00 06 3C 69 6E 69 74 3E 01 00 03 28 29    .I...&lt;init&gt;...()00000030: 56 01 00 04 43 6F 64 65 01 00 0F 4C 69 6E 65 4E    V...Code...LineN00000040: 75 6D 62 65 72 54 61 62 6C 65 01 00 03 69 6E 63    umberTable...inc00000050: 01 00 03 28 29 49 01 00 0A 53 6F 75 72 63 65 46    ...()I...SourceF00000060: 69 6C 65 01 00 09 4D 61 69 6E 2E 6A 61 76 61 0C    ile...Main.java.00000070: 00 07 00 08 0C 00 05 00 06 01 00 0A 6F 74 68 65    ............othe00000080: 72 2F 4D 61 69 6E 01 00 10 6A 61 76 61 2F 6C 61    r/Main...java/la00000090: 6E 67 2F 4F 62 6A 65 63 74 00 21 00 03 00 04 00    ng/Object.!.....000000a0: 00 00 01 00 02 00 05 00 06 00 00 00 02 00 01 00    ................000000b0: 07 00 08 00 01 00 09 00 00 00 1D 00 01 00 01 00    ................000000c0: 00 00 05 2A B7 00 01 B1 00 00 00 01 00 0A 00 00    ...*7..1........000000d0: 00 06 00 01 00 00 00 08 00 01 00 0B 00 0C 00 01    ................000000e0: 00 09 00 00 00 1F 00 02 00 01 00 00 00 07 2A B4    ..............*4000000f0: 00 02 04 60 AC 00 00 00 01 00 0A 00 00 00 06 00    ...`,...........00000100: 01 00 00 00 0D 00 01 00 0D 00 00 00 02 00 0E       ...............</code></pre><p>javap反编译 javap -verbose -p Main.class</p><pre><code>Classfile /Users/xxx/xxx/xxxx/xxx/main/java/xxx/Main.class  Last modified 2022-2-25; size 271 bytes  MD5 checksum 81e29186872af47b63bf14bd01d386b8  Compiled from &quot;Main.java&quot;public class other.Main  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #4.#15         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #3.#16         // other/Main.m:I   #3 = Class              #17            // other/Main   #4 = Class              #18            // java/lang/Object   #5 = Utf8               m   #6 = Utf8               I   #7 = Utf8               &lt;init&gt;   #8 = Utf8               ()V   #9 = Utf8               Code  #10 = Utf8               LineNumberTable  #11 = Utf8               inc  #12 = Utf8               ()I  #13 = Utf8               SourceFile  #14 = Utf8               Main.java  #15 = NameAndType        #7:#8          // &quot;&lt;init&gt;&quot;:()V  #16 = NameAndType        #5:#6          // m:I  #17 = Utf8               other/Main  #18 = Utf8               java/lang/Object{  private int m;    descriptor: I    flags: ACC_PRIVATE  public other.Main();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 8: 0  public int inc();    descriptor: ()I    flags: ACC_PUBLIC    Code:      stack=2, locals=1, args_size=1         0: aload_0         1: getfield      #2                  // Field m:I         4: iconst_1         5: iadd         6: ireturn      LineNumberTable:        line 13: 0}SourceFile: &quot;Main.java&quot;</code></pre><h3 id="详细结构"><a href="#详细结构" class="headerlink" title="详细结构"></a>详细结构</h3><h4 id="魔数"><a href="#魔数" class="headerlink" title="魔数"></a>魔数</h4><p>前8位是魔数，字节码的标志，都是CAFEBABE</p><h4 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h4><p>接下来8位位版本号<code>0000 0034</code>，前4位位副版本号，后四位位主版本号，（只知道java8是52，是有规律的）</p><h4 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h4><p>接下来4位<code>0013</code>是常量池中的常量数量，这个数量是从1开始计数的，所以一共有18个，<br>常量池中存放了（字面量）文字字符串，常量值，（符号引用）当前类的类名，字段名，方法名，字段和方法的描述符，对当前类的引用信息，当前类中对其他类的引用信息等。<br>常量池是一个类的结构索引，其他地方对对象的引用可以通过索引位置代替，常量池中的数据通过索引来访问，但是下标是从1开始的，如果索引了0，就代表不引用任何常量。</p><p>在字节码加载入虚拟机的链接阶段，内部分为校验，准备，解析，在解析阶段，会把符号引用转变为直接引用，也就是把常量池中的这些符号引用转化成为内存中的真实地址。</p><p>0013后面的到下一个类型前的内容都是常量池的内容，每一种常量类型的结构不同，占用字节也不同，解析也是通过tag先识别类型，然后读取对应长度的字节来解析的。<br>这边就不具体说了，可以参考一下表<br><img src="2.png" alt="常量池"></p><h4 id="类访问标记"><a href="#类访问标记" class="headerlink" title="类访问标记"></a>类访问标记</h4><p>接下来是类的访问标记，有个对应表<br><img src="1.png" alt="对应表"><br>值得注意的是，这个字段用两个字节表示，例如例子中的javap后的反编译内容中访问标记是ACC_PUBLIC, ACC_SUPER，将二者相加，结果是0x0021，可以在字节码文件中找到</p><h4 id="类索引，父类索引，接口索引"><a href="#类索引，父类索引，接口索引" class="headerlink" title="类索引，父类索引，接口索引"></a>类索引，父类索引，接口索引</h4><p>接下来的2个字节是类的索引，是一个无符号整数，值为常量池的索引，<br>再接下来2个字节是父类的索引，同上<br>再接下来2个字节是接口的计数<br>再接下来n*2个字节是接口的索引，n是接口的数量</p><h4 id="字段表"><a href="#字段表" class="headerlink" title="字段表"></a>字段表</h4><p>接下来2个字节表示类的字段数量，包括实例字段和类字段，不包括方法内部的局部变量，同样不包括父类或者接口中的字段<br>再接下来就是字段的具体描述，每个字段用一个field_info结构体来描述，包含多个修饰符，例如：</p><ul><li>访问标记 u2</li><li>字段名索引 u2</li><li>描述符索引 u2</li><li>属性计数器 u2</li><li>属性集合<br>其中修饰符都是布尔值，要么有，要么没有，字段名是索引，常量池中的<br>还有一个属性集合包含初始化值，注释信息等</li></ul><h4 id="方法表"><a href="#方法表" class="headerlink" title="方法表"></a>方法表</h4><p>还是先是两个字节表示方法数量<br>接下来是方法的具体描述，使用method_info来描述，结构也类似</p><ul><li>访问标志 u2</li><li>字段名索引 u2</li><li>描述符索引 u2</li><li>属性计数器 u2</li><li>属性集合</li></ul><h4 id="属性表集合"><a href="#属性表集合" class="headerlink" title="属性表集合"></a>属性表集合</h4><p>属性表指class文件携带的辅助信息，比如该class文件的源文件的名称，以及注解信息<br>属性表的结构没有很严格，只要不重名，任何人实现的编译器都可以向属性表写入东西，但是java虚拟机会忽略掉不认识的<br>结构如下</p><ul><li>属性名索引 u2</li><li>属性长度 u4 </li><li>属性表 u1</li></ul><p>属性表详情就不介绍了，后面有需要再说。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES原理</title>
      <link href="/2022/02/23/es-yuan-li/"/>
      <url>/2022/02/23/es-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="ES集群存储"><a href="#ES集群存储" class="headerlink" title="ES集群存储"></a>ES集群存储</h2><p><img src="1.png" alt="架构图（来自dpai.tech)"></p><h3 id="宏观"><a href="#宏观" class="headerlink" title="宏观"></a>宏观</h3><p>集群由一系列node组成，每个node由分片组成，每个es索引index由分布在不同node里面的多个分片组成。每个分片也就是shard，就是lucene索引</p><p>当一个请求到达一个node时，这个节点就称为上帝节点，根据索引信息，判断请求会被路由到哪个核心节点，以及那个人副本时可用的等信息，在执行搜索前，会讲query语句转化成lucene语句，</p><h3 id="微观"><a href="#微观" class="headerlink" title="微观"></a>微观</h3><p>每个lucene索引里面有很多的segement，可以看作mini-index<br>每个segment里面有很多数据结构，例如</p><ul><li>inverted index（倒排索引）<ul><li>倒排索引包括两部分， 一个是有序的数据字典（包含单词term和它出现的频率），另一个是单词对应的位置，也就是文件id</li><li>当搜索时， 先对搜索内容进行分解，然后在字典里面找到对应的term，从而查找到与搜索相关的文件内容</li><li>所以对于包含查找，搜索成本很大，因为需要遍历倒排表，例如<code>*休闲鞋</code>这样的查找,需要做一些优化</li></ul></li><li>stored field<ul><li>为了包含特定字符串的查找</li></ul></li><li>document values</li><li>cache<ul><li>lucene会尽量缓存，例如会缓存filter条件本身缓存，但是不会对queries缓存（我理解时分词后的query），需要应用自己缓存<br>搜索发生时，lucene会搜索所有的segment，然后把每个segment的搜索结果返回，最后合并返回<br>segment时不可变的，删除时设置标识位，更新时先删除再创建数据</li></ul></li></ul><h2 id="ES持久化"><a href="#ES持久化" class="headerlink" title="ES持久化"></a>ES持久化</h2><p>对于es的写操作</p><ol><li>会根据文档id路由到合适的分片</li><li>对应分片收到来自协调节点的请求后，会将请求写入内存缓冲区，然后定时（默认1s，refresh_interval指定）写入文件系统缓存中，这个过程是refresh</li><li>为了防止意外情况下上述两个系统的数据丢失，es通过translog的机制来保证数据是可靠的，具体的机制是，当接收的请求后，同时写入translog，当从文件系统缓存中写入磁盘后，才会清楚掉，这个过程较flush</li><li>flush过程中，内存中的缓冲将被清除，内容写入一个新段，段的fsync将创建一个新的提交点，将内容刷新到磁盘，旧的translog将删除并开始一个新的，flush的时机时定时触发（30min）或者translog变得太大时。</li><li>未执行refresh时，数据还没有到达segment，所以搜索是搜不到的，但是通过文档id可以查到（从translog）</li></ol><p>值得注意的点</p><ol><li>lucene不保证数据的安全，都是由es使用translog保证</li><li>es写入之后，会向所有副本同步写入，所有副本都写入才算成功</li></ol><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p>对于es的读操作</p><h3 id="getById"><a href="#getById" class="headerlink" title="getById"></a>getById</h3><ol><li>客户端向node发送获取请求</li><li>node根据_id确认分片，分片的副本存在与所有的三个节点上，如果路由到别的节点，查询结束后，会将结果返回给node再返回给客户端</li><li>处理读请求时，会轮询副本达到负载均衡</li><li>文档被检索时，可能主分片的数据还没有同步到副本，但是如果主分片返回了数据，代表同步已经结束<h3 id="search"><a href="#search" class="headerlink" title="search"></a>search</h3></li><li>如果有自定义路由的话，会路由到对应的分片</li><li>初始查询的时候，查询会广播到所有分片，每个分片在本地执行搜索并构建一个匹配文档的大小from+size的优先队列，</li><li>每个分片返回各自优先队列中的所有文档id的排序和协调节点，该节点合并自己的优先队列中来产生一个全局排序的结果列表</li><li>协调节点辨别出哪些文档应该被返回，然后返回给客户端</li></ol><p>值得注意的点</p><ol><li>所有的搜索都分为两阶段，第一个阶段查询匹配到的文档id，第二阶段再查询对应的完整文档</li><li>getById是实时的，search不是，前者会查询translog的值，后者只会查询文件系统缓存中的值，所以只有当refresh后才可以查询到。</li></ol><h2 id="数据并发冲突"><a href="#数据并发冲突" class="headerlink" title="数据并发冲突"></a>数据并发冲突</h2><ol><li>所有操作都会更新版本号，删除也会，软删除。更新操作为删除后，新建一个文档</li><li>搜索时，如果带上版本号，则会检查是否是最新的版本号，如果没有带，则会先读取最新的，然后再读取，进行一个cas</li></ol><h2 id="es选举"><a href="#es选举" class="headerlink" title="es选举"></a>es选举</h2><p>这里说下7.x的raft协议的选举</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>正常情况下，集群中只有一个leader，其余都是follower，follow只是被动的接受请求，不发送请求。<br>引入term任期的概念，每个任期前先进行选举阶段，然后选出一个leader，一个任期只有一个leader，任期结束后，再次进入选举阶段。</p><h3 id="es实现"><a href="#es实现" class="headerlink" title="es实现"></a>es实现</h3><p>es中，每个候选人先不投自己，直接发出requestVote，节点可以投多票，对于平票的情况，es选择让最后当选的称为leader，实现的话，就是当有节点收到集群一半以上的票时，发送消息告诉自己当选，如果它再收到投票信息，则主动退出，让后续节点当选。</p>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线程池与IO多路复用</title>
      <link href="/2022/01/05/xian-cheng-chi-yu-io-duo-lu-fu-yong/"/>
      <url>/2022/01/05/xian-cheng-chi-yu-io-duo-lu-fu-yong/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近对线程池和IO多路复用又一些新的理解， 简单记录下</p></blockquote><h2 id="线程池与IO多路复用"><a href="#线程池与IO多路复用" class="headerlink" title="线程池与IO多路复用"></a>线程池与IO多路复用</h2><p>线程池的技术比较简单，在java中，设置核心线程数，最大线程数，然后提交运行即可，线程池对外是异步的，但是在线程池内部，还是阻塞执行的，当有任何一个线程执行的任务遇到异常情况阻塞时，在高并发的情况下，会对整体造成影响。<br>这里提一下io多路复用，一般说的io多路复用，是指操作系统而言，对于io的处理，有select，poll，epoll等方法，但是这里说的是指在应对io密集型任务时的线程模型，最常见的就是netty的reactor线程模型，核心就是有一个selector进行任务的接收分发，然后具体任务由线程池进行执行，但是不一样的是，每个执行的<br>任务由回调控制，可以及时通知状态，这样线程池就可以增大，容纳更多的线程同时执行。比较典型的应用见okHttp的实现http2Connection，对于每一个链接内部可以开始多个stream进行数据传输，然后内部会启动一个ReaderRunnable线程，轮询链接喜爱所有stream的响应结果，然后激活对应线程。<br>线程池和IO多路复用按理说不是放在一起讨论的，但是很多时候，我们在cpu密集和io密集的场景中都是简单的将任务放到线程池后就不管了，认为并发执行可以解决一切，但是对于部分IO密集的场景，仅仅使用并发不能解决所有问题，这个时候就需要使用io复用结合起来，okhttp就是一个很好的例子。</p><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ol><li><a href="https://www.jianshu.com/p/bd95cf008250" target="_blank" rel="noopener">https://www.jianshu.com/p/bd95cf008250</a></li><li><a href="https://zhuanlan.zhihu.com/p/66563955" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/66563955</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 理论知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 理论知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>make 命令</title>
      <link href="/2020/07/22/make-ming-ling/"/>
      <url>/2020/07/22/make-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>因为没有系统的学过c/c++，对于make一直都是见过没用过，最近很多项目里都用到，这里记录一下1</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="make-的概念"><a href="#make-的概念" class="headerlink" title="make 的概念"></a>make 的概念</h3><p>make即制作，就是“打包”“执行”一个项目，根据makefile里的内容，执行命令。</p><h3 id="makefile"><a href="#makefile" class="headerlink" title="makefile"></a>makefile</h3><p>makefile就是包含一系列的规则的文件，make命令就是根据这些规则来执行的。<br>makefile的格式如下：  </p><pre class="line-numbers language-make"><code class="language-make">targer : prerequisites[tab] command<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中targer是目标，prerequisites是前置条件，第二行必须由tab起，然后接具体的命令<br>其中目标是必需的，其他都是可选的。  </p><h3 id="target"><a href="#target" class="headerlink" title="target"></a>target</h3><p>目标通常是文件名，也可以是一个伪目标，也就是具体操作的名字。<br>文件名是默认的选择，所以如果有一个伪目标的名字等于文件名，命令就不会执行了，所以<br>需要使用<code>.PHONY: 伪目标</code>来声明目标名。</p><h3 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h3><p>前置条件通常是一组文件名，用空格分割，它指定来目标是否重新构建的判断标准，只要有一个前置条件不存在，或者有更新（文件的修改时间），目标都会重建。</p><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><p>每行命令前都必须有一个tab，还可以使用<code>.RECIPEPREFIX = &gt;</code>来指定使用&gt;代替tab键。<br>每一行命令都是单独的shell，所以隔行定义的变量是无法读取的，一个解决办法就是写在一行，用；分割。<br>另一个办法就是在换行前加\转义。<br>还有一种办法就是在命令前加上<code>.ONESHELL</code>  </p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker</title>
      <link href="/2020/04/27/docker/"/>
      <url>/2020/04/27/docker/</url>
      
        <content type="html"><![CDATA[<h1 id="前"><a href="#前" class="headerlink" title="前"></a>前</h1><p>最近做毕业设计，部署前后端以及数据库服务时，用到了docker，现在做的差不多了，正好了记录一下</p><h1 id="正"><a href="#正" class="headerlink" title="正"></a>正</h1><h2 id="docker-镜像"><a href="#docker-镜像" class="headerlink" title="docker 镜像"></a>docker 镜像</h2><h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><ul><li>使用<code>docker images</code>可以查看本地的所有镜像，</li><li>使用<code>docker pull 镜像名：tag</code>可以从远程拉取指定版本的镜像</li><li>使用<code>docker search 镜像名</code> 可以搜索镜像</li><li>使用<code>docker rmi 镜像名</code> 可以删除镜像</li></ul><h3 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h3><ol><li>从已经创建的容器中更新镜像，并且提交这个镜像<br>首先根据一个已有的镜像创建一个容器，然后在这个容器内部进行一定的更改，例如在ubuntu中使用<code>apt-get update</code>,<br>然后使用<br><code>docker commit 容器id 要提交的镜像名</code><br>可以把更新后的容器作为一个镜像提交到本地，<code>docker commit</code>有几个参数：  <ul><li>-m：指定镜像的描述信息</li><li>-a：指定镜像作者</li></ul></li><li>构建镜像<br>这里是使用dockerfile来构建一个自定义的镜像<br>dockerfile的写法放在后面，写好好一个dockerfile以后，就可以使用<br><code>docker build -t 镜像名：tag dockerfile的路径</code><br>来构建一个镜像</li></ol><h3 id="推送镜像"><a href="#推送镜像" class="headerlink" title="推送镜像"></a>推送镜像</h3><p>首先使用<code>docker tag 原镜像名tag 现镜像名tag</code>例如<br><code>docker tag ubuntu:18.04 username/ubuntu:18.04</code><br>来更改镜像tag，然后使用<code>docker push username/镜像名</code>来推送自己的镜像到远程，记得要登陆</p><h2 id="docker-容器"><a href="#docker-容器" class="headerlink" title="docker 容器"></a>docker 容器</h2><h3 id="构建一个docker-容器"><a href="#构建一个docker-容器" class="headerlink" title="构建一个docker 容器"></a>构建一个docker 容器</h3><p>构建docker容器，需要有一个镜像，二者的关系就像是Java中的类和对象一样，一个镜像可以构建多个docker容器，这里使用的命令是：<br><code>docker run -it 镜像名 shell名</code><br>这里的<code>-it</code>是两个参数，<code>-i</code> 是指进入一个交互，<code>-t</code>是指终端进入交互，使用这个命令一个，就可以直接构建docker 容器成功并进入容器内部，通过一个交互式的终端，想要推出这个容器，使用<code>exit</code>.  </p><ul><li>如果想要容器一开始就后台执行，加上<code>-d</code>参数</li><li>使用 –name 来指定容器名</li></ul><p>如果有使用到端口：</p><ul><li>可以使用<code>-P</code>来将容器内部使用的网络端口随即映射到我们使用的主机上。</li><li>使用<code>-p 主机端口：容器内端口</code> 来映射端口<h3 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h3></li><li><code>docker ps</code>可以查看所有正在运行的docker容器,加上<code>-a</code>参数可以查看所有容器</li><li><code>docker start 容器名</code> 可以启动一个已经存在的容器，不进入交互</li><li><code>docker stop 容器名</code> 可以关闭一个已经存在且正在运行的容器</li><li><code>docker restart 容器名</code>可以重启一个正在运行的容器</li><li><code>docker rm 容器名</code> 可以删除一个容器</li><li><code>docker logs 容器id或名</code> 可以查看容器内部的标准输出。</li><li><code>docker top 容器名</code> 可以查看容器内部的进程</li></ul><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><ul><li><code>docker attach 容器id</code> 可以进入一个容器的交互，但是当使用exit退出的时候，容器会关闭  </li><li><code>docker exec -it 容器id</code> 交互shell 可以进入一个容器的交互，但是当退出的时候，不会关闭容器</li></ul><h3 id="导出容器和导入"><a href="#导出容器和导入" class="headerlink" title="导出容器和导入"></a>导出容器和导入</h3><ul><li>使用 <code>docker export 容器id &gt; 快照名.tar</code> 导出一个容器快照</li><li>使用 <code>cat 快照名 | docker import - 镜像名</code></li><li>使用 <code>docker import url</code> 可以远程导入一个镜像</li></ul><h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><ul><li>这里有一个使用过程中的知识点，我的项目需要使用到postgres和pgadmin，二者都是在docker中运行的，但是pgadmin需要连接到postgres，这个时候因为docker容器之间的网络关系，不能使用localhost进行连接，需要使用<br><code>docker inspect 容器名</code><br>查看docker容器 底层信息，看到这个容器运行时的ip，使用这个ip来连接即可。</li></ul><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>上面说到了dockerfile是用来自定义构建镜像的，下面主要说一下怎么写这个dockerfile：</p><ul><li>From 指定镜像并拉取</li><li>Run 运行指令<br>这里一共有两种，一种是shell，另一种是可执行文件，格式如下：<ul><li>RUN &lt;命令行命令&gt;</li><li>RUN [“可执行文件”, “参数1”, “参数2”]<br>这里需要注意一点，每次使用指令，都会让docker 构建镜像的时候多构建一层，所以尽量使用<code>&amp;&amp;</code>来连接指令</li></ul></li><li>COPY<br>复制从主机目录中复制文件或者目录到容器里指定路径。<ul><li>COPY [–chown=<user>:<group>] &lt;源路径1&gt;…  &lt;目标路径&gt;</group></user></li><li>COPY [–chown=<user>:<group>] [“&lt;源路径1&gt;”,…  “&lt;目标路径&gt;”]  </group></user></li></ul></li></ul><p>更多指令请看<a href="https://www.runoob.com/docker/docker-dockerfile.html" target="_blank" rel="noopener">菜鸟教程</a></p><p>这里贴一个部署vue到nginx的dockerfile： </p><pre class="line-numbers language-dockerfile"><code class="language-dockerfile">FROM node:10COPY ./ /appWORKDIR /appRUN npm install && npm run buildFROM nginxRUN mkdir /appCOPY --from=0 /app/dist /appCOPY nginx.conf /etc/nginx/nginx.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="后"><a href="#后" class="headerlink" title="后"></a>后</h1><p>先说到这，下一次要说一下docker compose 和docker的网络和集群问题，深入一下。</p>]]></content>
      
      
      <categories>
          
          <category> 云计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 云计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>终端斗地主--看看源码</title>
      <link href="/2020/02/22/zhong-duan-dou-di-zhu-kan-kan-yuan-ma/"/>
      <url>/2020/02/22/zhong-duan-dou-di-zhu-kan-kan-yuan-ma/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>最近看了一个蛮有意思的项目，是终端的斗地主，适合编程人群上班摸鱼，这里简单说一下整体的设计和客户端和服务端交互的流程</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h3><p>先说一下项目地址：<br><code>https://github.com/ainilili/ratel</code><br>具体的使用和介绍可以在<code>Github</code>中查看<br>这个项目的通信框架使用的是<code>Netty</code>，序列化框架是<code>Protobuf</code>，Netty对于Protobuf支持还是蛮好的，提供相应的处理器。  </p><h3 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h3><p>整体的源码并不多，看下来，还是很佩服作者的整体设计。<br>整体是一个Netty经典的通信方式，先看客户端的，在pipipeline的链式handler中，主要又三部分：  </p><ul><li>心跳检测</li><li>protobuf编解码器</li><li>逻辑处理  </li></ul><p>前两个都是netty自带的，不做详解，主要看逻辑处理的类<code>TransferHandler</code>.<br>在内部重写了三个方法，一个是心跳处理的，一个是异常捕获的，剩下的就是最重要的<code>channelRead</code>，用于接受服务端传来的数据并做处理。<br>这里作者使用了一个顶层的抽象类<code>ClientEventListener</code>，来抽象出客户端的所有行动，内部的<code>call()</code>抽象方法是主要的逻辑处理，各个行动类继承这个类，然后实现call（）方法。<br>内部还有一个<code>get()</code>方法，来通过传来的String code 来映射出相应的处理类，通过反射的方式拿到对应的Class类，然后实例化。<br>这里的实例化的类都是单例的，并不是通过类本身来限制单例，而是通过<code>get()</code>方法内部的判断，将实例化的类放进map，可以保证单例，因为这些具体的处理类都是没有状态的。  </p><p>具体的处理类下面再详细说，有一个我较为疑惑的点，作者封装了一个<code>ChannelUtils</code>的类，用于向客户端和服务端推消息，前面也说了，使用的是<code>protobuf</code>序列化框架，所以这里的类都是由<code>protobuf</code>生成的，客户端和服务端的一样，如下：  </p><pre class="line-numbers language-java"><code class="language-java">    string code <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>    string data <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>    string info <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后是生成对应的<code>Java</code>代码，生成的代码是自带<code>builder</code>的，我的疑惑就是这里<code>ChannelUtils</code>中的<code>pushToServer</code>和<code>pushToClient</code>中的<code>writeAndFlush</code>方法，是向另一端发消息，但是这里发送的是两个封装的消息的builder类，后面的编解码框架中会对builder类进行`build()，但是我并没有很理解这样做的原因，我猜想是为了方便在之后进行一些修改，但是暂时还没有发现，可能是为了扩展吧。  </p><p>服务端的类似，没有很大的区别。</p><h3 id="处理类和交互流程"><a href="#处理类和交互流程" class="headerlink" title="处理类和交互流程"></a>处理类和交互流程</h3><ol><li><p>客户端发送请求，第一次到达服务端会触发<code>channelRegistered</code>方法，这个方法内部，首先拿到ctx中的channel，然后构造一个客户端侧的类<code>ClientSide</code>，然后注册入服务端map，然后向客户端发送两个命令，</p><ul><li><code>CODE_CLIENT_CONNECT</code></li><li><code>CODE_CLIENT_NICKNAME_SET</code><br>第一个是向一个已经连接的通知，客户端并不做反应。<br>第二个是一个昵称的设置，这是客户端会做反应。</li></ul></li><li><p>在<code>CODE_CLIENT_NICKNAME_SET</code>中，对应的是处于客户端的处理类<code>ClientEventListener_CODE_CLIENT_NICKNAME_SET</code>,内部，首先是对服务端传来的数据进行验证（第一次服务端传来为null，后续会传来对客户端昵称的检验结果，暂时就是长度检测，），如果为null，会在客户端本地进行长度检测，长度限制是10，如果不符合，就再次调用该方法，如果符合，会将昵称发送给服务端，命令为<code>CODE_CLIENT_NICKNAME_SET</code>.</p></li><li><p>服务端对应的类为<code>ServerEventListener_CODE_CLIENT_NICKNAME_SET</code>,这个类比较简单，就是对昵称长度进行检测，长度也是10（这里又一个建议，这个长度常量写在common模块中的常量类中比较好）。如果不符合，就发送验证结果到客户端，客户端的处理在上面。如果符合，会修改前面存储的客户端侧类中的昵称值，然后发送命令<code>CODE_SHOW_OPTIONS</code>。</p></li><li><p>客户端的选项类是<code>ClientEventListener_CODE_SHOW_OPTIONS</code>，内部有三个选型，下面会对三个选项分别介绍。</p><ul><li><p>PVP<br>pvp模式是主要的逻辑，客户端选择pvp模式，会向客户端发送命令<code>CODE_SHOW_OPTIONS_PVP</code>到本地，对应的类是<code>ClientEventListener_CODE_SHOW_OPTIONS_PVP</code>,然后是再次提供四个选项，分别是：  </p><ul><li><p><strong>创建房间</strong><br>创建房间会向服务端发送命令<code>CODE_ROOM_CREATE</code>，在服务端的处理类是<code>ServerEventListener_CODE_ROOM_CREATE</code>，内部，主要是创建一个<code>Room</code>类，类的具体字段先不介绍，其中<code>Room</code>的<code>id</code>是一个全局增长的原子变量，然后讲用户侧类中的房间id设为该房间id，然后将<code>Room</code>对象序列化，发送到客户端，命令是<code>CODE_ROOM_CREATE_SUCCESS</code>。客户端不对这个命令反应，只是在客户端显示加入的房间id，然后初始化对局属性。创建房间就这样完类，主要是需要等待其他人进入房间。</p></li><li><p><strong>房间列表</strong><br>房间列表顾名思义，就是获取线上的所有房间列表，这里的发向服务端的命令是<code>CODE_GET_ROOMS</code>，在服务端的类是<code>ServerEventListener_CODE_GET_ROOMS</code>，然后从服务端存储的RoomMap中获取所有房间，构造新的<code>map-RoomList</code>，属性为<br><code>roomId</code>，<code>roomOwner</code>，<code>roomClientCount</code>，<code>roomType</code>四种.<br>然后序列化整个roomList，发往客户端，命令是<code>CODE_SHOW_ROOMS</code>，回到客户端，对应的类为<code>ClientEventListener_CODE_SHOW_ROOMS</code>，内部，就是对房间列表的格式化展示，然后调用本地<code>CODE_SHOW_OPTIONS_PVP</code>命令，供再次选择房间。</p></li><li><p><strong>加入房间</strong><br>加入房间会调用服务端，命令<code>CODE_ROOM_JOIN</code>，服务端对应类<code>ServerEventListener_CODE_ROOM_JOIN</code>，内部，首先根据客户端传来的roomid获取房间，如果房间不存在，返回一个<code>CODE_ROOM_JOIN_FAIL_BY_INEXIST</code>的客户端命令，客户端进行展示结果并返回到选项界面。<br>如果房间存在，首先查看房间人是否已经满了，如果满了，就调用命令<code>CODE_ROOM_JOIN_FAIL_BY_FULL</code>，然后客户端还是进行展示，然后返回选项界面。<br>如果房间未满，则将该用户加入房间，并修改相关存储信息，如果加入后，房间有3个人，开始游戏，调用服务端本地<code>CODE_GAME_STARTING</code>命令，在方法内部，先为房间里的三人分发扑克，扑克的生成方法自行查看，在<code>PokerHelper</code>里面，然后发送房间信息和该玩家的牌到玩家方。<br>如果客户端是玩家，则发送<code>CODE_GAME_STARTING</code>命令到客户端，对应类是<code>ClientEventListener_CODE_GAME_STARTING</code>，内部向玩家展示扑克，然后本地调用抢地主类。<br>如果客户端侧是机器人，且轮到该机器人抢地主，调用服务端机器人抢地主方法。<br>抢地主，有三个选项，分别是</p><ul><li><p>退出房间<br>退出房间调用服务端命令<code>CODE_CLIENT_EXIT</code>，服务端修改房间数据，并发送相同命令到客户端，客户端做提示退出房间，然后返回到选项界面</p></li><li><p>抢地主<br>调用服务端<code>CODE_GAME_LANDLORD_ELECT</code>命令，内部先判断是否有房间，然后将地主牌添加到地主牌里，设置房间地主相关属性，然后将更新后的房间属性和地主额外牌告诉所有人。</p></li><li><p>不抢地主，还是调用<code>CODE_GAME_LANDLORD_ELECT</code>命令，先判断该玩家是否已经是地主，如果是，就进入游戏，如果不是，就更新<code>index</code>，下个玩家决定是否抢地主。<br>如果没有人抢地主，就重新洗牌，开始游戏  </p><p>下面说一下游戏正式开始。决定地主后，由地主确认后，进入<code>CODE_GAME_POKER_PLAY_REDIRECT</code>方法，服务端进行出牌重定向，然后发向客户端，<br>先停在这</p></li></ul></li><li><p><strong>返回</strong><br>返回选项界面</p></li></ul></li><li><p>PVE<br>pve的玩法类似，就是服务端有机器人玩家做操作，处理过程类似。</p></li><li><p>设置</p></li></ul></li></ol><h2 id="后"><a href="#后" class="headerlink" title="后"></a>后</h2><p>对局中还没有分析，是斗地主的逻辑了，下次再分析，总之，这是一个很好的项目，很适合作为Netty的学习项目，很简单，也不长。希望可以去GitHub支持作者。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go Go Go (三)</title>
      <link href="/2019/12/27/go-go-go-san/"/>
      <url>/2019/12/27/go-go-go-san/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>学习笔记,部分图和表格内容都是copy from 《the way to go 》</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><h4 id="声明-初始化-make"><a href="#声明-初始化-make" class="headerlink" title="声明.初始化.make"></a>声明.初始化.make</h4><p><code>var map1 map[keytype] valuetype</code><br><code>var map1 map[string] int</code><br><code>var map1 = make(map[keytype]valuetype)</code><br>key可以是任何可以用 == 或者!= 操作符比较的类型,这里类似java.如果想要使用结构体作为key,需要提供key()和hash()方法<br>不要使用new 来构造map  </p><h4 id="存在和删除"><a href="#存在和删除" class="headerlink" title="存在和删除"></a>存在和删除</h4><p>因为直接使用map索引不存在的key,可以得到值类型的默认值,所以无法直接判断key-value是否存在.<br>使用 <code>v , isPresent = map1[key1]</code><br>isPresent会返回一个bool值,<br>删除直接使用<code>delete(map1,key1)</code></p><h4 id="for-range"><a href="#for-range" class="headerlink" title="for-range"></a>for-range</h4><p><code>for key , value := range map1{}</code><br><code>for _, value := range map1{}</code> 只获得value<br><code>for key := range map1{}</code>只获得key</p><h4 id="map类型的切片"><a href="#map类型的切片" class="headerlink" title="map类型的切片"></a>map类型的切片</h4><p>例子:  </p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Version A:</span>    items <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token operator">:=</span> <span class="token keyword">range</span> items <span class="token punctuation">{</span>        items<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        items<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span>    <span class="token punctuation">}</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"Version A: Value of items: %v\n"</span><span class="token punctuation">,</span> items<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Version B: NOT GOOD!</span>    items2 <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> item <span class="token operator">:=</span> <span class="token keyword">range</span> items2 <span class="token punctuation">{</span>        item <span class="token operator">=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// item is only a copy of the slice element.</span>        item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span> <span class="token comment" spellcheck="true">// This 'item' will be lost on the next iteration.</span>    <span class="token punctuation">}</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"Version B: Value of items: %v\n"</span><span class="token punctuation">,</span> items2<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="map排序"><a href="#map排序" class="headerlink" title="map排序"></a>map排序</h4><p>将key拷贝到一个切片,然后对切片排序,再打印</p><h3 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h3><h4 id="标准库–copy"><a href="#标准库–copy" class="headerlink" title="标准库–copy"></a>标准库–copy</h4><ul><li><code>archive/tar</code> 和 <code>/zip-compress</code>：压缩(解压缩)文件功能。</li><li><code>fmt</code>-<code>io</code>-<code>bufio</code>-<code>path/filepath</code>-<code>flag</code>:  <ul><li><code>fmt</code>: 提供了格式化输入输出功能。  </li><li><code>io</code>: 提供了基本输入输出功能，大多数是围绕系统功能的封装。  </li><li><code>bufio</code>: 缓冲输入输出功能的封装。  </li><li><code>path/filepath</code>: 用来操作在当前系统中的目标文件名路径。  </li><li><code>flag</code>: 对命令行参数的操作。　　</li></ul></li><li><code>strings</code>-<code>strconv</code>-<code>unicode</code>-<code>regexp</code>-<code>bytes</code>:  <ul><li><code>strings</code>: 提供对字符串的操作。  </li><li><code>strconv</code>: 提供将字符串转换为基础类型的功能。</li><li><code>unicode</code>: 为 unicode 型的字符串提供特殊的功能。</li><li><code>regexp</code>: 正则表达式功能。  </li><li><code>bytes</code>: 提供对字符型分片的操作。  </li><li><code>index/suffixarray</code>: 子字符串快速查询。</li></ul></li><li><code>math</code>-<code>math/cmath</code>-<code>math/big</code>-<code>math/rand</code>-<code>sort</code>:  <ul><li><code>math</code>: 基本的数学函数。  </li><li><code>math/cmath</code>: 对复数的操作。  </li><li><code>math/rand</code>: 伪随机数生成。  </li><li><code>sort</code>: 为数组排序和自定义集合。  </li><li><code>math/big</code>: 大数的实现和计算。  　　</li></ul></li><li><code>container</code>-<code>/list-ring-heap</code>: 实现对集合的操作。  <ul><li><code>list</code>: 双链表。</li><li><code>ring</code>: 环形链表。<br>下面代码演示了如何遍历一个链表(当 l 是 <code>*List</code>)：<pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">for</span> e <span class="token operator">:=</span> l<span class="token punctuation">.</span><span class="token function">Front</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> e <span class="token operator">!=</span> <span class="token boolean">nil</span><span class="token punctuation">;</span> e <span class="token operator">=</span> e<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//do something with e.Value</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul></li><li><code>time</code>-<code>log</code>:  <ul><li><code>time</code>: 日期和时间的基本操作。  </li><li><code>log</code>: 记录程序运行时产生的日志,我们将在后面的章节使用它。</li></ul></li><li><code>encoding/json</code>-<code>encoding/xml</code>-<code>text/template</code>:<ul><li><code>encoding/json</code>: 读取并解码和写入并编码 JSON 数据。  </li><li><code>encoding/xml</code>:简单的 XML1.0 解析器,有关 JSON 和 XML 的实例请查阅第 12.9/10 章节。  </li><li><code>text/template</code>:生成像 HTML 一样的数据与文本混合的数据驱动模板（参见第 15.7 节）。  </li></ul></li><li><code>net</code>-<code>net/http</code>-<code>html</code>:（参见第 15 章）<ul><li><code>net</code>: 网络数据的基本操作。  </li><li><code>http</code>: 提供了一个可扩展的 HTTP 服务器和基础客户端，解析 HTTP 请求和回复。  </li><li><code>html</code>: HTML5 解析器。  </li></ul></li><li><code>runtime</code>: Go 程序运行时的交互操作，例如垃圾回收和协程创建。  </li><li><code>reflect</code>: 实现通过程序运行时反射，让程序操作任意类型的变量。<br><code>exp</code> 包中有许多将被编译为新包的实验性的包。它们将成为独立的包在下次稳定版本发布的时候。如果前一个版本已经存在了，它们将被作为过时的包被回收。然而 Go1.0 发布的时候并不包含过时或者实验性的包。</li></ul><h4 id="正则"><a href="#正则" class="headerlink" title="正则"></a>正则</h4><p>一个例子来学吧,说得多记不住  </p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token punctuation">(</span>    <span class="token string">"fmt"</span>    <span class="token string">"regexp"</span>    <span class="token string">"strconv"</span><span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//目标字符串</span>    searchIn <span class="token operator">:=</span> <span class="token string">"John: 2578.34 William: 4567.23 Steve: 5632.18"</span>    pat <span class="token operator">:=</span> <span class="token string">"[0-9]+.[0-9]+"</span> <span class="token comment" spellcheck="true">//正则</span>    f <span class="token operator">:=</span> <span class="token keyword">func</span><span class="token punctuation">(</span>s <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token builtin">string</span><span class="token punctuation">{</span>        v<span class="token punctuation">,</span> <span class="token boolean">_</span> <span class="token operator">:=</span> strconv<span class="token punctuation">.</span><span class="token function">ParseFloat</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> strconv<span class="token punctuation">.</span><span class="token function">FormatFloat</span><span class="token punctuation">(</span>v <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'f'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> ok<span class="token punctuation">,</span> <span class="token boolean">_</span> <span class="token operator">:=</span> regexp<span class="token punctuation">.</span><span class="token function">Match</span><span class="token punctuation">(</span>pat<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token function">byte</span><span class="token punctuation">(</span>searchIn<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span><span class="token string">"Match Found!"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    re<span class="token punctuation">,</span> <span class="token boolean">_</span> <span class="token operator">:=</span> regexp<span class="token punctuation">.</span><span class="token function">Compile</span><span class="token punctuation">(</span>pat<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//将匹配到的部分替换为"##.#"</span>    str <span class="token operator">:=</span> re<span class="token punctuation">.</span><span class="token function">ReplaceAllString</span><span class="token punctuation">(</span>searchIn<span class="token punctuation">,</span> <span class="token string">"##.#"</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//参数为函数时</span>    str2 <span class="token operator">:=</span> re<span class="token punctuation">.</span><span class="token function">ReplaceAllStringFunc</span><span class="token punctuation">(</span>searchIn<span class="token punctuation">,</span> f<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span>str2<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="锁和sync包"><a href="#锁和sync包" class="headerlink" title="锁和sync包"></a>锁和sync包</h4><p>表面上暂时当做java中的synchronized关键字来看<br>互斥锁 : <code>sync.Mutex.Lock()</code> , <code>sync.Mutex.Unlock()</code><br>读写锁 : <code>sync.RWMutex.RLock()</code>读锁 , <code>sync.RWMutex.Lock()</code>写锁 </p><h4 id="精密计算-big包"><a href="#精密计算-big包" class="headerlink" title="精密计算 big包"></a>精密计算 big包</h4><p>一个例子 :  </p><pre class="line-numbers language-go"><code class="language-go"><span class="token comment" spellcheck="true">// big.go</span><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token punctuation">(</span>    <span class="token string">"fmt"</span>    <span class="token string">"math"</span>    <span class="token string">"math/big"</span><span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Here are some calculations with bigInts:</span>    im <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewInt</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>MaxInt64<span class="token punctuation">)</span>    in <span class="token operator">:=</span> im    io <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewInt</span><span class="token punctuation">(</span><span class="token number">1956</span><span class="token punctuation">)</span>    ip <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewInt</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    ip<span class="token punctuation">.</span><span class="token function">Mul</span><span class="token punctuation">(</span>im<span class="token punctuation">,</span> in<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Add</span><span class="token punctuation">(</span>ip<span class="token punctuation">,</span> im<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Div</span><span class="token punctuation">(</span>ip<span class="token punctuation">,</span> io<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"Big Int: %v\n"</span><span class="token punctuation">,</span> ip<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Here are some calculations with bigInts:</span>    rm <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewRat</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>MaxInt64<span class="token punctuation">,</span> <span class="token number">1956</span><span class="token punctuation">)</span>    rn <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewRat</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1956</span><span class="token punctuation">,</span> math<span class="token punctuation">.</span>MaxInt64<span class="token punctuation">)</span>    ro <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewRat</span><span class="token punctuation">(</span><span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>    rp <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewRat</span><span class="token punctuation">(</span><span class="token number">1111</span><span class="token punctuation">,</span> <span class="token number">2222</span><span class="token punctuation">)</span>    rq <span class="token operator">:=</span> big<span class="token punctuation">.</span><span class="token function">NewRat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    rq<span class="token punctuation">.</span><span class="token function">Mul</span><span class="token punctuation">(</span>rm<span class="token punctuation">,</span> rn<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Add</span><span class="token punctuation">(</span>rq<span class="token punctuation">,</span> ro<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Mul</span><span class="token punctuation">(</span>rq<span class="token punctuation">,</span> rp<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"Big Rat: %v\n"</span><span class="token punctuation">,</span> rq<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/* Output:Big Int: 43492122561469640008497075573153004Big Rat: -37/112*/</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="自定义包和可见性"><a href="#自定义包和可见性" class="headerlink" title="自定义包和可见性"></a>自定义包和可见性</h4><p>导入包 :<br><code>import &quot;包的路径或者URL地址&quot;</code><br>例如 : <code>import &quot;github.com/org1/pack1&quot;</code> ,  <code>import &quot;./pack1/pack1&quot;</code>  </p><p>当时用 <code>.</code>作为包的别名时,你可以不通过包名来使用其中的项目  </p><p>使用<code>go install</code> 安装外部包  </p><h3 id="结构体和方法"><a href="#结构体和方法" class="headerlink" title="结构体和方法"></a>结构体和方法</h3><h4 id="结构体定义"><a href="#结构体定义" class="headerlink" title="结构体定义"></a>结构体定义</h4><p>一般方式 : </p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">type</span> identifier <span class="token keyword">struct</span> <span class="token punctuation">{</span>    field1 type1    field2 type2    <span class="token operator">...</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用 <code>t := T(v1,v2...)</code> 创建结构体类型变量<br>使用new 来给一个结构体分配内存,返回的是已分配内存的指针 : <code>var t *T = new(T)</code><br>此时 <code>.</code> 被称为选择器,无论是结构体类型还是结构体指针,都可以使用</p><h4 id="使用工厂方法创建结构体实例"><a href="#使用工厂方法创建结构体实例" class="headerlink" title="使用工厂方法创建结构体实例"></a>使用工厂方法创建结构体实例</h4><p>可以使用go文件对于可见性的规则强制调用方使用工厂方法创建结构体实例</p><h4 id="结构体不能使用make-map不能使用new"><a href="#结构体不能使用make-map不能使用new" class="headerlink" title="结构体不能使用make, map不能使用new"></a>结构体不能使用make, map不能使用new</h4><h4 id="带标签的结构体"><a href="#带标签的结构体" class="headerlink" title="带标签的结构体"></a>带标签的结构体</h4><p>结构体中的字段除了名字和类型外,还有一个可选的标签,但是不可以在一般的编程中使用,只能用反射获得  </p><h4 id="匿名字段"><a href="#匿名字段" class="headerlink" title="匿名字段"></a>匿名字段</h4><p>结构体内可以有没有名字的字段,但是必须有类型,如果是类型是结构体,是组合的意味</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>Go中的方法并不是属于类的,当然Go就没有类,但是go的方法有一个接受者的东西,这个东西客户以是任何类型,除了指针类型.<br>一般的定义方式 : <code>func (recv receiver_type) methodName(parameter_list) (return_value_list) { ... }</code>  </p><p>recv 就像是java中的this或python中的self,所以方法不用写在结构体内部,只需要的recv处标识这个函数的接受者是谁就行了.  </p><h4 id="关于方法和类型还有比较麻烦的一些东西"><a href="#关于方法和类型还有比较麻烦的一些东西" class="headerlink" title="关于方法和类型还有比较麻烦的一些东西"></a>关于方法和类型还有比较麻烦的一些东西</h4>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go Go Go (二)</title>
      <link href="/2019/12/26/go-go-go-er/"/>
      <url>/2019/12/26/go-go-go-er/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>一些表格图片copy from 《the way to go》</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="控制结构"><a href="#控制结构" class="headerlink" title="控制结构"></a>控制结构</h3><p>说点值得注意的,这种基础的东西各个语言都差不多  </p><ul><li>返回异常相关<br><code>value,err := pack.Function(param)</code> ,然后对err进行判断处理</li><li>for循环不需要()</li><li>没有while 和 do while</li><li>可以使用 <code>for condition {}</code>代替while</li><li>for range<br>一般的形式是<code>for ix,val := range coll {}</code> ix是索引,val是集合中对应索引的值拷贝,如果val是指针,也是拷贝.coll是一个可迭代的变量</li><li>标签和goto<br>标签就是在某一行,以一个单词和:结尾,标识一个运行位置,可以使用contine和goto跳转到该位置,同时可以配合break跳出多重循环.这东西不建议使用</li></ul><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><ul><li>函数声明,java中没有的,就是在一个函数中,只给出函数名和函数签名,而不需要函数体,然后在外部定义</li><li>Go不允许函数重载</li><li>函数参数可以没有名字</li><li>允许多值返回</li><li>值传递和引用传递就是c和java那一套</li><li>命名返回值 : 如果返回值被命名,就不用在返回处再写了,直接return</li><li>空白符/占位符: 用来抛弃一些不需要的值,</li><li>变长参数 : <code>func myFunc(a,b,arg ... int){}</code></li><li>defer : 类似finally,允许我们推迟到函数返回之前才执行词句语句,功能也就是finally的,释放资源什么的,值得一提的是,一个函数中可以有多个,执行顺序是栈,先进后出</li></ul><h4 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h4><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>close</td><td>用于管道通信</td></tr><tr><td>len、cap</td><td>len 用于返回某个类型的长度或数量（字符串、数组、切片、map 和管道）；cap 是容量的意思，用于返回某个类型的最大容量（只能用于切片和 map）</td></tr><tr><td>new、make</td><td>new 和 make 均是用于分配内存：new 用于值类型和用户定义的类型，如自定义结构，make 用于内置引用类型（切片、map 和管道）。它们的用法就像是函数，但是将类型作为参数：new(type)、make(type)。new(T) 分配类型 T 的零值并返回其地址，也就是指向类型 T 的指针。它也可以被用于基本类型：<code>v := new(int)</code>。make(T) 返回类型 T 的初始化之后的值，因此它比 new 进行更多的工作 <strong>new() 是一个函数，不要忘记它的括号</strong></td></tr><tr><td>copy、append</td><td>用于复制和连接切片</td></tr><tr><td>panic、recover</td><td>两者均用于错误处理机制</td></tr><tr><td>print、println</td><td>底层打印函数，在部署环境中建议使用 fmt 包</td></tr><tr><td>complex、real imag</td><td>用于创建和操作复数</td></tr></tbody></table><h4 id="函数做参数"><a href="#函数做参数" class="headerlink" title="函数做参数"></a>函数做参数</h4><p><code>func callback(f func(int , int )){}</code></p><h4 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h4><p>这鬼东西我真的是一直记不住,因为一直能看到,但是从来没用过<br>匿名函数, <code>func(x,y int) int {return x + y}</code> 不能单独存在,可以被赋予某个变量,或者直接调用<code>func(x,y int) int {return x + y}(3,4)</code><br>匿名函数被称为闭包,定义没意义  </p><h4 id="闭包应用-将函数作为返回值"><a href="#闭包应用-将函数作为返回值" class="headerlink" title="闭包应用,将函数作为返回值"></a>闭包应用,将函数作为返回值</h4><p><code>func Add() (func(b int) int)</code>该函数不接受任何参数,但是返回一个函数<code>func(b int)int</code>的函数<br>此时,如果我们在Add中定义一个变量,同时在返回的函数中使用,该变量的值就可以被保存下来,例子</p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token string">"fmt"</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> f <span class="token operator">=</span> <span class="token function">Adder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">" - "</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">" - "</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">Adder</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token builtin">int</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> x <span class="token builtin">int</span>    <span class="token keyword">return</span> <span class="token keyword">func</span><span class="token punctuation">(</span>delta <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token builtin">int</span> <span class="token punctuation">{</span>        x <span class="token operator">+=</span> delta        <span class="token keyword">return</span> x    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回值<code>1 - 21 - 321</code></p><h3 id="数组和切片"><a href="#数组和切片" class="headerlink" title="数组和切片"></a>数组和切片</h3><h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h4><p>声明 : <code>var identifier [len]type</code><br>创建<br><code>var a2 = new (5[]int)</code> a2的类型是*[5]int,<br><code>a := [...]string{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;}</code> 类似java的<code>string[] a = {...}</code>,当然…可以替换为固定的长度<br>还可以通过<code>var arrkeyvalue = [5]string{3:&quot;chris&quot;,4:&quot;ron&quot;}</code>来给特定索引的位置赋值,其他都是默认值</p><h4 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h4><ul><li><p>切片是对数组一个连续片段的引用,其实就是python中的list的[]语法  </p></li><li><p>切片是一个长度可变的数组,提供了计算容量的函数cap()可以测量出切片最长可以达到多少: 如果s是一个切片,cap(s)就是从s[0]到数组末尾的数组长度.  </p></li><li><p>切片声明 : <code>var identifier []type = arr[start:end]</code>,从arr的start开始,到end为止,不包括end.如果start和end为空([:]),代表整个数组,<br>例子: (copy的)<br><img src="1.png" alt>  </p></li><li><p>使用make创建一个切片: <code>slice := make(type[],len)</code>,此时cap(slice) == len(slice) == 10 ;<br>还可以使用<code>slice := make(type[] ,len,cap)</code>  </p></li><li><p>这里有一个make和new的差别:<br><img src="2.png" alt>  </p></li><li><p>切片重组<br>扩容一位: <code>s = s[0:len(s)+1]</code></p></li><li><p>切片复制和追加<br>copy(s_to,s_from), 将s_from的数据复制到s_to<br>append(s,x…T) , 将数据添加到切片s中</p></li><li><p>字节切片<br>参照python,实际是字节数组</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go Go Go (一)</title>
      <link href="/2019/12/26/go-go-go-yi/"/>
      <url>/2019/12/26/go-go-go-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>还是学一下,这里简单记录一下</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><p>现在用的开发机是win10,就在上面安装了,不过这种安装真的没什么可以说的,尤其是win,下载msi,next下去就可以了,<code>GoROOT</code>和<code>GOPATH</code>都会自己配置好的,然后下载一个GoLand做IDE,(实在不喜欢用vscode).settings里配置一下<code>GOROOT</code> 和 <code>GOPATH</code>(不出意外也会自己配置的),然后开发</p><h3 id="包"><a href="#包" class="headerlink" title="包"></a>包</h3><p>创建一个项目后,在项目下还要创建一个main包,然后再main包下创建.go文件,写个<code>hello world</code>,这里说一下main包,应该是go语言要求的main包才是整个项目的入口,所以一定要有一个package main的go文件,然后写一个main函数.<br><code>import</code> : 通常写法就是 <code>import &quot;package name&quot;</code>,其中可以对包重命名,写在<code>package name</code>前就可以了,例如: <code>import fm &quot;fmt&quot;</code><br><code>可见性规则</code> : 比较好玩,当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头,就是<code>public</code>的,对外可见的,当是小写字符开头,就是private,对外不可见的.<br>当你导入一个包但是不用的话,会报错.</p><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>和java相同</p><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><p>常量定义格式:<br><code>const identifier [type] = value</code><br>常量的类型只能是bool,数字和字符串.<br>类型可以省,常量的值必须是在编译期就确定的.但可以使用内置函数</p><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>变量定义格式:<br><code>var identifier type</code><br><code>var identifier [type] = value</code><br>局部变量可以用<code>a := 1</code>这样来声明</p><p>变量被声明后会被赋予初值,int=0,float=0.0,bool=false,string=空字符串””,指针=nil<br>占位符用法,并不像scala中一样,这里用来抛弃赋值,<code>_,b = 1,2</code></p><h4 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h4><p>没什么特殊的,值得一说的就是同名变量,内部的同名变量会覆盖外部的  </p><h3 id="值类型和引用类型"><a href="#值类型和引用类型" class="headerlink" title="值类型和引用类型"></a>值类型和引用类型</h3><p>java和c那一套</p><h3 id="基本类型和运算符"><a href="#基本类型和运算符" class="headerlink" title="基本类型和运算符"></a>基本类型和运算符</h3><p>Go是强类型语言,不支持隐式转换</p><h4 id="布尔bool"><a href="#布尔bool" class="headerlink" title="布尔bool"></a>布尔bool</h4><p>没什么好说的</p><h4 id="数字类型和float"><a href="#数字类型和float" class="headerlink" title="数字类型和float"></a>数字类型和float</h4><ul><li>int<br>  有int,uint,uintptr,前两个在32位系统上,使用32位,64位则是64位,后一个长度被设定为存放一个指针即可<br>  有符号整数<ul><li><code>int8（-128 -&gt; 127）</code></li><li><code>int16（-32768 -&gt; 32767）</code></li><li><code>int32（-2,147,483,648 -&gt; 2,147,483,647）</code></li><li><code>int64（-9,223,372,036,854,775,808 -&gt; 9,223,372,036,854,775,807）</code><br>无符号整数：</li><li><code>uint8（0 -&gt; 255）</code></li><li><code>uint16（0 -&gt; 65,535）</code></li><li><code>uint32（0 -&gt; 4,294,967,295）</code></li><li><code>uint64（0 -&gt; 18,446,744,073,709,551,615）</code></li></ul></li><li>float<br>  只有float32和float64<ul><li><code>float32（+- 1e-45 -&gt; +- 3.4 * 1e38）</code></li><li><code>float64（+- 5 * 1e-324 -&gt; 107 * 1e308）</code></li></ul></li></ul><p>值得注意的: </p><ul><li>尽量使用float64,因为math包返回的都是float64</li><li>Go中不允许不同类型混合使用赋值(包括int 和 int32),但是常量可以赋值到变量(不限类型)</li></ul><h4 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h4><p>整除 : /<br>取余 : % </p><h4 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h4><p>使用<code>type alias int</code>其中alias就是int的别名</p><h4 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h4><p>byte是uint8的别名,声明的时候也是和java一样用单引号,<code>var c byte = &#39;A&#39;</code></p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>Go中的字符串的字符根据需要占用1-4个字节  </p><h4 id="字符串比较"><a href="#字符串比较" class="headerlink" title="字符串比较"></a>字符串比较</h4><p>比较运算符(==,!=,&lt;,&gt; …),都是把内存中的字符串按字节比较</p><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><p>类似python吧,使用[]来索引,从0开始</p><h4 id="字符串拼接"><a href="#字符串拼接" class="headerlink" title="字符串拼接"></a>字符串拼接</h4><p>就是<code>+</code>,但是跟java中类似,并不高效,更好的办法是使用函数strings.Join()或者字节缓冲(bytes.Buffer)</p><h3 id="函数小解"><a href="#函数小解" class="headerlink" title="函数小解"></a>函数小解</h3><p>基本格式 :<br><code>func functionName()</code><br>括号内部可以写参数,但是类型在参数名后(和java相反),并且后续的 <code>{</code> 不能放在下一行,必须紧跟在声明后面.<br>符合规范的声明格式:<br><code>func functionName(parameter_list) (return_value_list) {   …}</code><br>其中<br>参数列表中,如果一系列参数的类型相同,可以写在一起,例如:<code>a,b int , c string</code><br><code>return_value_list</code>一般的格式是<code>变量名 类型</code>但是可以省略变量名.  </p><h4 id="特殊-内置函数"><a href="#特殊-内置函数" class="headerlink" title="特殊/内置函数"></a>特殊/内置函数</h4><ul><li>init函数,这个函数在每个包完成初始化后自动执行,优先级比main函数高,用于变量初始化</li></ul><h3 id="指針"><a href="#指針" class="headerlink" title="指針"></a>指針</h3><p>程序在内存中存储它的值,每个内存快有一个地址,通常用十六进制数表示<br>取地址符是 <code>&amp;</code>,放在一个变量前使用<br>当我们想要存储一个地址时,就需要指针了,这是一个特殊的数据类型,使用<code>*</code>加类型表示执行该类型的指针,例如<code>*int</code>表示指向int的指针.<br>声明一个指针 :<br><code>var p *int</code><br>内存地址的大小和所在机器的位数有关,与指向的值得大小无关.<br><code>*</code>也可以被放在指针变量名前,就可以取出这个指针指向的地址存储的值,当然可以这样使用:`var == *(&amp;var)<br>在Go中,指针是不允许运算的</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次工程</title>
      <link href="/2019/12/22/ji-yi-ci-gong-cheng/"/>
      <url>/2019/12/22/ji-yi-ci-gong-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="前"><a href="#前" class="headerlink" title="前"></a>前</h2><p>已经来工作两周了，新人来这边不是一开始就上手开发的，是要做一个新人任务的，也就是一个开发任务，我接到的任务是一个做一个简易的聊天系统，<br>功能包括登录注册，好友，即时聊天，群聊等功能，其实好久没有好好写代码了，得有个2个多月，一开始遇到的麻烦也挺多的，不过也慢慢解决了。</p><h2 id="正"><a href="#正" class="headerlink" title="正"></a>正</h2><h3 id="系统相关"><a href="#系统相关" class="headerlink" title="系统相关"></a>系统相关</h3><p>一开始搭环境就是个问题，不再像以前一样写代码是随便写，首先要求是微服务，每个服务模块又必须使用多模块开发，gradle做包管理，因为分了多模块而且使用了springboot，找不到bean的问题经常发生，虽然都是小问题，但是还是比较麻烦的。</p><p>然后就是系统的设计，按照功能划分服务，就分为三个模块：  </p><ul><li>用户模块，负责登录，注册，验证用户，创建群聊等功能</li><li>好友模块，负责好友关系的建立，删除，好友列表，群列表的维护等</li><li>聊天模块，负责消息的存储，同步等，</li></ul><p>这三个是服务模块，本来还应该有一个群聊模块，但是因为赶得紧，就凑到这个三个模块里面了，还有一个就是对外提供服务的server模块了，提供的方式也就是springboot的那一套，server需要调用上面三个服务模块，这里就是RPC调用了，用的是dubbo，没有很深入，就是简单的调用了一下。</p><p>最后就是一个ORM的相关了，很久之前，我觉得原生的jpa那套很好，因为什么都不用写，声明个接口就行了，但是后来发现还是自己写sql好一点，虽然jpa也可以，但是还是mybatis的支持更好一点。</p><h3 id="IM"><a href="#IM" class="headerlink" title="IM"></a>IM</h3><p>说起IM还是比较有趣的，说起IM就是聊天，实现的原理也很简单，就是收到一个人的消息，服务端存储，然后推到另一边，但是真正实现起来确实问题多多，有未读已读的问题，有最近联系人的更新，还有很多前端控件的更新，这或许也是使用websocket的原因吧。</p><h3 id="自己"><a href="#自己" class="headerlink" title="自己"></a>自己</h3><p>这两周的开发，还是认识到自己的诸多问题，最重要的就是太浅薄了，无论是技术上还是对技术的认知上，很多学到的东西并不能运用，单纯的就是个知识摆在那里，以为自己知道很多解决办法，但遇到问题，确很少能单纯的靠自己就解决，写代码时也许是因为比较急吧，很多规范都没有注意，驼峰和下划线混杂的用，也写了很多脑残代码，甚至写完自己都不想去看，所以听到老大要抽空看一下我的代码，感觉相当慌，毕竟是自己都不愿意回头看的。</p><h2 id="后"><a href="#后" class="headerlink" title="后"></a>后</h2><p>因为公司的保密原因，不能上传代码，所以只能靠文字简单的说一下，其实这篇博客对别人没有什么意义，纯粹是自己做个总结，也算是作为工作开始的记录，大概就是这样，不多说了。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再看看 Git</title>
      <link href="/2019/12/02/zai-kan-kan-git/"/>
      <url>/2019/12/02/zai-kan-kan-git/</url>
      
        <content type="html"><![CDATA[<h2 id="前情"><a href="#前情" class="headerlink" title="前情"></a>前情</h2><p>马上要工作了,Git这东西还是需要重新再看一下,顺便记录在这</p><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p><code>git init</code> – 初始化仓库<br>如果初始化成功,当前目录下会生成一个.git的隐藏文件夹,这个文件夹存储这管理当前目录内容所需的仓库数据.在Git中,我们将这个目录称为<code>附属于该仓库的工作树</code>.文件的编辑等操作在工作树中记性,将记录到仓库中,从此管理文件的历史快照.如果要将文件恢复到原先的状态,可以从仓库中调取之前的快照,在工作树中打开.<br>但是一般我都不会使用这个命令,而是直接从线上仓库<code>git clone</code>下来.</p><p><code>git status</code>  – 查看仓库的状态<br>可以看到当前的分支,提交状态等信息</p><p><code>git add</code> – 向暂存区中添加文件<br>如果想要Git管理你的文件,就需要通过git add 将文件添加到暂存区,暂存区是提交前的一个临时区域.<br>如果要添加指定文件,在add 后加文件名,如果要添加所有文件,就使用<code>.</code></p><p><code>git commit</code>  –  保存仓库的历史记录<br>git commit命令可以将当前暂存区中的文件实际保存在仓库的历史记录中,通过这些记录,我们就可以在工作树中复原文件.<br>通常,需要使用<code>-m</code>来添加本次提交的说明.或者直接git commit,然后启动编辑器具体添加说明.</p><p><code>git log</code>  – 查看提交日志<br>该命令可以查看以往仓库的调教的日志,包括可以查看什么时候提交了合并,以及操作前后有怎样的差别.<br>使用<code>--pretty=short</code>可以简化日志信息<br>在命令后加指定文件名,可以只查看相关的文件的提交信息<br>使用<code>-p</code>,可以查看提交前后差异  </p><p><code>git diff</code>  – 查看更改前后差别<br>该命令可以查看工作树,暂存区,最新提交之间的差别, 如果是查看本地仓库和远程仓库的区别,就在后面加<code>origin branchname</code></p><p><code>git push</code> – 推送到远程仓库<br>一般如果我们是<code>git clone</code>下来的文件,可以直接push,当然后面需要加<code>origin master</code>也就是远程的master分支,当然也可以切换到相关的分支推送.</p><p><code>git pull</code> –获取远程最新的分支内容<br>当本地内容不是最新的内容时,为了避免提交时的矛盾,可以先获取远程仓库中的最新内容.后续也可以加<code>origin master</code>master可以替换成其他分支名</p><p><code>git reset</code> –返回到之前的版本<br>一般是<code>git reset HEAD</code>就可以回到head,但是如果想回到之前固定的版本,使用<code>git reset --soft/--hard</code> 后接固定版本的commit hash值,–soft和–hard的区别是是否修改暂存区和工作目录</p><h2 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h2><p>分支并不难,难的是多分支开发过程中的冲突问题</p><p><code>git branch</code> – 查看分支<br><code>git checkout -b</code> – 创建并切换分支<br><code>git branch</code> – 创建分支<br><code>git checkout</code> – 切换分支<br>切换分支前一定要push当前分支的内容,否则会报错<br><code>git checkout -</code> – 切换回上一个分支<br><code>git merge</code> – 合并分支内容<br>一般的合并到master分支,是在远程仓库的UI界面进行,提出一个mq,然后由管理者合并,这里是命令行的本地合并内容.本地合并,后面加要合并的分支,意为将后面的分支合并到当前分支中.<br><code>git reset</code> – 回溯历史版本<br>后续是<code>--hard 哈希值</code>,所谓哈希值,是Git为每一个提交快照的一个加密哈希,在日志中可以看到</p><h2 id="消除冲突"><a href="#消除冲突" class="headerlink" title="消除冲突"></a>消除冲突</h2><p>这是比较重要的一个点,仔细说一下  </p><ol><li>修改不同的文件<br>如果用户user1和用户user2各自的本地提交中修改了不同的文件,当一个用户将改动推送的远程仓库后,另一个用户推送就会遇到推送错误,需要先合并后再推送,因为两个用户修改的是不同文件,所以合并不会遇到麻烦.</li><li>修改相同文件的不同区域<br>当用户user1和user2在本地提交中修改相同的文件,但是修改的是不同位置时,则两个用户的提交仍可以成功合并.<br>具体的从操作是:user1将自己的修改推送到远程仓库后,user2也对一个文件不同位置进行修改,commit后,fetch远程的最新内容,然后merge,合并不同的分之内容,最后再push</li><li>相同位置不同内容<br>首先我们可以使用git merge,然后产生冲突文件会有修改的内容,<code>=======</code>上面的内容,是当前HEAD的内容,以下的内容是合并的目标文件的内容,然后我们在编辑器中将内容合并,然后再合并提交</li><li>工作后的总结<br>如果发生冲突,回到之前的版本,然后再修改,再提交<h2 id="后"><a href="#后" class="headerlink" title="后"></a>后</h2>暂时先这样,等遇到具体的情况再补充</li></ol>]]></content>
      
      
      <categories>
          
          <category> 开发问题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日语基本语法一</title>
      <link href="/2019/11/08/ri-yu-ji-ben-yu-fa-yi/"/>
      <url>/2019/11/08/ri-yu-ji-ben-yu-fa-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然我已经放弃了考级,哈哈,但是即使是对于一般口语,也是需要掌握一些基本的语法,主要是动词的变形.</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="整体变形图"><a href="#整体变形图" class="headerlink" title="整体变形图"></a>整体变形图</h3><p><img src="1.jpg" alt="五段一段"><br><img src="2.jpg" alt="カ サ"></p><h3 id="未然形"><a href="#未然形" class="headerlink" title="未然形"></a>未然形</h3><p>这一大类的变形叫做未然性,顾名思义是没有发生的状态。<br>动词的未然性有很多用法,但是还是有一个最初的变形,然后才是后续的接续.<br>五段动词的原型是词干+う列的基本音.然后未然性的变形就是将う列变成あ列的对应行的音.<br>一段动词的原型是词干+る ，然后未然性就是将 る 去掉。<br>カ行或サ行 变换比较复杂，看上图<br>然后在后面接后续.<br>常见的后续:  </p><ul><li>后接 <code>ない</code> 表示否定</li><li>后接 <code>なければならない</code> 表示必须</li><li>后接 <code>なければいけない</code> 表示必然</li><li>后接 <code>ねばならない</code> 表示义务</li><li>后接 <code>せる</code>・ <code>させる</code> 表示使役</li><li>后接 <code>れる　.　られる</code> 表示被动、可能、尊敬、自发</li></ul><p>其中未然性还包括一种变形，表示意志，就是将う列变成お列的对应行的音，然后后续<code>う　.　よう</code>表示意志。</p><h4 id="例句"><a href="#例句" class="headerlink" title="例句"></a>例句</h4><ol><li>表否定：　 <code>見るだけで買わない</code>（只看不买）</li><li>表必须：　<code>君が行かなければいけない</code>（你必须去）</li><li>表示使役：　<code>学生に作文を書かせる</code> （让学生写作文）</li><li>表示被动：　<code>お金お泥棒にこっより盗まれた</code> （钱被小偷偷光了）</li><li>表示可能：　<code>英語が読まれる</code> （能看懂英语）</li><li>表示尊敬：　 <code>先生の書かれた論文を拝読板しました</code> （拜读了老师撰写的论文）</li><li>表示意志：   <code>バスで行こう</code>　（坐公交车去吧)</li></ol><h3 id="连用形"><a href="#连用形" class="headerlink" title="连用形"></a>连用形</h3><p>日语动词的连用形有两种，一种ます形，另一种て连用形<br>五段动词将う段的假名改成该行的い假名，一段动词将最后一个假名的る去掉，サ变动词的连用形是し，カ变动词的连用形是き。  </p><p>动词连用形后续ます构成动词现在是和将来时的敬体。现在时表示经常性、习惯性的动作及恒常不变的事情，将来时表示未来的动作或作用，并含有将要进行该动作的意志。ます的否定式是<code>ません</code>，过去肯定是<code>ました</code>，过去否定式是<code>ませんでしだ</code>。</p><p><code>私は友達に手紙を書きます。</code> (我给朋友写信)</p><p>动词后续<code>たい　・　たがる</code>表示第一人称自身内在的愿望，第三人称显露在外表或行动上的愿望，后续样态助动词そうだ表示样子，情形，状态，后续并列动词ながら，表示两个动作同时进行。  </p><p><code>私は水が飲みたいです</code> (我想喝水)</p><p>动词后续<code>て ・　た</code>时的连用形，其活用规则是，一段动词，サ变动词，カ变动词与后续ます时的连用形完全一样，五段动词则不同，要发生音便，具体如下：<br><img src="3.jpg" alt="音变">  </p><p>接续动词て接在动词连用形后面可以起连接前后两个句子的作用,根据前后句的关系,往往会产生并列,先后,因果等关系,或者前句是后句的一种手段,方法,方式等.  </p><p><code>髪がし白くなって、歯も抜いた</code> (头发也白了,牙齿也掉了)</p><p>接续助词て与补助动词いる一起接在动词连用形之后构成持续体,动词持续体表示正在进行的动作,或经常,反复进行的动作,乙级动作结果的存续.</p><p><code>私はすでに結婚している</code> (我已经结婚了)</p><p>动词连用形后续表示过去的助动词た够长动词的过去式简体形式,它既可以用来结句,也可以用来做连体修饰语,修饰后面的名词,た在句中处理表示过去意外,还可以表示”完了”,<br>“确认”,”回想”,”状态”等含义.</p><p><code>きのう学校で運動会を開いた</code> (昨天学校召开了运动会)</p><p>最后,动词的连用形还可以后续ては,表示假定或确定的顺接前提条件,后续なら表示过去或完了的顺接前提条件,后续<code>たも,たって</code>表示假定或确定的逆接前提条件,后续<code>てはならない・てはいけない</code>表示干涉,禁止,后续たり表示并列</p><p><code>夜遅く寝ては体に悪い。</code>  (晚上睡得晚有害于健康)</p>]]></content>
      
      
      <categories>
          
          <category> 日语 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>有趣的句子(一)</title>
      <link href="/2019/10/14/you-qu-de-ju-zi-yi/"/>
      <url>/2019/10/14/you-qu-de-ju-zi-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>记一些有趣的句子</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><blockquote><p>真正的强者,不是因为某件事而壮烈的死去,而是因为某件事而卑微的活着。     —鲁迅</p></blockquote><br><blockquote><p>与人相处最怕的就是： 你不相信你看到的我，却相信别人口中的我    —《宫崎骏》</p></blockquote><br><blockquote><p>你必须内心丰富，才能摆脱这些胜过表面的相似。  —王朔</p></blockquote><br><blockquote><p>要让一群人团结起来,需要的不是英明的领导,而是共同的敌人   —《春物》</p></blockquote><br><blockquote><p>人的脆弱和坚强都巢湖自己的想象。有时，我可能脆弱得一句话就泪流满面，有时，也发现自己咬着牙走了很长的路   — 莫泊桑《一生》</p></blockquote><br><blockquote><p>没有一个人是禁得起分析的，能够试着了解，已是不容易了   —《亲爱的三毛》</p></blockquote><br><blockquote><p>三岁学说话,一生学闭嘴</p></blockquote><br><blockquote><p>心之所向,素履以往,生如逆旅,一苇以航.      —七堇年</p></blockquote><br><blockquote><p>惟沉默是最高的轻蔑         — 鲁迅</p></blockquote><br> <blockquote><p>世界上真正的好人和坏人都很少,大部分都是普通人,平时随波逐流,关键时刻则会出于自我保护而露出獠牙,而然正是因为这样才可怕.   —《春物》</p></blockquote><br><blockquote><p>勇者愤怒,抽刃向更强者;怯者愤怒,抽刃向更弱者     —鲁迅</p></blockquote><br><blockquote><p>人就是这样,越是没有实力越爱说大话,世界上只有没有实力的人,才整天希望别人赞赏   —卡卡西</p></blockquote><br><blockquote><p>事情总是突然的,而理由总是事后加上去的.</p></blockquote><br><blockquote><p>有些事,只能一个人做,有些关,只能一个人过,有些路,只能一个人走    —龙应台</p></blockquote><br><blockquote><p>人类的悲欢并不相通,我只觉得他们吵闹  —鲁迅</p></blockquote><br><blockquote><p>所谓世人,不就是你吗?   —太宰治</p></blockquote><br><blockquote><p>悲剧是将人生有价值的东西毁灭给人看,喜剧是将那些无价值的撕破给人看.   –鲁迅</p></blockquote><br><blockquote><p>不合群是表面的孤独,合群了才是内心的孤独   —刘同</p></blockquote><br><blockquote><p>人们只会看到自己想看到的,听到自己想听到的,我也不例外    —《春物》</p></blockquote><br>]]></content>
      
      
      <categories>
          
          <category> 简记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 简记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见算法整合(一)</title>
      <link href="/2019/09/18/chang-jian-suan-fa-zheng-he-yi/"/>
      <url>/2019/09/18/chang-jian-suan-fa-zheng-he-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>此算法不是机器学习中的算法,是开发中解决问题常用的工具的实现算法.毕竟我是开发嘛.术业有专攻.</p><h2 id="位图和Bloom-Filter"><a href="#位图和Bloom-Filter" class="headerlink" title="位图和Bloom Filter"></a>位图和Bloom Filter</h2><h4 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h4><p>一般接触到位图都是在对与一些海量数据的处理上,比如,在十亿个数中找到重复的或者判断是否存在等等,这个时候一般会有内存和机器的限制,不能直接保存整数,而是使用bit来代表每个数.<br>位图: 在Java中可以是BitSet,使用的话,也比较简单,底层应该也是数组,不过可以精确到每一bit,算一下,十亿个整数,每个证书是4个字节,那就是40亿字节,就是4GB左右的大小,如果我们用一位代表一个整数,那就是10亿位,8位一个字节,是128M左右.</p><h4 id="Bloom-Filter"><a href="#Bloom-Filter" class="headerlink" title="Bloom Filter"></a>Bloom Filter</h4><p>Bloom Filter即布隆过滤器,我初次接触实在处理缓存击穿的时候用到的.这个后面说,先说主要用途.<br>一般是这样一个题,我在腾讯面试的时候遇到的,如何在10亿个url中找到重复的.<br>因为url不是整数,我们不能直接用位图,(当然还有分治的方法,这里先不说),所以我们可以马上想到,对url做hash,然后用位图,但是单单是位图不行,因为hash碰撞的问题太严重,而且我们刚才在用位图的时候还有一个问题没有提到,就是位图对于数据范围有要求.<br>想象一下,如果我们实在1千万个整数中找重,但是这一千万个整数的范围是整个整数范围,那么我们还是需要128M左右,因为位图是随着数据范围而不是数据量,但如果我们直接使用map存整数,只需要40M,这就出现了问题,这个时候就需要Bloom Filter</p><p>我们使用K个hash函数,对同一个url求哈希值,会得到K个不同的Hash值,分别记做X1,X2,X3…Xk.我们把这K个数字作为位图的下标,填入位图,也就是说我们用K个二进制位来表示一个数字的存在.<br>当我们查询某个url是否存在时,也是先进行k个Hash,得到Y1,Y2,Y3,…Yk,看是否对应位图的下标是否都为true,如果有一个不是,那就不存在.<br>很容易看出来,Bloom Filter是存在误判的,也就是我们判断是存在的,但有可能是因为Hash碰撞导致的,而事实不存在,但这个误判率可以通过调整Hash来减少到0.1%以下,大部分系统应该都是可以容忍这样的误判的.<br>有一句话是这样说的<code>false is always false, true is true</code>,也就是如果判断不存在那就一定不存在,如果判断存在,那可能存在.</p><h4 id="缓存击穿中的应用"><a href="#缓存击穿中的应用" class="headerlink" title="缓存击穿中的应用"></a>缓存击穿中的应用</h4><p>先介绍一下缓存击穿,就是查询一个一定不存在的数据,缓存肯定不会命中的,这导致每一次的查询都落到DB上,如果有人恶意攻击,就会有漏洞.<br>一般的解决办法有两个,一个是缓存中将这个数据保留在缓存,值就是空,不过要设置失效时间.<br>另一种就是使用Bloom Filter,在缓存服务的基础上,设置Bloom Filter数据结构,查找逻辑如下:  </p><ol><li>根据key查找缓存,如果存在值,就返回,如果不存在,向下</li><li>根据key查询缓存BF中的值,如果存在,说明该key不存对应的值,返回空,如果不存在,向下</li><li>查询db对应的值,如果存在,更新缓存,并返回值,如果不存在,更新BF,并返回空.</li></ol><h2 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h2><p>这应该是一种分类算法,我面试网易的时候被问到知道什么分类算法吗?当时我说不知道,然后就没了,所以赶紧记录一下.<br>先看一下公式:<br>P(A|B) = P(B|A) * P(A) / P(B)<br>就是很简单,就是我们高中概率的东西,翻译一下就是:<br>B事件发生的情况下A发生的概率 等于 A发生的情况下B发生的概率 * A发生的概率 然后除以 B发生的概率.<br>例子的话,就是垃圾短信的过滤.<br>基于概率统计的过滤器,是基于短信内容来判定是否是垃圾短信,而计算机没办法理解短信的含义(我们先不考虑机器学习和神经网络),所以我们需要通过特征项,代替短信,来做短信过滤.<br>首先通过分词算法,把一个短信分割成n个单词,这n个单词就是一组特征项,全权代表这个短信,因此判断一个短信是否是垃圾短信,就变成了判断同时包含这几个单词的短信是否是垃圾短信.<br>但是这个判断不可以非黑即白,需要一个可信度,我们这样:<br>P(短信是垃圾短信 | w1,w2,w3….wn同时出现在一条短信中)<br>如果我们用简单的计算概率的方法,我们没有很多包含w1,w2,w3…wn的短信,没办法计算,所以需要朴素贝叶斯算法.<br>P(短信是垃圾短信|w1,w2…wn在同一条短信里) = P(w1,w2,..wn在短信里|短信是垃圾短信)<em>P(短信是垃圾短信) / P(w1,w2,…wn同时在一条短信中)<br>我们高中概率学中学到,如果A,B是独立事件,P(A</em>B) = p(A) * P(B)<br>然后我们的P(w1,w2,..wn同时出现在一条短信中|短信是垃圾短信) =<br>P(w1出现在短信中|短信是垃圾短信) *<br>P(w2出现在短信中|短信是垃圾短信) *<br>P(w3出现在短信中|短信是垃圾短信) *<br>….<br>P(wn出现在短信中|短信是垃圾短信)<br>其中P(wi出现在短信中|短信是垃圾短信)很简单可以计算,假设垃圾短信y个,包含wix个,那这个值就是x/y<br>然后是P(短信是垃圾短信)这个更简单,就是垃圾短信数/总短信数<br>最后是P(w1,w2,…wn同时出现在一条短信中)按理说需要频繁集挖掘算法,但是这里就不需要了,我们可以通过上面的值,计算出这条短信是垃圾短信和不是垃圾短信的分子值,因为分母都是这个,所以分子大的,那概率就大,如果是垃圾短信的概率源大于不是,那这个短信就是垃圾短信.  </p><p><code>判断垃圾短信这种需求,还是机器学习和神经网络靠谱一点,这里就是介绍一下朴素贝叶斯算法</code></p><h2 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h2><p>我以前做了大数据的相关题目,就是商品推荐,当时使用的是基于频繁集的挖掘生成关联规则的方法,算法是<code>Aprior</code>.但是推荐算法数不胜数,还有一种就是协同过滤算法,这是一种倾向于挖掘喜好的推荐算法,和频繁集相比的话,多了对人的喜好的因素.举个简单例子:<br>我们就拿音乐推荐来说:<br>假设我们有5个人,有10首歌,每个人对每首歌都有喜爱程度,比如你收藏了,或者把它添加进歌单,肯定要比只是听过一次要更加喜欢,根据喜爱程度从高到低,分数为,<code>5,4,3,2,1,0,-1</code>.<br>然后我们就有了每个人对于这10首歌的喜爱程度的打分.<br>这个时候我们就得到一个二维数组,然后把每个人的对于10首歌的打分列为一个向量,就比如<br><code>(5,1,3,4,0,0,-1,3,2,5)</code><br>这个时候我们有5个这样的向量,然后计算在向量空间里这5个向量的欧几里得距离,得到最每个人喜好最相近的那个人,然后就可以根据两人的听过的歌进行推荐.<br>还有根据歌曲进行的推荐,这样可以将歌曲进行推荐,<br>如果你用过网易云,可以发现在你进入软件时,有一个根据你人的推荐,然后你点进一首歌,又有根据歌曲的推荐,这就是二者的区别</p><h2 id="后"><a href="#后" class="headerlink" title="后"></a>后</h2><p>大概就这样吧，有些例子都是找来的，记录一下</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>水杯倒水问题-BFS</title>
      <link href="/2019/09/17/shui-bei-dao-shui-wen-ti-bfs/"/>
      <url>/2019/09/17/shui-bei-dao-shui-wen-ti-bfs/</url>
      
        <content type="html"><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><blockquote><p>三个水杯<br>时间限制：1000 ms | 内存限制：65535 KB<br>难度：4<br>描述<br>给出三个水杯，大小不一，并且只有最大的水杯的水是装满的，其余两个为空杯子。三个水杯之间相互倒水，并且水杯没有标识，只能根据给出的水杯体积来计算。现在要求你写出一个程序，使其输出使初始状态到达目标状态的最少次数。<br>输入<br>第一行一个整数N(0 &lt; N &lt; 50)表示N组测试数据<br>接下来每组测试数据有两行，第一行给出三个整数V1 V2 V3 (V1 &gt; V2&gt; V3 V1&lt;100 V3&gt;0)表示三个水杯的体积。<br>第二行给出三个整数E1 E2 E3 （体积小于等于相应水杯体积）表示我们需要的最终状态<br>输出<br>每行输出相应测试数据最少的倒水次数。如果达不到目标状态输出-1<br>样例输入<br>2<br>6 3 1<br>4 1 1<br>9 3 2<br>7 1 1<br>样例输出<br>3<br>-1  </p></blockquote><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>其实第一次遇到这个题,我一点思路都没有,现在这个解法也是看了别人的C代码,理解后决定记录一下,顺北实现一下Java版本的.<br>其实说是BFS,也就是暴力破解,这道题也有很多变种,但这个应该是可以应对其他变种的一种解法.<br>首先我们需要将三杯水的状态和操作的步骤数封装成类,(其实不用类也可以,就是不方便)然后创建一个队列,将初始状态放进队列,然后进入循环,每次取出对头的状态,先和最终状态比较,看是否满足,满足就退出,否则进行<code>变换</code>,如果这个状态没有出现过就放进队列中,直到队列为空,如果还是,没有满足的状态,就返回-1;<br>这里的重点就是这个<code>变换</code>,其实就是两杯水x,y,x-&gt;y.如果x中有水且y不满,就把x中的水倒入y中,这里有两种情况,一种是将y倒满,另一种是x为空,当然可能二者同时发生,但必须发生一个.  </p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre class="line-numbers language-Java"><code class="language-Java">public class Solution {    /**     * 状态内部类,实现深拷贝,很重要     */    static class State implements Cloneable {        int[] s ;        int step ;        public State(int x,int y ,int z){            s = new int[]{x,y,z};            step = 0 ;        }        @Override        public Object clone() {            try {                State ss = (State)super.clone();                // 深拷贝数组,坑                ss.s = this.s.clone();                return ss ;            } catch (CloneNotSupportedException e) {                return null;            }        }    }    //最终状态,减少方法参数    static int[] endState ;    /**     * 查找改状态变成最终状态的步数,如果不行,返回-1     * @param s 初始状态     * @return step or -1     */    private static int BFS(State s) {        // 初始状态        State initial = new State(s.s[0],0,0);        // 存储状态的队列        LinkedList<State> ls = new LinkedList<>();        // 判断某一状态是否出现过        int[][][] isVisited = new int[s.s[0]+1][s.s[1]+1][s.s[2]+1];        isVisited[initial.s[0]][0][0] = 1;        ls.addLast(initial);        //进入循环        while (!ls.isEmpty()){            // 取出头元素            State temp = ls.pop();            // 判断是否和最终状态相同            if (isArchive(temp)){                return temp.step;            }            // 对每一个状态进行变换            for (int i = 0 ; i < 3 ; i++){                for (int j = 0 ; j < 3 ;j++){                    if (i != j && temp.s[i] != 0 && temp.s[j] < s.s[j]){                        State cur = (State) temp.clone();                        // i -> j 倒水                        pourWater(i,j,cur,s);                        // 步数+1                        cur.step+=1;                        // 如果没有被访问,就添加进入队列                        if (isVisited[cur.s[0]][cur.s[1]][cur.s[2]] == 0){                            isVisited[cur.s[0]][cur.s[1]][cur.s[2]] =1 ;                            ls.addLast(cur);                        }                    }                }            }        }        return  -1 ;    }    /**     * i -> j倒水     * @param i 源杯     * @param j 目的杯     * @param cur 当前状态     * @param capacity 杯子容量     */    private static void pourWater(int i, int j, State cur,State capacity) {        int waterNeeded = capacity.s[j] - cur.s[j];        if (waterNeeded <= cur.s[i]){            cur.s[j] += waterNeeded; //start.s[j]            cur.s[i] -= waterNeeded;        }else{            cur.s[j] += cur.s[i];            cur.s[i] = 0 ;        }    }    /**     * 判断当前状态是否满足最终状态     * @param cur 当前状态     */    private static boolean isArchive(State cur) {        if (cur == null){            return false;        }        for (int i = 0 ; i < 3 ;i++){            if (cur.s[i] != endState[i]){                return false;            }        }        return true;    }    public static void main(String[] args) {        Scanner scan = new Scanner(System.in);        int n = scan.nextInt();        for (int i = 0 ; i < n ;i++){            int x = scan.nextInt(),y = scan.nextInt(),z = scan.nextInt();            State s = new State(x,y,z);            endState = new int[]{scan.nextInt(),scan.nextInt(),scan.nextInt()};            int step = BFS(s);            System.out.println(step);        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>代码中的注释很详细,很容易看懂.</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ConcurrentHashMap源码分析</title>
      <link href="/2019/09/16/concurrenthashmap-yuan-ma-fen-xi/"/>
      <url>/2019/09/16/concurrenthashmap-yuan-ma-fen-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>基于JDK8的源码<br>ConcurrentHashMap介绍使用什么的我就不说了,直接进入主题吧</p><h2 id="主要属性"><a href="#主要属性" class="headerlink" title="主要属性"></a>主要属性</h2><pre class="line-numbers language-Java"><code class="language-Java">    // 容量最大值    private static final int MAXIMUM_CAPACITY = 1 << 30    // 默认容量    private static final int DEFAULT_CAPACITY = 16;    //底层数组最大长度    static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;    // 默认并行度    private static final int DEFAULT_CONCURRENCY_LEVEL = 16;    //负载因子    private static final float LOAD_FACTOR = 0.75f;    // 链表变成红黑树的界限值    static final int TREEIFY_THRESHOLD = 8;    //非树化界限    static final int UNTREEIFY_THRESHOLD = 6;    //树化最小容量    static final int MIN_TREEIFY_CAPACITY = 64;    private static final int MIN_TRANSFER_STRIDE = 16;    private static int RESIZE_STAMP_BITS = 16;    private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;    private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;    static final int MOVED     = -1; // 正在转移节点    static final int TREEBIN   = -2; // 已经转移成树    static final int RESERVED  = -3; // 临时保留hash    static final int HASH_BITS = 0x7fffffff; // 普通节点可用的hash位数    // 可用cpu核数    static final int NCPU = Runtime.getRuntime().availableProcessors();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>大致的解释都在注释里了,具体的应用还是要再方法里看</p><h2 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h2><p>链表节点类:</p><pre class="line-numbers language-Java"><code class="language-Java">    static class Node<K,V> implements Map.Entry<K,V> {        final int hash;        final K key;        volatile V val;        volatile Node<K,V> next;    ...    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>很简单,只有四个属性,两个方法,值得注意的就是修饰属性的关键字,首先是hash和key,使用final修饰的,应该是保证这个节点的key不可变,除非删除节点,否则不能改变key值,响应的hash也就不能变.然后是val和next是用volatile修饰的,因为get()方法时无锁的,所以这里有使用volatile保证及时的可见性.  </p><p>树节点:</p><pre class="line-numbers language-Java"><code class="language-Java">    static final class TreeNode<K,V> extends Node<K,V> {        TreeNode<K,V> parent;  // red-black tree links        TreeNode<K,V> left;        TreeNode<K,V> right;        TreeNode<K,V> prev;    // needed to unlink next upon deletion        boolean red;    ...    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>很简单的红黑树结构,但是红黑树本身并不简单,或许可以很好的理解插入删除等操作,但是真正去实现,就有点难,关于红黑树的源码,可以看TreeMap的源码.</p><h2 id="操作节点数组的三个原子方法"><a href="#操作节点数组的三个原子方法" class="headerlink" title="操作节点数组的三个原子方法"></a>操作节点数组的三个原子方法</h2><pre class="line-numbers language-Java"><code class="language-Java">    // 返回节点数组的指定位置的节点的原子操作    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {        return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);    }    // cas原子操作,在指定位置设置值    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,                                        Node<K,V> c, Node<K,V> v) {        return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);    }    //原子操作,在指定位置设置值    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {        U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h2><pre class="line-numbers language-Java"><code class="language-Java">    //默认构造,使用默认参数构造    public ConcurrentHashMap() {    }    //设置初始容量的构造,底层数组将设置为2的整数幂大小    public ConcurrentHashMap(int initialCapacity) {        if (initialCapacity < 0)            throw new IllegalArgumentException();        int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?                   MAXIMUM_CAPACITY :                   tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));        this.sizeCtl = cap;    }    //还有很多,可以指定负载因子,传入一个Map,并行度的构造函数    ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h2><pre class="line-numbers language-Java"><code class="language-Java">    public V get(Object key) {        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;        // 计算hash值        int h = spread(key.hashCode());        //定位及判断        if ((tab = table) != null && (n = tab.length) > 0 &&            (e = tabAt(tab, (n - 1) & h)) != null) {            //判断定位到的头结点是不是key            if ((eh = e.hash) == h) {                if ((ek = e.key) == key || (ek != null && key.equals(ek)))                    return e.val;            }            // 头结点hash值为负的情况            else if (eh < 0)                return (p = e.find(h, key)) != null ? p.val : null;            //遍历节点寻找,找到返回值            while ((e = e.next) != null) {                if (e.hash == h &&                    ((ek = e.key) == key || (ek != null && key.equals(ek))))                    return e.val;            }        }        // 没有该key对应的值,返回null        return null;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h2><p>put方法实际调用的是putVal(),直接看这个方法</p><pre class="line-numbers language-Java"><code class="language-Java">final V putVal(K key, V value, boolean onlyIfAbsent) {        // concurrent不允许key或value为null        if (key == null || value == null) throw new NullPointerException();        // 计算hash值        int hash = spread(key.hashCode());        // 记录这个链表有多少个值,控制转树        int binCount = 0;        // 无限制循环        for (Node<K,V>[] tab = table;;) {            Node<K,V> f; int n, i, fh;            // 如果table没有初始化,就调用初始化            if (tab == null || (n = tab.length) == 0)                tab = initTable();            // 如果节点数组当前位置没有值,就调用cas操作设置值            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {                if (casTabAt(tab, i, null,                             new Node<K,V>(hash, key, value, null)))                    break;                   // no lock when adding to empty bin            }            // 如果当前节点正在扩容的阶段,改线程也进行帮助扩容            else if ((fh = f.hash) == MOVED)                tab = helpTransfer(tab, f);            else {                V oldVal = null;                //如果当前节点一切正常,就获得当前头结点的排它锁                synchronized (f) {                    if (tabAt(tab, i) == f) {                        // 大于0代表还是链表                        if (fh >= 0) {                            binCount = 1;                            //遍历列表,寻找是否有对应的key                            for (Node<K,V> e = f;; ++binCount) {                                K ek;                                // 如果有,就替换                                if (e.hash == hash &&                                    ((ek = e.key) == key ||                                     (ek != null && key.equals(ek)))) {                                    oldVal = e.val;                                    if (!onlyIfAbsent)                                        e.val = value;                                    break;                                }                                Node<K,V> pred = e;                                //如果没有,就尾插一个新的节点                                if ((e = e.next) == null) {                                    pred.next = new Node<K,V>(hash, key,                                                              value, null);                                    break;                                }                            }                        }                        // 已经变树了                        else if (f instanceof TreeBin) {                            Node<K,V> p;                            binCount = 2;                            // 调用putTreeVal将节点插入红黑树中                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,                                                           value)) != null) {                                oldVal = p.val;                                if (!onlyIfAbsent)                                    p.val = value;                            }                        }                    }                }                // 判断这个数组该位置的节点数是不是大于等于变树界限,如果是,就转树                if (binCount != 0) {                    if (binCount >= TREEIFY_THRESHOLD)                        treeifyBin(tab, i);                    if (oldVal != null)                        return oldVal;                    break;                }            }        }        //计数加一        addCount(1L, binCount);        return null;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>总结一下:  </p><ol><li>首先判断添加的k-v是不是null,如果是,就抛出异常</li><li>接着判断table是否已经初始化,如果没有,就初始化</li><li>然后计算hash确定在数组中的位置  </li><li>如果当前位置为空,直接添加,如果不为空,取出这个节点</li><li>如果该节点hash值是moved,表示正在扩容,就去帮助扩容</li><li>否则,取出节点,判断是树还是链表(hash值是否小于0),如果是链表,就操作链表,如果是树,就操作树</li><li>判断当前位置的count是不是大于界限值,如果大于,就转换成树</li></ol><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><p>扩容比较复杂,大致说一下:<br>首先确认的就是,底层数组的长度永远都是2的正整数幂的大小,然后扩容和转红黑树之间也有一定关系,当底层数组大小小于64的时候,链表达到界限值是不会转树的,而是扩容数组,只有数组大于等于64后,才会转树.<br>触发扩容的条件是当容器存储值大于sizectl(capacity*负载因子).<br><code>ConcurrentHashMap</code>扩容是一个并发的扩容,通常是将原来的数组复制到一个新的数组,然后允许多个线程进入,每个线程负责一定长度(16)的数组部分.</p><p>源码待析…</p><h2 id="同步问题"><a href="#同步问题" class="headerlink" title="同步问题"></a>同步问题</h2><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p>可以看到,get全程是无锁的,也就是说无论是否有其他线程正在扩容或者正在put,都是无锁进行的,可以想到的就是上面说到的节点的属性,首先扩容不改变值,且在新的数组中进行,所以不影响get(),其次是put(),这里应该就是通过volatile来保证及时的可见性,毕竟get()操作只是获取值.</p><h4 id="put"><a href="#put" class="headerlink" title="put"></a>put</h4><p>这里就是put和扩容时的问题.上面可以看到,如果数组正在扩容,会设置节点hash为moved,put线程看到后,会调用<code>helpTransfer</code>方法帮助扩容</p><h4 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h4><p>其实上面都有说到,<code>concurrentHashmap</code>主要通过<code>synchronized</code>和<code>cas</code>来完成同步.<br>在获取sizeCtl和定位数组中的位置时都是<code>CAS</code><br>在put某个位置时,使用<code>synchronized</code><br>等等</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>concurrentHashMap这个并发容器真的是比较重要,我看到的源码里用的有Spring的IOC容器底层实现就是一个<code>ConcurrentHashMap</code>,所以掌握深一点绝对没错.</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Http的Get Post</title>
      <link href="/2019/09/13/http-de-get-post/"/>
      <url>/2019/09/13/http-de-get-post/</url>
      
        <content type="html"><![CDATA[<h2 id="初识"><a href="#初识" class="headerlink" title="初识"></a>初识</h2><p>第一次接触get和post,只是知道get是将参数加在url后面,Post是将参数加在表单里,然后说Get是不安全的,因为将信息都放在了url里,而Post将参数隐藏起来,其他的并不知道很多,但这可以说是非常浅薄的.</p><h2 id="更多区别"><a href="#更多区别" class="headerlink" title="更多区别"></a>更多区别</h2><p>后来我学习更多的web相关知识,知道了更多对的区别,列一下<code>w3schools</code>中的对比:  </p><ul><li>GET后退按钮/刷新无害，POST数据会被重新提交（浏览器应该告知用户数据会被重新提交）</li><li>GET书签可收藏，POST为书签不可收藏。GET能被缓存，POST不能缓存 。</li><li>GET编码类型<code>application/x-www-form-url</code>，POST编码类型 <code>encodedapplication/x-www-form-urlencoded</code> 或 <code>multipart/form-data。</code>为二进制数据使用多重编码。</li><li>GET历史参数保留在浏览器历史中。POST参数不会保存在浏览器历史中。</li><li>GET对数据长度有限制，当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。POST无限制。</li><li>GET只允许 ASCII 字符。POST没有限制。也允许二进制数据。与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。GET的数据在 URL 中对所有人都是可见的。POST的数据不会显示在 URL 中。</li></ul><p>但事实真的是这样吗?</p><h2 id="浏览器请求"><a href="#浏览器请求" class="headerlink" title="浏览器请求"></a>浏览器请求</h2><p>我们知道,Get,Post是Http中的方法,是什么事方法,也就是http请求报文中请求行中的Method.同时还有Put,Delete等,为什么有这些方法呢?事实就是,其实这只是个规范,并不是一定要这样.<br>我们知道,Http在五层网络协议中处于最高层,也就是应用层,而下一层使用的是TCP协议,而根据Http的协议内容,没有要求说Get就一定不能有body,Post就不能把参数加在url后面,只能说这些规定和上面的区别只是一个东西规定的,那就是浏览器.<br>我们最常用的发送http请求的就是浏览器了,我们从地址栏输入url,一般都是Get请求,而在页面提交表单,就是post请求.为什么这样规定呢,就是因为浏览器只有几种,而网站有亿万种,怎么才能让浏览器能访问所有网页呢,这就需要规定,不然你的网站就别让别人看见.所以有上面那些区别,都是因为浏览器.</p><p>这里说的浏览器，更多的是指一些原生的浏览器操作，不包括ajax发送请求的方式，原生的浏览器操作中， get请求例如地址栏输入网址或者点击<code>&lt;a/&gt;</code>标签，post的话，就是使用<code>&lt;form&gt;</code> 标签,浏览器的get操作只能由url触发，所以我们如果想要携带参数，必须使用querystring，而post请求如果想使用querystring， 也非常简单，只要使用<code>&lt;form action=&quot;url&quot;&gt;</code> 即可。</p><h2 id="接口请求"><a href="#接口请求" class="headerlink" title="接口请求"></a>接口请求</h2><p>那么除了浏览器,还有什么使用http请求呢,那就是我们开发使用api接口了,常见的有很多,我熟悉的就是python的<code>requests</code>和Java的<code>commons-httpclient</code>或者<code>okhttp</code>,当然还有很多工具,比如linux的<code>curl</code>和很多人用过的<code>postman</code>,我就拿<code>Python</code>来说说.<br>我们先看一下<code>requests</code>库中的方法,这是一个http客户端的库,就看一下Get和Post:<br><code>def get(url, params=None, **kwargs):</code><br><code>def post(url, data=None, json=None, **kwargs):</code><br>可以看到其实get和post一样,都是传入一个参数,不过名字不一样,一个是<code>params</code>,另一个是<code>data</code>或<code>json</code>(data和json的区别自行查找). 其实我不知道底层,也可能get会把params里的参数变成<code>url?key=value&amp;key2=value2</code>这样的形式,但是这还是因为浏览器对网站的规范,那怎么证明呢?我们自己写个接口服务呗!<br>还是Python,我们就用Flask.先看一下Flask的Get服务.</p><pre class="line-numbers language-Python"><code class="language-Python">@app.route('/')def hello_world():    return 'Hello, World!'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这其实看不出什么区别,我们可以看一下,flask中Get和Post是怎么拿参数数据的.<br>Get : <code>request.args</code><br>Post : <code>request.form</code></p><p>单从客户端和服务端中任何一个其实看不出什么结果,我们整体来看,我们可以这样认为,是因为浏览器,才让这些框架去指定这样的区别,就是flask的<code>request.args</code>和<code>request.form</code>,然后requests库就对这样的规定妥协了,因为不管是网站服务还是api接口服务,人家已经用这样的框架,在这样的规范下写了,所以我们没有办法,也只能分个Get和Post.<br>这是从什么角度来看的呢,是从浏览器角度,如果绕开浏览器,我们看一下可以发现,如果客户端requests库不需要这样的规范,那么Get和Post就只有语义上的区别了,从函数看有什么区别,不都是一个url和一个参数字典.如果服务端可以保证,我的接口就只会被开发库调用,而不被浏览器访问,那写成什么样都是自己说的算,我允许Get带数据就带,允许Post在url后加东西就加东西,没任何区别.  </p><h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>这里补充一下编码的问题，一般来说，http请求的编码需要分成url编码和body编码。</p><p>url编码在RFC中有规定，不经编码可以展示的是<code>[a-zA-Z0-9$-_.+!*&#39;(),]</code>，其他字符，例如中文，必须经过编码才能展示，这些需要编码的字符需要使用percent encoding来编码，编码后加到url中，但是这个编码不规定字符集，有些和浏览器相同，有些和操作系统相同，所以还是使用ajax发送请求比较好。</p><p>而body的编码就比较容易了， 可以在header中的content-type来确定。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h4 id="post是否需要发送两个请求"><a href="#post是否需要发送两个请求" class="headerlink" title="post是否需要发送两个请求"></a>post是否需要发送两个请求</h4><p>客户端行为，和协议无关</p><h4 id="url长度"><a href="#url长度" class="headerlink" title="url长度"></a>url长度</h4><p>浏览器和服务器由规定，和协议无关</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>说了这么多,想说什么呢?<br>Http只是协议,协议就是双方进行规范的东西,协议也是人定的,只要双方可以认同,那就没什么一定是什么样的,只不过在这个例子来看,是因为浏览器的存在,要求所有提供网站服务的人遵循这样的一个规定,然后久而久之,很多人就认为一定要这样.我们应该从广义的角度来看这些东西.如果上面的这些不能说服你,建议学习一下ES的API访问,你就知道Get请求一样可以带body.就这样.</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JUC下的同步工具</title>
      <link href="/2019/09/12/juc-xia-de-tong-bu-gong-ju/"/>
      <url>/2019/09/12/juc-xia-de-tong-bu-gong-ju/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这些锁是并发包下的锁,实现原理全是基于AQS,还使用了CAS操作,先了解一下<a href="https://relife957.github.io/2019/09/11/shuo-shuo-bai-aqs/">AQS和CAS</a>,<br>然后看一下JUC包的结构<br><img src="1.png" alt="JUC"></p><h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><h4 id="介绍和使用"><a href="#介绍和使用" class="headerlink" title="介绍和使用"></a>介绍和使用</h4><p>可重入的独占锁,即同时只有一个线程可以获取锁,其他尝试获取锁的线程会被放在锁的AQS阻塞队列中,重入的意思是指同一个线程可以多次获取锁.<br>公平锁和非公平锁. ReentrantLock内部有两个内部类<code>NonfairSync</code>和<code>FairSync</code>分别是非公平锁和公平锁,公平和不公平的区别在于后尝试的线程是否会在先尝试获取锁的线程前获取这个锁.具体的实现,下面说.<br>AQS的博客中说到过,state这个变量在不同的锁实现中有不同的意义,在ReentrantLock中,state变量代表一个线程获取锁的可重入次数,默认情况下为0,代表没有被线程持有,当第一个线程尝试使用CAS设置state为1,如果CAS成功,就记录锁的持有者为该线程,这个记录的操作是通过AQS中的<code>setExclusiveOwnerThread(Thread)</code>设置.在该线程没有释放锁的情况下第二次获取锁后,状态值被设置为2,即可重入次数.在该线程释放锁时,尝试CAS操作使state减一,如果减一后为0,当前线程释放锁.</p><ul><li>lock,tryLock,lockInterruptibly<ul><li>这个是面试中的问题,三种获取锁的方式有什么不同</li><li>lock是获取锁,如果锁已经被其他线程持有,就将该线程封装置于AQS队列中阻塞挂起.该方法的公平和非公平策略有所不同<ul><li>非公平策略:先来的线程没有获取到锁被置于队列中挂起,后来的线程如果刚好碰到当前持有的锁的线程释放锁,就会直接获取锁,不会查看队列中是否有比自己先来的线程.</li><li>公平策略就容易理解了,在能拿到锁的时候查看队列中是否有比自己先来的锁,如果有,会让出.</li></ul></li><li>lockInterruptibly();与lock()类似,不过对中断响应,即如果使用该方法尝试获取时,如果其他线程调用了interrupt()方法中断该线程,该方法会抛出<code>InterruptionException</code></li><li>tryLock();尝试获取锁,如果锁被持有,就直接返回false,不添加到队列,不挂起阻塞,否则获取锁,返回true;</li></ul></li></ul><h4 id="底层一点"><a href="#底层一点" class="headerlink" title="底层一点"></a>底层一点</h4><p>在AQS的时候,我说过,AQS其实是使用了模板模式,继承AQS后需要实现<code>tryAcquire()</code>等方法,所以我们就来看看这个方法   </p><pre class="line-numbers language-Java"><code class="language-Java">final boolean nonfairTryAcquire(int acquires) {    //当前线程    final Thread current = Thread.currentThread();    //获取同步状态    int c = getState();    //state == 0,表示没有该锁处于空闲状态    if (c == 0) {        //获取锁成功，设置为当前线程所有        if (compareAndSetState(0, acquires)) {            setExclusiveOwnerThread(current);            return true;        }    }    //线程重入    //判断锁持有的线程是否为当前线程    else if (current == getExclusiveOwnerThread()) {        int nextc = c + acquires;        if (nextc < 0) // overflow            throw new Error("Maximum lock count exceeded");        setState(nextc);        return true;    }    return false;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看代码中的注释就可以知道一个大致的流程,同时我们可以看到<code>ReentrantLock</code>的可重入性以及如何实现.<br>至于其他的方法我们就很容易理解了,都是围绕<code>state</code>的一个操作,至于其他的AQS已经有提供了.  </p><h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><h4 id="介绍和使用-1"><a href="#介绍和使用-1" class="headerlink" title="介绍和使用"></a>介绍和使用</h4><ul><li><p>可重入的读写锁,在某些方面和上一个锁还是有些类似的,读写锁内部维护了一个ReadLock和一个WriteLock,底层还是AQS,但是AQS只有一个state状态量,如何同时控制读和写呢,这里使用了state(int)的高16位表示读状态,低16为表示写,高16位的值代表获取读锁的线程数,低16位代表写锁的可重入数.</p></li><li><p>读写锁维持了很多和读锁有关的变量:</p><ul><li>Thread firstReader:第一个获取读锁的线程</li><li>int firstReaderHoldCount:记录第一个获取读锁的线程的可重入次数.</li><li>int cachedHoldCounter:最后一个获取读锁的线程的可重入次数</li><li>ThreadLocal readHolds:除了第一个获取读锁的线程以外的线程的可重入次数</li></ul></li><li><p>读写锁也有公平和非公平策略,与ReentrantLock大同小异,不详细介绍了</p></li><li><p>写锁的获取与释放</p><ul><li>void lock(); 写锁是一个独占锁,和ReentrantLock类似,如果有其他线程已经获得写锁,就进入队列挂起等待,否则获取锁或者使状态值加一.</li><li>还有tryLock()和lockInterruptibly()以及一些带等待时限的方法,不介绍了,大同小异</li><li>void unlock();释放锁,状态值减一,为0后释放锁,如果没有持有锁而调用了释放锁,抛出<code>IllegalMonitorStateException</code>异常.</li></ul></li><li><p>读锁的获取和释放</p><ul><li>void lock();如果当前没有其他线程持有写锁,可以获得读锁,高16为加一,方法返回,否则进入队列阻塞等待.<ul><li>需要注意的是,如果当前要获取读锁的线程已经持有了写锁,则也可以获取读锁,但要注意的是,先获取了写锁,然后获取读锁处理事情完毕后,读写锁都释放,不能只释放其一.</li></ul></li><li>获取读锁的实现不复杂,但是很麻烦,因为读写锁内部维持了很多读锁的变量,需要在获取读锁成功后修改.</li></ul></li></ul><h4 id="底层一点-1"><a href="#底层一点-1" class="headerlink" title="底层一点"></a>底层一点</h4><p>主要看这一段代码:<br>首先是读锁的lock()函数,底层调用的是tryAcquireShared(),是一个共享的获取锁的过程:  </p><pre class="line-numbers language-Java"><code class="language-Java">protected final int tryAcquireShared(int unused) {            /*             * Walkthrough:             * 1. 如果写锁被其他线程持有, fail.             */             //当前线程            Thread current = Thread.currentThread();            //状态state            int c = getState();            // 如果写锁不为0且当前线程不是持有写锁的线程,退出            if (exclusiveCount(c) != 0 &&                getExclusiveOwnerThread() != current)                return -1;            // 读变量            int r = sharedCount(c);            // 读不阻塞且读锁的获取者小于最大值,cas设置            if (!readerShouldBlock() &&                r < MAX_COUNT &&                compareAndSetState(c, c + SHARED_UNIT)) {                //如果读锁为0,设置第一个获得读锁的线程为当前                if (r == 0) {                    firstReader = current;                    firstReaderHoldCount = 1;                //如果当前线程就是第一个获得读锁的线程,计数++                } else if (firstReader == current) {                    firstReaderHoldCount++;                } else {                    HoldCounter rh = cachedHoldCounter;                    if (rh == null || rh.tid != getThreadId(current))                        cachedHoldCounter = rh = readHolds.get();                    else if (rh.count == 0)                        readHolds.set(rh);                    rh.count++;                }                // 获得读锁成功,返回1                return 1;            }            return fullTryAcquireShared(current);        }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后是写锁的lock方法,调用的是tryAcquire(),是一个排他锁:</p><pre class="line-numbers language-Java"><code class="language-Java">    protected final boolean tryAcquire(int acquires) {            /*             * Walkthrough:                1. 如果读计数非零且写计数也非零,但当前线程不是持有锁的线程,报错                2. 如果计数饱和,报错                3. 如果这个线程是可重入获取或队列策略允许，那么它就有资格获得锁。如果是，则更新状态并设置所有者。              */             //当前线程            Thread current = Thread.currentThread();            // 状态值            int c = getState();            // 读锁值            int w = exclusiveCount(c);            //状态不为0            if (c != 0) {                // (Note: if c != 0 and w == 0 then shared count != 0)                // 没有拿到读锁的线程,当时有写锁,且当前线程不是持有读锁的线程,返回false                if (w == 0 || current != getExclusiveOwnerThread())                    return false;                // 拿到读锁后是否大于最大限制,如果大于,抛出错误                if (w + exclusiveCount(acquires) > MAX_COUNT)                    throw new Error("Maximum lock count exceeded");                // Reentrant acquire                // set状态值                setState(c + acquires);                return true;            }            // state = 0            // 如果写阻塞且cas获取失败,返回false            if (writerShouldBlock() ||                !compareAndSetState(c, c + acquires))                return false;            // cas成功,设置当前线程为拿到读锁的线程,返回true            setExclusiveOwnerThread(current);            return true;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h2><h4 id="故事"><a href="#故事" class="headerlink" title="故事"></a>故事</h4><p>这个工具类其实我是用过的,之前做过一个后端的项目,用到了SpringBoot中结合线程池,但是有一个问题,SpringBoot并不会主动关闭线程池,而我的项目不是一个web,需要一直运行,是一个每天定时运行的项目,所以我需要手动关闭线程池,但又不能直接在main线程中关闭,所以用到了CountDownLatch.  </p><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>CountDownlatch,字面意思是减少计数的门闩,就是不断减少计数,直到为0后门打开,然后执行门后的内容.</p><h4 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h4><p>构造方法<code>CountDownlatch(int count)</code>count表示需要减少的计数.<br><code>await()</code>一般是主线程调用,意味着该线程阻塞在这里,直到计数为0,然后执行后面的内容<br><code>countDown()</code>一般是工作线程调用,完成任务后调用,意味着减少一个计数<br>用法很简单,没什么难度</p><h4 id="底层一点-2"><a href="#底层一点-2" class="headerlink" title="底层一点"></a>底层一点</h4><p>其实这个源码没什么意思,就是简单用了AQS.<br>首先我们可以确定的就是,使用的是AQS的共享锁.<br>然后是<code>await()</code>方法,就是去判断当前值是否为0,不为0就会调用一个自旋方法去一直获得同步状态.<br>接着是<code>countDown()</code>,首先获取到锁的状态,如果当前状态为0,直接返回减少失败,否则使用CAS更改状态使c–;<br>就这样,没有什么别的,源码很少很简单,可以自己打开看一下.</p><h2 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h2><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>CyclicBarrier,字面意思是可循环使用的屏障,它要做的事情就是,让一组线程到达一个屏障时被阻塞,知道最后一个线程到达屏障时,会执行指定方法.  </p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>构造方法 : <code>CyclicBarrier(int parties)</code>,参数表示构造屏障拦截的数目.<br>          <code>CyclicBarrier(int parties, Runnable barrierAction)</code> barrierAction可以缺省,表示当所有线程到达后执行的内容.<br><code>await()</code>,每个工作线程调用的,意味着我已经到了,就等你们了,等所有(parties)线程都使用await()等待后,门打开,执行后续.</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>一般会把<code>CountDownlatch</code>和<code>CyclicBarrier</code>比较,其实我觉得差不多,就是后者可以复用,然后底层后者使用<code>ReentrantLock</code>和<code>Condition</code>,而前者是基于<code>AQS</code>．　　</p><h4 id="底层一点-3"><a href="#底层一点-3" class="headerlink" title="底层一点"></a>底层一点</h4><p>比较重要的就是一个<code>dowait()</code>方法和分代的一个思想,代码我贴一下:  </p><pre class="line-numbers language-Java"><code class="language-Java">private int dowait(boolean timed, long nanos)        throws InterruptedException, BrokenBarrierException,        TimeoutException {    //获取锁    final ReentrantLock lock = this.lock;    lock.lock();    try {        //分代        final Generation g = generation;        //当前generation“已损坏”，抛出BrokenBarrierException异常        //抛出该异常一般都是某个线程在等待某个处于“断开”状态的CyclicBarrie        if (g.broken)            //当某个线程试图等待处于断开状态的 barrier 时，或者 barrier 进入断开状态而线程处于等待状态时，抛出该异常            throw new BrokenBarrierException();        //如果线程中断，终止CyclicBarrier        if (Thread.interrupted()) {            breakBarrier();            throw new InterruptedException();        }        //进来一个线程 count - 1        int index = --count;        //count == 0 表示所有线程均已到位，触发Runnable任务        if (index == 0) {  // tripped            boolean ranAction = false;            try {                final Runnable command = barrierCommand;                //触发任务                if (command != null)                    command.run();                ranAction = true;                //唤醒所有等待线程，并更新generation                nextGeneration();                return 0;            } finally {                if (!ranAction) // 未执行，说明 barrierCommand 执行报错，或者线程打断等等情况。                    breakBarrier();            }        }        for (;;) {            try {                //如果不是超时等待，则调用Condition.await()方法等待                if (!timed)                    trip.await();                else if (nanos > 0L)                    //超时等待，调用Condition.awaitNanos()方法等待                    nanos = trip.awaitNanos(nanos);            } catch (InterruptedException ie) {                if (g == generation && ! g.broken) {                    breakBarrier();                    throw ie;                } else {                    // We're about to finish waiting even if we had not                    // been interrupted, so this interrupt is deemed to                    // "belong" to subsequent execution.                    Thread.currentThread().interrupt();                }            }            if (g.broken)                throw new BrokenBarrierException();            //generation已经更新，返回index            if (g != generation)                return index;            //“超时等待”，并且时间已到,终止CyclicBarrier，并抛出异常            if (timed && nanos <= 0L) {                breakBarrier();                throw new TimeoutException();            }        }    } finally {        //释放锁        lock.unlock();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>具体的内容看注释,我总的说一下:<br>首先是拿到锁,这个锁是全局的排它锁,意味着同时只有一个线程可以在一个时刻进入,然后是一些中断和异常的判断,到index处,将当前计数–,然后判断是否这是最后一个到达的线程,如果不是,就使用<code>Condition</code>的<code>await()</code>阻塞当前线程到条件变量的阻塞队列,如果是最后一个线程,就执行我们创建<code>CycliBarrier</code>时的传入的runnable,当然,前提是我们传入了.然后唤醒所有等待在条件变量等待队列中的线程,更新换代.  </p><p>然后我们说一下换代的问题.<code>Generation</code>是一个内部类,也就是<code>parties</code>个线程到达前,他们属于同一代,因为<code>CyclicBarrier</code>是复用的,所以还有下一代,其实很简单,就是唤醒所有线程,重置count,重置Generation.</p><h2 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h2><p>原子操作的问题还是要回到<code>i++</code>上来,我们知道<code>i++</code>并不是一个原子操作,当一个线程读取值,然后使i+1,然后再写回缓存或者内存,这是三步操作,中间可能有其他线程的参与,就会导致线程安全问题,为了解决在这个问题,方法很多,可以加锁(synchronized和lock),还有就是下面说的原子类.<br>JUC下提供了一系列的原子类,就是<code>atomic</code>包下面的类,这是一种乐观锁的实现,主要就是通过<code>volatile</code>关键字和<code>CAS</code>操作来实现,这两个具体我就不说了,我以前的博客也有相关内容.这里主要说一下原子类.主要有一下几种:  </p><ul><li>原子类: <code>AtomicBoolean</code>,<code>AtomicInteger</code>,<code>AtomicLong</code>,<code>AtomicReference</code></li><li>院子数组 : <code>AtomicIntegerArray</code>,<code>AtomicLongArray</code>,<code>AtomicReferenceArray</code>,</li><li>原子属性更新: <code>AtomicLongFieldUpdater</code>,<code>AtomicIntegerFieldUpdater</code>,<code>AtomicReferenceFieldUpdater</code></li></ul><h2 id="非阻塞队列"><a href="#非阻塞队列" class="headerlink" title="非阻塞队列"></a>非阻塞队列</h2><p>非阻塞队列即不使用锁的队列,主要使用<a href="https://blog.csdn.net/qq_36865108/article/details/86679822" target="_blank" rel="noopener">CAS</a>操作保证原子性</p><h4 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h4><p>ConcurrentLinkedQueue是无界非阻塞队列.底层数据结构是单向链表,通过volatile分别修饰两个节点,这两个节点分别存放链表的头结点和尾节点来实现可见性,通过CAS操作保证节点入队出队时操作链表的原子性.</p><ul><li><p>offer():在队列尾部添加一个元素</p><ul><li>多线程情况下,如何实现多线程同时插入元素.前面说了,通过CAS实现入队时操作的原子性,看一下源码这一行<code>if (p.casNext(null, newNode))</code>,如果多线程同时执行到这一步,因为CAS操作<code>casNext</code>本身是原子的,如果有一个线程完成了操作,那么其他竞争的线程会重新进入这一行代码的上层循环尝试进行CAS操作,只有成功才会返回.</li><li>这个过程是无锁的,因为没有线程因为没有完成操作而被挂起阻塞,而是在无限循环中不断尝试,就是利用CPU资源换取阻塞引起的开销.孰是孰非,要具体分析.</li></ul></li><li><p>poll() : 从队头移除一个元素</p><ul><li>还是一行代码:<code>if (item != null &amp;&amp; p.casItem(item, null))</code>,可以看到,所谓的删除操作就是将当前节点的值设为null,然后重新指定头结点,被移除的节点没了引用,会在gc时被回收,因为整个队列维持了头结点和尾节点两个volatile变量,所以poll和offer并不冲突.</li><li>有一点需要注意,如果没有执行过offer操作就直接poll,会返回null.</li></ul></li><li><p>peek():获取头结点元素,不移除</p><ul><li>这个操作其实和poll类似,不过没有cas操作</li></ul></li><li><p>size() ; 获取队列长度</p><ul><li>这个方法有个问题,因为没有加锁,所以如果在调用size()的过程中可能发生增删的操作,造成统计不准确.</li></ul></li></ul><h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><h4 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h4><p>使用<a href="https://blog.csdn.net/qq_36865108/article/details/86692639" target="_blank" rel="noopener">ReentrantLock</a>实现锁机制,底层也是单向列表,也有两个节点存放头节点和尾节点,还有一个count代表元素个数.</p><ul><li><p>类中有两个ReentrantLock,分别用于添加和删除操作时的锁控制.LinkedBlockingQueue是一个有界的阻塞队列,可以初始指定容量,默认是0x7fffffff;</p></li><li><p>offer:队列尾部添加一个元素,队列已满返回false,方法不阻塞.</p><ul><li>offer操作的过程是这样的:先判断元素是否为空,为空抛出空指针异常;然后判断队列是否已满,如果已满返回false;构造新节点,获取putLock独占锁,<strong>再一次判断队列是否满</strong>,不满则入队列,计数+1,最后释放锁.了解了独占锁,这些其实很简单也很正常,解释一下加粗的内容,为什么要重新判断队列是否满.第一次判断队列是否满时还没有拿到独占锁,如果没有拿到独占锁而被挂起,后来再拿到锁时,可能已经有其他线程进入添加了元素,所以要重新判断.</li></ul></li><li><p>put() ; 类似offer,不过如果队列已满不会返回false,而是阻塞线程,直到队列空闲再插入</p><ul><li>具体实现还有一点需要注意,就是队列已满的等待和没有获取到锁的等待是不同的,前者,会将阻塞线程放到条件变量的条件队列中,后者则是放在AQS的阻塞队列中.具体看ReentrantLock源码那篇</li></ul></li><li><p>poll:从头部移除一个元素,如果队列为空返回null,该方法不阻塞</p><ul><li>其实实现和offer差不多,不过对应逻辑变一变.注意的是也要判断两次队列是否为空,道理一样.</li></ul></li><li><p>peek():获取头部元素但不删除,队列为空返回null.</p></li><li><p>take():类似poll,不过队列为空阻塞线程直到队列不为空.</p></li><li><p>方法是不是阻塞的,就是当队列满或空时是否阻塞线程.如果被阻塞的线程被其他线程调用了中断方法,会抛出<code>InterruptedException</code>异常而返回.</p></li><li><p>offer和put操作成功后,会通知被take操作阻塞的线程,类似的,take和poll操作成功后也会通知被put操作阻塞的线程.</p></li></ul><h4 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h4><p>底层通过数组实现的有界队列.维持两个下标,一个入队下标,一个出队下标.因为是数组,所以只使用一个独占锁,也就意味着同时只有一个线程进行入队和出队操作.</p><ul><li>offer() ; 向队尾插入一个元素,如果队列有空闲则插入成功并返回true ; 如果队列已满则丢弃当前元素放回false,如果插入元素为null返回空指针异常.<ul><li>如果添加成功,会通知一个被take操作阻塞的线程.put同</li></ul></li><li>put(); 操作,向队尾插入一个元素,如果队列有空闲则插入成功后直接返回true,如果队列已满则阻塞线程知道队列有空闲并插入成功并返回true;</li><li>poll():从头部移除一个元素,如果队列为空返回null;<ul><li>所谓移除,就是重置对头元素,重设对头下标</li><li>移除后会激活条件变量通知条件队列中因为队列满而被阻塞的线程.take同</li></ul></li><li>take();从头部移除一个元素,如果队列空,则阻塞线程.</li></ul><h4 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h4><p><code>PriorityBlockingQueue</code>是一个带优先级的无界阻塞队列,每次出兑都返回优先级最高或者最低的元素,内部采用平衡二叉树堆实现,所以直接遍历队列元素不保证有序,因为是带优先级的,所以队列元素必须实现<code>Comparable</code>接口,然后设置对象的<code>compareTo</code>方法,值得一提的是,最大堆还是最小堆是由这个方法决定的;底层采用数组存放元素,</p><ul><li><p>设置一个notEmpty条件变量控制删除时的数组为空的情况,维持一个条件队列,当队列中没有元素时,删除操作的线程会被放入这个队列</p></li><li><p>一个很重要的标志<code>allocationSpinLock</code>,只有两个状态0-1,0代表数组没有进行扩容,1代表数组正在进行扩容;</p></li><li><p>offer(E e) : 在队列中添加一个元素,由于是无界队列,所以只会返回true;方法内部,使用ReetrantLock加锁,当成功加入一个元素后,唤醒notEmpty条件队列中的一个阻塞线程,</p><ul><li>扩容问题 <code>tryGrow</code>:  <code>PriorityBlockingQueue</code>为了提高并发性能,使用CAS控制并发操作,而且在执行扩容操作前就释放了offer中添加的独占锁,使得其他线程可以进入,当其他线程拿到锁,进入了offer方法,但是扩容线程还没有完成扩容,就又进入了tryGrow方法,又释放了锁,但是进行CAS失败,不会影响到扩容线程;</li><li>建堆 : 在类中被没有真正的树形的堆,这个最大/最小堆是根据数组存在的,也就是从0-size-1遍历时,对应下标的值就是树形中的层次遍历的顺序,</li></ul></li><li><p>poll() : 获取队列内部堆树的根节点元素,如果队列温控,返回null,这个方法不是阻塞的,但是当一处根节点元素后,整个数组需要调整,建立新的堆;</p></li><li><p>put(E e) : 因为是无界的, 所以就是offer</p></li><li><p>take() : 获取队列中根节点的元素,如果队列为空,阻塞线程</p></li><li><p>size( ) : 安全的,内部加锁;</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>说说呗,AQS</title>
      <link href="/2019/09/11/shuo-shuo-bai-aqs/"/>
      <url>/2019/09/11/shuo-shuo-bai-aqs/</url>
      
        <content type="html"><![CDATA[<blockquote><p>AQS的文章之前写过一篇,还在CSDN,今天重新看了一边,就正好搬过来,顺便补充和修改一些  </p></blockquote><h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><p>AQS是抽象同步队列AbstractQueuedSynchronizer的简称,是实现同步机制的基础,并发包中的各种所谓的锁就是通过AQS实现的.</p><h4 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h4><p>顾名思义,锁支持,是rt.jar包中的工具类,提供硬件层次的挂起和唤醒锁<br>主要两个静态方法:</p><ul><li>LockSupport关联的许可证:根据名字看做一个黑盒的许可证</li><li>park():如果当前线程持有到许可证,调用pack方法后会马上返回,结束方法,如果没有持有许可证,就会挂起处于阻塞状态,线程默认情况下没有许可证.</li><li>unpark(Thread thread):获取许可证.有几种情况:<ul><li>先执行unpack,再执行pack,pack会直接返回,结束方法.</li><li>先执行pack,线程挂起,再执行unpack,线程被唤醒.</li></ul></li><li>还有一些带时限的方法,就不详细说了.毕竟是底层的东西,知道大意就可以了,一般用不上.</li></ul><h4 id="AQS使用"><a href="#AQS使用" class="headerlink" title="AQS使用"></a>AQS使用</h4><p>AQS给我的感觉像是一个”接口”(实际是一个抽象类),又像是一个底层工具类.其实就是<code>模板模式</code>,AQS中最重要的是其维持的一个单一的状态变量state(int),不同类型的锁机制就是通过对state的不同的定义来实现的.例如,可重入锁ReentrantLock,state可以用来表示当前线程获取锁的可重入次数;对于读写锁ReentrantReadWriteLock来说,state的高16位表示获取到的读锁的线程的可重入次数,低16位是写锁.对于smaphore来说,state用来表示当前可用信号的个数;对于CountDownlatch来说,state用来表示计数器当前的值.</p><ul><li>独占 and 共享<br>独占,顾名思义,就是这个锁同时只能被一个线程占有,共享就相反,在同一时刻可有有多个线程获得同步状态</li><li>AQS根据对于state的操作方式分为独占方式和共享方式:<ul><li>独占方式:<ul><li>获取资源<code>void acquire(int arg)</code>或<code>void acquireInterruptibly(int arg)</code></li><li>释放资源<code>boolean release(int arg)</code></li></ul></li><li>共享方式:<ul><li>获取资源<code>void acquireShared(int arg)</code>或<code>void acquireSharedInterruptibly(int arg)</code></li><li>释放资源<code>boolean releaseShared(int arg)</code></li></ul></li><li>光看这几个方法没什么用,但是暂时先记住名字,解释一下获取资源中的两个方法(即有无Interruptibly)的区别:有Interruptibly意味着要对中断进行响应,也就是说如果获取资源失败后进入挂起状态时,有其他线程中断该线程,该线程会抛出<code>InterruptedException</code>而中断,而没有Interruptibly的意味着忽略中断,不理睬其他线程的中断请求.</li></ul></li><li>获取资源和释放资源的过程:<ul><li>独占<ul><li>当一个线程调用acquire方法时,会使用tryAcquire方法尝试获取资源(可以暂时将这个方法视为一个黑盒),后续具体的操作就是设置状态变量的值,成功则直接返回,失败则将当前线程封装成AQS的一个内部类Node插入到AQS的阻塞队列尾部,并调用LockSupport.pack方法挂起自己.</li><li>当一个线程调用release方法时,会使用tryRelease方法释放资源,还是设置状态变量state的值,然后调用LockSupport.unpack方法激活AQS队列中的被阻塞的一个线程,被激活的线程使用tryAcquire尝试,看当前的state是否满足要求,满足则成功激活,失败则重进入队列挂起.</li><li>我上面说,将tryAcquire和tryRelease视为一个黑盒,是因为AQS并没有实现这两个方法,而是交由具体的子类自行实现.具体的操作也说了,就是通过CAS设置状态变量的值,来控制同步.</li></ul></li><li>共享<ul><li>类似独占,不同的是,获取资源失败的线程被封装称为Node.SHARED类型的Node节点插入队列,而独占中是封装称为Node.EXCLUSIVE类型的节点.</li></ul></li></ul></li></ul><h4 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h4><ul><li>条件变量ConditionObject也是AQS的内部类.有什么用呢?其实就是类似wait和notify,不过在AQS中称为await和signal.就是控制同步,你在基础编程中如何使用wait和notify,AQS实现类中就怎么使用await和signal.类似的,wait和notify一定要在synchronized代码块或方法中使用,await和signal也必须在实现类的lock和unlock中间使用.</li><li>内部实现<ul><li>过程是这样的:当前线程调用条件变量的await时(当前线程一定调用过lock方法,内部会构造一个类型为Node.CONDITION类型的node节点,然后插入到队列末尾(这个队列不是AQS的阻塞队列,是条件变量这个内部类中的一个条件队列),然后释放获得的锁,这时如果有其他线程使用lock获取锁,会获得锁.这时如果有另一个线程调用的了条件变量的signal方法,在内部会把条件队列中队头的一个节点从条件队列里面移到AQS的阻塞队列中,等待时机获取锁.</li></ul></li><li>一个AQS可以有多个条件变量,通过newCondition方法获取条件变量实例,这个方法也需要子类实现.</li></ul><h2 id="AQS底层"><a href="#AQS底层" class="headerlink" title="AQS底层"></a>AQS底层</h2><h4 id="同步队列"><a href="#同步队列" class="headerlink" title="同步队列"></a>同步队列</h4><p>AQS叫做抽象同步队列,自然是有个队列的,而队列的实现无非就是数组和列表,那就要深究一下这个队列是什么样子的.<br>看一下底层队列链表节点代码:  </p><pre class="line-numbers language-Java"><code class="language-Java">static final class Node {        /** Marker to indicate a node is waiting in shared mode */        static final Node SHARED = new Node();        /** Marker to indicate a node is waiting in exclusive mode */        static final Node EXCLUSIVE = null;        /** waitStatus value to indicate thread has cancelled */        // 节点从队列中取消        static final int CANCELLED =  1;        /** waitStatus value to indicate successor's thread needs unparking */        // 后继节点处于等待状态,如果当前节点释放锁,后继节点可以运行        static final int SIGNAL    = -1;        /** waitStatus value to indicate thread is waiting on condition */        // 节点进入等待状态        static final int CONDITION = -2;        /**         * waitStatus value to indicate the next acquireShared should         * unconditionally propagate         */         //下一次共享式同步状态获取将无条件传播下去        static final int PROPAGATE = -3;        // 节点状态        volatile int waitStatus;        // 前驱节点        volatile Node prev;        // 后继节点        volatile Node next;        //线程        volatile Thread thread;        //等待队列中的下一个节点        Node nextWaiter;        //省略一些构造方法        ....<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们可以看到,这是一个双向队列,可以绑定一个线程.同时,AQS中还有两个Node节点,<code>head</code>和<code>tail</code>,也就是头结点和尾节点,用来管理同步队列,实现获取锁失败入列和释放锁是出列等.  </p><p>我们可以看<code>acquire()</code>方法,这是获取独占锁的方法:</p><pre class="line-numbers language-Java"><code class="language-Java">    public final void acquire(int arg) {        if (!tryAcquire(arg) &&            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))            selfInterrupt();    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实很简单,就是如果能拿到锁,返回,如果没有拿到锁,就入队列,而这个<code>tryAcquire()</code>是抽象方法,也就是需要子类去实现的,而我之前也说了,其实就是去修改<code>state</code>这个状态变量.<br>然后说一下入队操作,就是将线程封装成节点,然后不断尝试CAS尾插入队列,不过有初始化头结点的过程.<br>这个链表的队列的头节点是一个虚节点，所以一般是用头节点的下一个节点获取锁（后面的头节点是指虚节点的下一个节点）<br>（这里也有ReentrantLock的公平锁和非公平锁的实现原理，公平锁在一个线程请求锁的时候会判断队列中是否还有节点，如果没有，当前线程去获取锁，失败放进队列，而如果有，则直接加入队列，而非公平锁会直接进行获取锁，公平与否就体现在这里。）<br>接着上面说，如果头节点在自旋中获取到了锁，就会设置当前节点为虚节点，这样，下一个节点就可以继续获取锁了，而在获取锁期间发生了异常（lockInterruptly则会相应中断，抛出异常），当前节点会被封装成cancel节点，然后唤醒后续节点获取锁。<br>有一张图很好,<a href="https://juejin.im/post/5aeb07ab6fb9a07ac36350c8" target="_blank" rel="noopener">copy</a>来的.<br><img src="1.png" alt><br>然后看一下释放锁: </p><pre class="line-numbers language-Java"><code class="language-Java">public final boolean release(int arg) {        if (tryRelease(arg)) {            Node h = head;            if (h != null && h.waitStatus != 0)                unparkSuccessor(h);            return true;        }        return false;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实重点是<code>unparkSuccessor()</code>方法,不过太长了,就简单说一下,就是获取头结点的后继节点,调用<code>LookSupport.unpark(Thread)</code>方法,唤醒线程.</p><p>其他就是可中断和一些时限的方法,大致是一样的,还有共享锁,其实就是把锁从一个变成n个,过程还是一样的. </p><h2 id="Condition原理"><a href="#Condition原理" class="headerlink" title="Condition原理"></a>Condition原理</h2><p>我们知道,每一个AQS可以拥有多个condition变量,而每一个condition变量都拥有一个等待队列,使用await()时,线程入队,使用signal()时出队列.这个等待队列节点还是AQS中的Node,还记得Node中有个<code>nextWaiter</code>节点,就是用来构造等待队列,所以可以知道,这是一个单向的队列.  </p><h4 id="await"><a href="#await" class="headerlink" title="await"></a>await</h4><p>当我们调用condition.await()方法后会使当前获取锁的`线程进入等待队列,具体是这样的.</p><ol><li>将当前线程封装成Node,尾插入队列</li><li>进入一个循环,不断的判断是否被唤醒,如果没有使用LockSuppor.pack(this)挂起当前线程</li><li>跳出循环的条件有两个,一个是被signal()唤醒,另一个是当前线程被中断.</li></ol><h4 id="signal-signalAll"><a href="#signal-signalAll" class="headerlink" title="signal/signalAll"></a>signal/signalAll</h4><p>使用condition的signal或signalAll可以将等待队列中等待时间最长的节点移动到同步队列中,因为是尾插,满足FIFO,所以头结点就是等待时间最长的,然后就是更改头节点的状态,然后尾插入同步队列.</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>AQS是JUC的基础,一般我觉得掌握整体的一个流程就可以了,然后熟练一点API,对于Lock的实现类和阻塞队列的实现的理解很有帮助.</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql的多种日志</title>
      <link href="/2019/09/11/mysql-de-duo-chong-ri-zhi/"/>
      <url>/2019/09/11/mysql-de-duo-chong-ri-zhi/</url>
      
        <content type="html"><![CDATA[<p>总结一下binlog undolog redolog</p><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>从大的方向来,binlog也就是二进制日志,是为了保证数据库的数据持久化的,而undolog 和redolog是数据库事务中保证事务的ACID的两个日志,然后就分开说:</p><h2 id="一条sql语句的执行链路"><a href="#一条sql语句的执行链路" class="headerlink" title="一条sql语句的执行链路"></a>一条sql语句的执行链路</h2><p>例如一条更新语句，执行链路如下</p><ol><li>如果buffer pool中没有对应的数据， 从磁盘加载这条数据</li><li>如果内存中没有数据，从磁盘加载后，记录一个undo log。直接写入磁盘，记录更新前的数据</li><li>更新内存中的数据</li><li>写redo log日志到内存</li><li>将redo log写入磁盘 prepare阶段</li><li>准备提交事物，将binlog文件写入磁盘</li><li>将修改的binlog文件名和修改的位置记录到redolog中，最后加入commit标记，commit标记表示此次事物成功提交了，除此之外都不算成功</li><li>会有一个后台线程，定时将内存数据写入磁盘。同时删除对应redolog</li></ol><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a><a href="https://www.cnblogs.com/f-ck-need-u/p/9001061.html#auto_id_4" target="_blank" rel="noopener">Binlog</a></h2><p>二进制日志包含了引起或可能引起数据库改变(如delete)的事件信息,但不包含例如select和show这样的查询语句.以事件的形式保存,包含了时间,时间开始和结束的位置等信息.<br>二进制日志是以事件形式记录的,所以对于事务的操作,二进制日志只在事务提交的时候一次性写入,对于非事务表的操作,执行完就直接写入.</p><h4 id="开启"><a href="#开启" class="headerlink" title="开启"></a>开启</h4><p>Mysql默认没有启动二进制日志,通过<code>--log-bin=[on|off|filename]</code>开启,或者通过修改my.ini文件.</p><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>二进制日志的作用就是为了定点恢复数据库和主从复制的时候使用.</p><ul><li>定点还原<br>可以选择基于时间点和位置的恢复,通过<code>mysqlbinlog</code>命令</li><li>主从复制<br>主从复制是基于3个线程的交互:</li></ul><ol><li>Master上面的binlog dump线程,负责将master的binlog event传到slave</li><li>Slave上面的IO线程,负责接收Master传过来的binlog,并写入relay log</li><li>slave上面的sql线程,读取relay log并执行</li></ol><h2 id="redo-log-undo-log"><a href="#redo-log-undo-log" class="headerlink" title="redo log , undo log"></a><a href="https://cnblogs.com/kismetv/p/10331633.html" target="_blank" rel="noopener">redo log , undo log</a></h2><p>之前说了,redo undo是在数据库事务中为了保证ACID而存在的,隔离性是由锁实现的,持久性通过redo实现,原子性和一致性通过undo log实现.仔细说说</p><h4 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h4><p>一般事务开始的时候就会产生redo_log,redo_log并不是随着事务的提交写入,而是在事务的执行过程中就写入,就是为了防止故障发生的时候,还有未写入磁盘的脏页数据,如果发生故障,会在重启mysql的时候,根据redo log进行重做.当事务的脏页数据写入磁盘后,redo_log的空间就会被覆盖.</p><h4 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h4><p>保存事务发生之前的数据的一个版本,可以用于回滚,同时可以提供多版本并发控制下的读(MVCC),也即非锁定读.<br>在事务开始前生成undo log,同时undo也会产生redo保证undo log的可靠性,当事务提交后,undo并不能立马删除,而是放入待清理的链表,由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息,决定是否可以清理undo log的日志空间.</p><h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><p>多版本并发控制,这是一个无锁的并发控制方法,从大的方向来看,就是通过<code>某种方法</code>实现让连接到数据库的瞬间看到数据库的一个快照,写操作完成之前对于其他用户是不可见的.那么重点就是这个某种方法.<br>当一个MVCC数据库乣更新一条数据的时候,并不是直接用新数据覆盖旧数据,而是将旧数据标记为过时,并在别处增加新版本的数据,这样就会有存储多个版本的数据,但是只有一个是最新的.总之,MVCC就是同一份数据临时保留多版本的一种方式,进而实现并发控制.然后就是实现了.</p><h4 id="MVCC插入"><a href="#MVCC插入" class="headerlink" title="MVCC插入"></a>MVCC插入</h4><p>当我们建表时,每个表都有三列隐藏记录,和MVCC有关系的就是<code>DB_TRX_ID</code>(数据行版本号)和<code>DB_ROLL_PT</code>(删除版本号),当我们插入数据时,会将事务ID记录到<code>DB_TRX_ID</code>中.</p><h4 id="MVCC删除"><a href="#MVCC删除" class="headerlink" title="MVCC删除"></a>MVCC删除</h4><p>同样的,当我们删除时,也会将全局事务ID记录到<code>DB_ROLL_PL</code>中</p><h4 id="MVCC修改"><a href="#MVCC修改" class="headerlink" title="MVCC修改"></a>MVCC修改</h4><p>当我们修改数据的时候,会先复制一条当前记录行数据,同事标记这条数据的数据行版本号为当前事务版本号,最后把原来数据行的删除版本号标记为当前事务.</p><h4 id="MVCC查询"><a href="#MVCC查询" class="headerlink" title="MVCC查询"></a>MVCC查询</h4><ul><li>查找数据行版本号早于当前事务版本号的数据行记录<br>也就是说,数据行的版本号要小于或等于当前事务的系统版本号,这样也就确保读取到的数据时事务开始前已经存在的数据</li><li>查找删除版本号要么为null,要么大于当前事务版本号的记录<br>这样才能确保查询出来的数据在事务开启之前没有被删除</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>整体看下来并不复杂,就是通过两个版本号来保证读取和写入的时间合理性.MVCC用在数据库事务的RC隔离性中,我们知道RC保证了不发生脏读,当发生写操作的时候通过排它锁,而读操作就是MVCC,因为MVCC可以读取到被锁住的数据的其他版本,并发量就up了</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring IOC底层分析</title>
      <link href="/2019/09/09/spring-ioc-di-ceng-fen-xi/"/>
      <url>/2019/09/09/spring-ioc-di-ceng-fen-xi/</url>
      
        <content type="html"><![CDATA[<blockquote><p>欢迎大神指正</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>关于IOC底层的东西,我这里只是说一下大致的流程,不涉及具体的代码(能力有限).</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="IOC初始化-xml角度"><a href="#IOC初始化-xml角度" class="headerlink" title="IOC初始化(xml角度)"></a>IOC初始化(xml角度)</h2><ul><li><p>IOC容器的初始化分为三个过程以及我们在使用spring时的代码对应(不是完全一一对应,这是顶层的方法,内部有较多的细节):</p><ul><li>Resource定位:<code>ClassPathReource resource = new ClassPathReource(&quot;bean.xml&quot;);</code></li><li>BeanDefinition的载入和解析: <code>DefaultListableBeanFactory factory = new DefaultListableBeanFactory();</code>  , <code>XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);</code></li><li>BeanDefinition注册: <code>reader.loadBeanDefinition(resource);</code></li><li>怎么理解BeanDefinition,可以将BeanDefinition在IOC初始化的地位看做是JVM中类的Class对象在类初始化中的地位,虽然二者没什么关系,但是好理解一些.</li></ul></li><li><p>Reource定位</p><ul><li>主要是两个接口:<code>Resource</code>Spring中的统一资源抽象接口;<code>ResourceLoader</code>是统一的资源加载抽象接口</li><li>具体的方法实现不细说,只需要知道接口的具体实现类会将外部的资源加载到Spring中,当然是以被封装的形式存在.<code>(resource-&gt;EncodedResource)</code>.最后会以EncodedResource对象的形式用于bean的后续初始化.</li></ul></li><li><p>BeanDefinition的载入和解析</p><ul><li>EncodedResource并不是直接就转换成BeanDefinition对象,而是要先转换成Document对象,然后再转换为BeanDefinition对象.这样做的原因也很简单,就是Document更方便.  </li><li>从EncodedResource到Document的转换过程有很多细节(比如文件解析器,错误处理,命名空间的问题),这里暂时将这个过程看做黑盒.</li><li><code>Document -&gt; BeanDefinition</code>的过程其实主要是和对Document的操作有关,也就是对xml标签的处理,有默认标签和自定义标签,不详细说.</li></ul></li><li><p>注册BeanDefinition</p><ul><li>IOC是什么?在逻辑定义层面有很多形象通俗的解释,我见过最好的一篇是<a href="https://www.cnblogs.com/wang-meng/p/5597490.html" target="_blank" rel="noopener">这个</a>,这里我们说一下代码层面的,代码层面的IOC容器其实就是一些Map,有存储BeanDefinition的Map,有存储实例化后的单例Bean的Map等等.这里先说一下存储BeanDefinition的Map.</li><li>这是一个ConcurrentHashMap,源代码如下:<br><code>private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256);</code><br>所谓注册,就是添加进入这个Map的过程,这里的key是beanName;</li></ul></li><li><p>初始化的过程就是这样,用一张图结束吧(copy来的):<br><img src="https://img-blog.csdnimg.cn/20190201145638843.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2ODY1MTA4,size_16,color_FFFFFF,t_70" alt="bean初始化"></p><h2 id="Bean实例化"><a href="#Bean实例化" class="headerlink" title="Bean实例化"></a>Bean实例化</h2></li><li><p>实例化时机分为很多种,一是使用BeanFactory和ApplicationContext的区别,二是Bean单例和多例的区别,三是单例情况下设置延迟加载的区别;</p></li><li><p>如果是非延迟加载,那么会在容器启动时实例化bean.</p></li><li><p>如果是延迟加载,那么Bean的加载就是第一次显示或隐式的调用<code>getBean</code>方法(该方法调用doGetBean方法),所以从这个方法开始:</p><ol><li>转换beanName,因为<code>getBean</code>传入的name不一定是beanName,可能传入的是<code>aliasName</code>或<code>FactoryBean</code></li><li>从缓存中获取bean,这里需要根据bean的作用域分一下情况:<ul><li>单例:spring的IOC只会保存一个对象实例,所有该对象的引用都共享这个实例,Spring容器只会创建唯一一个实例,保存在缓存中,并对该bean的后续请求和引用都会返回到该缓存的对象实例中.</li><li>多例:每次对bean的请求都会返回一个新的实例</li><li>其他<ul><li>request : 每次http请求都会有一个bean实例</li><li>session: 一个session中,一个bean定义对应一个bean实例</li></ul></li><li>所以,从缓存中获取的bean一定是单例的,这里的缓存也是一个Map,名为<code>singletonObjects</code>,同层次还有两个Map,一个是<code>earlySingletonObjects</code>,另一个是<code>singletonFactories</code>.分别保存早期单例对象和bean工厂.之所以使用三个缓存,是为了解决bean之间的循环依赖.</li></ul></li><li>缓存中没有找到的话,会在父容器的缓存中寻找</li><li>如果没有父容器或者父容器中也没有就会创建bean实例对象.这里的方法是<code>createBean</code><ul><li>如果<code>createBean</code>维持的一个缓存中没有对应bean的<code>beanWrapper</code>,这里会先创建<code>BeanWrapper</code>,这是一个对要实例化Bean的包装.创建BeanWrapper的方法是<code>createBeanInstrance</code>,同时,这个方法也是非单例bean的创建实例的方法.使用的就是初始化时创建的<code>BeanDefinition</code>,大致的步骤就是确定构造方法,然后实例化.实现起来有很多细节,比如如果有动态代理,就需要使用<code>Java动态代理</code>或<code>cglib</code>来实例化,否则使用反射实例化.</li><li>回到<code>createBean</code>方法,得到<code>BeanWrapper</code>对象后,就要进行一系列的处理,主要是属性注入和循环依赖的处理.然后初始化Bean.</li><li>初始化Bean主要是为了完成用户设定,例如激活Aware方法,应用后置处理器方法,激活自定义的方法.</li></ul></li><li>得到了bean实例,但是并没有结束,无论是从单例缓存中获取的或者<code>createBean</code>中创建的bean,都只是bean实例,还需要从bean实例中获取对象.这里很难理解,bean实例难道不是对象吗,我看的博客中都是这样说的,但是从我的理解来看,这里的bean实例其实是<code>FactoryBean</code>实例,不知道<code>FactoryBean</code>的可以了解一下.总之,最后需要从<code>FactoryBean</code>中拿到对象,其实就是调用了<code>getObject</code>方法,不过框架嘛,你懂得,总是需要处理很多情况,所以嵌套的比较深,可以从<code>getObjectForBeanInstance</code>和<code>getObjectFromFactoryBean</code>两个方法入手自己看一下.</li><li>主要的流程就是这样,但是旁支的东西数不胜数,代码远多于这些主线的内容,这里就主线内容说一下.</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java线程池如何定时回收空间线程探究</title>
      <link href="/2019/09/09/java-xian-cheng-chi-ru-he-ding-shi-hui-shou-kong-jian-xian-cheng-tan-jiu/"/>
      <url>/2019/09/09/java-xian-cheng-chi-ru-he-ding-shi-hui-shou-kong-jian-xian-cheng-tan-jiu/</url>
      
        <content type="html"><![CDATA[<h2 id="疑惑"><a href="#疑惑" class="headerlink" title="疑惑"></a>疑惑</h2><p>说到线程池,其实已经看过很多遍源码,不过大多是复用和阻塞队列获取时的部分,今天突然想到,线程池有个最大空闲时间,即空闲线程最大存活时间,我想知道怎么实现计时的,难道是每一个worker类中一个计时器吗?</p><h2 id="解惑"><a href="#解惑" class="headerlink" title="解惑"></a>解惑</h2><p>找了很多博客,都没有找到,只能自己在源码里找了,意外地好找,因为用到<code>keepAliveTime</code>这个变量,整个<code>ThreadPoolExecutor.java</code>中只有一个方法,只看这个方法就可以了,这个方法是<code>getTask()</code>,其中用到<code>keepAliveTime</code>的代码是这样的:</p><pre class="line-numbers language-Java"><code class="language-Java"> try {        Runnable r = timed ?workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :                workQueue.take();        if (r != null)            return r;        timedOut = true;    } catch (InterruptedException retry) {            timedOut = false;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中最重要的就是这句<br><code>workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</code><br>有什么用呢,看一下<code>workQueue</code>是什么:<br><code>private final BlockingQueue&lt;Runnable&gt; workQueue;</code><br>一个阻塞队列,即 核心线程数 =&lt; 当前线程数 &amp;&amp; 当前线程数 &lt; 最大线程数时,我们将任务封装放进一个阻塞队列,这就是那个阻塞队列;<br>然后看这个阻塞队列方法<br><code>E poll(long timeout, TimeUnit unit)</code><br>源码解释是这样的</p><blockquote><p>Retrieves and removes the head of this queue, waiting up to the specified wait time if necessary for an element to become available.<br>检索并删除此队列的头节点元素，如果需要，将等待到指定的等待时间，直到元素可用为止。</p></blockquote><p>其实熟悉阻塞队列就应该知道取出元素的方法有两个<code>poll()</code>和<code>take()</code>,前者是一个非阻塞方法,如果当前队列为空,直接返回,而take()是一个阻塞方法,即如果当前队列为空,阻塞线程,封装线程到AQS的条件变量的条件队列中,而上面的方法是一个介于二者之间的方法,语义是如果队为空,该方法会阻塞线程,但是有一个阻塞时间,如果到时见还没有被唤醒,就自动唤醒;</p><p>看到这里就应该知道了,我们的线程在获取任务时,如果队列中已经没有任务,会在此处阻塞<code>keepALiveTime</code>的时间,如果到时间都没有任务,就会return null(不是直接返回null,是最终),然后在<code>runWorker()</code>方法中,执行<br><code>processWorkerExit(w,completedAbruptly);</code><br>终止线程;</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内核线程-用户线程-理解</title>
      <link href="/2019/09/06/nei-he-xian-cheng-yong-hu-xian-cheng-li-jie/"/>
      <url>/2019/09/06/nei-he-xian-cheng-yong-hu-xian-cheng-li-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="内核态和用户态"><a href="#内核态和用户态" class="headerlink" title="内核态和用户态"></a>内核态和用户态</h2><ul><li>内核态: CPU可以访问内存的所有数据,包括外围设备,例如网卡,cpu也可以将自己从一个程序切换到另一个程序. </li><li>用户态: 只能受限的访问内存,且允许访问外围设备,占用cpu的能力被剥夺,cpu资源可以被其他程序获取.<br>之所以划分内核态和用户态,是为了限制不同程序之间的访问能力,防止他们获取其他程序的内存数据,或者外围设备的数据.<br>程序运行在用户态,但有时候需要做一些内核态的事情,比如从硬盘读数据,这个时候就需要从用户态切换到内核态,切换的机制就叫做<code>系统调用</code>.</li></ul><h2 id="内核线程-用户线程-轻量级进程"><a href="#内核线程-用户线程-轻量级进程" class="headerlink" title="内核线程,用户线程,轻量级进程"></a>内核线程,用户线程,轻量级进程</h2><p>有了上面的关于内核态和用户态的理解,理解下面就很容易了:  </p><ul><li>内核线程:<br>内核线程就是内核的分身,一个分身可以处理一件特定的事情,内核线程只运行在内核态,不受用户态上下文的拖累.</li><li>轻量级进程:<br>轻量级进程是建立在内核之上并有内核支持的用户线程,它是内核线程的高度抽象,每一个轻量级进程都与一个特定的内核线程关联.它是内核线程的一个高级接口。</li><li>用户线程:<br>用户线程是完全建立在用户空间的线程库,用户线程的创建,调度,同步,销毁全由库函数在用户空间完成,不需要内核的帮助,其内部的活动对于内核是透明的,</li></ul><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>先说一下线程实现模型,也就是1:1,N:1,N:M,分别说一下:</p><ul><li>轻量级进程:内核线程 = 1:1<br>这也是Java的线程实现模型,一个用户线程映射到一个内核线程,所以用户空间的切换就涉及到了内核态的线程的切换.</li><li>用户线程:内核线程 = N : 1<br>1:1的模型性能开销较大,而且受限于线程数量的限制,而N:1的模型在用户空间完成线程间的同步,销毁,切换,对于内核来说是完全透明的,不涉及线程的切换</li><li>用户线程:内核线程 = N : M<br>N:1的缺点在于操作系统无法感知到用户态的线程,所以可能造成一个线程进行被阻塞,导致整个进程被阻塞.<br>N:M的模型就解决了这个问题,而这也是实现原生协程的关键</li></ul><p>我们知道Java是没有原生的协程的,比较著名的协程语言应该就是GO了,Go就是使用了N:M的模型实现自己的调度器,<br>协程是怎样的呢?其实使用的目的和多线程差不多,都是为了实现并发,只是线程在有些时候过于重了,这都是相对而言,就好像进程的调度比之线程很重,协程更多的是一种暂停的概念,而线程就是上下文切换,我们可以再一个线程中.通过协调器来暂停继续不同的协程而不用线程的上下文切换,从而实现不同协程的交替运行.这个暂停继续都是在用户空间进行的,所以并没有用户态到内核态的切换,更没有内核态的上下文切换.<br>协程也是更加适合IO频繁的程序,我使用过的协程是python的gevent,在gevent的猴子补丁中,专门为socket的相关方法添加了补丁,当我们使用socket的相关方法时,如果发生阻塞等待,比如<code>requests.get()</code>,就会自动切换到其他协程,非常好用.可以尝试一下.</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTPS 再看一次</title>
      <link href="/2019/09/06/https-zai-kan-yi-ci/"/>
      <url>/2019/09/06/https-zai-kan-yi-ci/</url>
      
        <content type="html"><![CDATA[<h2 id="Https"><a href="#Https" class="headerlink" title="Https"></a>Https</h2><p>https比http多了一个s,在网络层次上多了一层,即SSL/TLS,位于TCP之上,HTTP之下,也就是在发送http请求之前先进行一次安全验证,具体的流程是这样的:<br><img src="1.png" alt><br>握手阶段分为5步:</p><ol><li>客户端给出协议号,一个客户端生成的随机数(client random),一级客户端支持的加密方法.  </li><li>服务器确定双方使用的加密方法,并给出数据证书,以及一个服务器生成的随机数(Server random).  </li><li>客户端<code>确认数据证书有效</code>,然后生成一个新的随机数(Premaster secret),并使用数据证书的公钥,加密这个随机数,发给服务器.</li><li>服务器使用自己的私钥,获取客户端发来的随机数(Premaster secret)</li><li>服务器和客户端根据约定的加密方法,使用前面的三个随机数,生成对话秘钥(session key),用来加密接下来整个对话过程</li></ol><p>这个过程是简单的,重点在于上面标注的内容<code>确认数据证书有效</code></p><h2 id="确认证书有效"><a href="#确认证书有效" class="headerlink" title="确认证书有效"></a>确认证书有效</h2><p>首先我们先知道证书是什么:<br>数字证书中包含了由某个受信任组织担保的用户或公司的相关信息,所有信息都是由一个官方的证书颁发结构(CA)以数字方式签发的,数字证书还包含对象的公开秘钥,以及对象和所用签名算法的描述性信息,任何人都可以创建一个数字证书,但并不是所有人都能获得<code>被认可</code>的,什么叫被认可?也就是很权威的机构颁发的,这样的证书,一般浏览器会预先安装其签名颁发的证书,拥有其公开秘钥.<br>我们还可以自制证书,与被认可的证书相比,就是浏览器可能无法需要提示你是不是信任这个证书.  </p><p>验证证书有效其实有两个方面,一个方面是证书的颁发机构,过期时间等等,另一个就是这个身份验证. </p><p>身份认证的内容有待深究</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java OOM触发条件小记</title>
      <link href="/2019/09/05/java-oom-hong-fa-tiao-jian-xiao-ji/"/>
      <url>/2019/09/05/java-oom-hong-fa-tiao-jian-xiao-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>关于Java OOM的一些疑惑,对于GC回收和OOM触发条件的一些疑惑</p><h2 id="简单说说GC"><a href="#简单说说GC" class="headerlink" title="简单说说GC"></a>简单说说GC</h2><p>我们知道GC分为Minor GC和Full GC(Major GC另说),当eden区无法再分配空间给当前对象时,触发minorGC,而fullGC的触发条件就很多了,总结一下:</p><ol><li><p>使用<code>System.gc()</code></p></li><li><p>方法区无法分配对象</p></li><li><p>Minor GC前,通过预测之前每次晋升老年代的平均大小(加权平均值)是否大于老年代的剩余空间大小,如果大于,直接full GC</p></li><li><p>对象默认分配到eden,如果对象过大(参数配置),则直接分配到老年代,同时大于老年代剩余大小,full GC<br>上面说到,年轻代晋升老年代,大家都知道的是当在年轻代的年龄达到一定值(默认15)时,会晋升,但其实还有一种,就是<code>内存空间分配担保</code></p><h4 id="内存空间分配担保"><a href="#内存空间分配担保" class="headerlink" title="内存空间分配担保"></a>内存空间分配担保</h4><p>这里我们先测试,然后看图说话(例子来自<a href="https://mp.weixin.qq.com/s?__biz=MzA5MzQ2NTY0OA==&mid=2650797224&idx=1&sn=5819bd097e6dabab34db382be2d0182c&chksm=885629f7bf21a0e1fe382626f8d272ee9c4066109f329ef93a205c29e37e9376f455c1710903&scene=21#wechat_redirect" target="_blank" rel="noopener">这里</a>,但是改了一点):  </p><pre class="line-numbers language-Java"><code class="language-Java">public class Test { private static final int _1MB = 1024*1024 ; static void test(){     byte[] allocation1,             allocation2,             allocation3,             allocation4;     allocation1 = new byte[2*_1MB];     allocation2 = new byte[2*_1MB];     allocation3 = new byte[_1MB];     allocation4 = new byte[_1MB]; } public static void main(String[] args) {     test(); }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行参数: <code>-Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps</code><br>然后看GC日志<br><img src="3.png" alt><br>可以看到,是当内存大小为7265K的时候触发了minorGC,但是按理说,6M的对象6144,eden大小8192K,不会触发的,<br>但我们算一下,5M的对象是5120K,我们要算上一些内置对象和对象头的大小,当分配5M时,新生代已占7265K了,是无法分配剩下的1M的,<br>然后我们看到结果,youngGen的变换是7265K -&gt; 915K,而总的堆的变换是7562k-&gt;6044K,可以得到什么呢,GC开始时,eden大小是7265K,老年代大小是0K,GC后,新生代大小为915K,而老年代大小为6044-915 = 5129,就是我们那5M对象,<br>fullGC将eden转为0(先不管那个fullGC),再看最后的heap属性,新生代大小是1106K,就是那1M,也就是说,之前的5M被晋升到了老年代,而当前的1M对象就分到了新生代.<br>总结一下,当当前对象大于eden剩余空间,触发minorGC,<code>然而survivor(from,to)无法放下活下来的对象</code>,而剩余对象年龄也不到晋升年龄,所以只能老年代来承受,也就是把新生代的对象移到老年代,再分配新对象到eden.<br>然后我们说说上面的full GC的事情,看下面这段程序:  </p><pre class="line-numbers language-Java"><code class="language-Java">public class Test3 { private static final int _1MB = 1024*1024 ; static void test(){     byte[] allocation1,             allocation2,             allocation3,             allocation4;     allocation1 = new byte[2*_1MB];     allocation2 = new byte[2*_1MB];     allocation3 = new byte[2*_1MB]; } public static void main(String[] args) {     test(); }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>只是把两个<code>_1MB</code>合成一个,结果就不一样了,<br><img src="4.png" alt><br>可以看到没有full GC了,有一篇<a href="https://cloud.tencent.com/developer/article/1082687" target="_blank" rel="noopener">博客</a>有说到这个,根据这个,本人只能猜测一番,是GC调节暂停时间和吞吐量之间的一种平衡.</p></li></ol><h2 id="OOM测试"><a href="#OOM测试" class="headerlink" title="OOM测试"></a>OOM测试</h2><blockquote><p>&lt;深入理解Java虚拟机&gt;测试用例  </p></blockquote><p>首先看程序</p><pre class="line-numbers language-Java"><code class="language-Java">public class Test {    static class OOMObject{    }    public static void main(String[] args) {        List<OOMObject> list = new ArrayList<>();        while (true){            list.add(new OOMObject());        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行的vm option :<br><code>-Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8</code></p><p>之所以这样设置,是为了更好的观察.然后看一下结果:<br><img src="2.png" alt><br>知道了前面的内存空间分配担保,就很好理解这个结果了,前两次GC都是MinorGC,都有第一次有内存空间担保,第二次Minor GC时已经无法担保,就有了Full GC协调,等youngGen和ParOldGen都无法再分配,就有了OOM.大概是这样一个过程.</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存和DB一致性问题</title>
      <link href="/2019/09/04/huan-cun-he-db-yi-zhi-xing-wen-ti/"/>
      <url>/2019/09/04/huan-cun-he-db-yi-zhi-xing-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="问题何在"><a href="#问题何在" class="headerlink" title="问题何在"></a>问题何在</h2><p>先说下缓存的意义,简单来说,就是为了减少数据库压力,如果缓存是基于内存的,那么系统性能也会大大提升.<br>但是问题也伴随而来,如果我们的系统或者相关业务并不大,可以把数据全部加到缓存,比如一个秒杀,抢红包,可以直接操作缓存,等抢购结束,再写回数据库.但是如果数据多了,肯定就不能这样,我们就要制定策略来同时更新数据库和缓存,并保证二者的一致性</p><h2 id="先删缓存-再修改数据库"><a href="#先删缓存-再修改数据库" class="headerlink" title="先删缓存,再修改数据库"></a>先删缓存,再修改数据库</h2><p>也就是有一个写请求,我们把相关的缓存先删除,然后去修改数据库,如果后面有请求访问该数据,会直接到数据库,然后再把值写回缓存.<br>当然,这是理想的情况,现实是在我们的写请求删除缓存和写数据库之间可能有另一条请求访问该数据,然后在缓存中没有找到,就在数据库读到了旧数据,再写回了缓存,然后写请求再更新数据库,这个时候就有了数据库缓存不一致的情况.</p><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><ul><li>分布式锁 :<br>使用分布式锁的意义很简单,就是保证写请求操作的时候,没有其他请求影响,就是一个排他锁.具体的加锁情况是这样.<br>在写请求删除缓存前请求分布式锁,更新完数据库后释放锁.<br>在读请求发现缓存为空的时候,请求分布式锁.<br>很容易理解,同时这个办法也保证了强一致性,也就是任何时刻,缓存和数据库都是一致的,问题是只适合写请求少的情况,如果写请求过多,频繁的加锁会导致性能下降</li><li>延迟双删<br>如果我们不要求强一致性,用这个办法是可以的,其实很简单,就是在上面先删缓存,再修改数据库的基础上,等我们修改数据库完后,再次删除缓存,同时我们可以把第二次删除缓存以异步的形式进行,这个其实更容易理解,但是会有短暂的不一致,但是可以保证最终一致性.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka相关</title>
      <link href="/2019/09/03/kafka-xiang-guan/"/>
      <url>/2019/09/03/kafka-xiang-guan/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><h4 id="消息队列的使用场景"><a href="#消息队列的使用场景" class="headerlink" title="消息队列的使用场景:"></a>消息队列的使用场景:</h4><ul><li>应用解耦</li><li>异步处理</li><li>流量削峰</li><li>消息通讯</li><li>日志处理<br>重点应该是前两个.至于这些东西具体怎么应用,我觉得要等到我工作中遇到这些场景.</li></ul><h4 id="使用消息队列有什么缺点"><a href="#使用消息队列有什么缺点" class="headerlink" title="使用消息队列有什么缺点"></a>使用消息队列有什么缺点</h4><p>很明显的,系统可用性降低,因为凭空多了一个服务,我们需要保证消息队列的高可用.<br>其次应该是系统更加复杂了,所以所我们学习可能弄的越复杂越好,但实际做起来,如果不需要,就不要给自己添加麻烦.<br>一致性也是一个问题,就好像缓存和数据库的一致性问题,这个时候我们就需要提供分布式的事务来管理.</p><h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><h4 id="kafka高吞吐量如何实现"><a href="#kafka高吞吐量如何实现" class="headerlink" title="kafka高吞吐量如何实现?"></a>kafka高吞吐量如何实现?</h4><p>这个问题在我面试网易的时候被问了两次,当时回答的不好,现在总结一下:  </p><ul><li>顺序IO<br>kafka可以保证单个partition的写入顺序性,而且kafka并没有提供删除和更新的操作,所以kafka会使用顺序读写磁盘中存储的文件,我们知道,顺序读写的速度比随机读写的速度可快一个数量级.但是磁盘就是磁盘,始终比不过内存,kafka为什么不用内存来保存呢,问题就是kafka是为海量数据而生的,不论是流式计算中的数据源,还是服务间的消息传递,都不是内存可以承担的,还有一点就是,我们知道kafka是用scala,java开发的,是运行在JVM上的,这就离不开GC了,如果存储在内存中,频繁的GC也不是一个高吞吐量的消息队列应该有的.</li><li>零拷贝<br>linux的zero-copy大家都知道,熟悉的就是mmap(内存映射文件),kafka就使用了这个.<br>还是重新说一下零拷贝,正常情况下,客户端从服务器读取数据是这样的过程:  </li></ul><ol><li>操作系统将数据从磁盘读到内核空间的读缓存</li><li>应用程序从内核读缓存中将数据拷贝到用户空间的缓存区</li><li>应用程序将数据从用户空间的缓冲区再写回到内核空间的socket缓冲区</li><li>操作系统将socket缓冲区的数据拷贝到NIC缓冲区中,然后通过网络发送给客户端<br>使用了零拷贝就不用经过用户空间了,直接将内核空间的度缓冲区直接拷贝到内核空间的socket缓冲区,再到NIC缓冲区.</li></ol><ul><li>分区<br>我们知道kafka将数据以topic在逻辑层面划分,而在物理层面,每个topic会被划分为多个partition,每个partition对应一个逻辑log,由多个segment文件组成.<br>partition存放在不同的broker,当生产者发布消息的时候,可以做一个负载均衡,然后分布到不同的partition,同样的,消费者拉取消息的时候,也可以做一个负载均衡,使从不同的broker中拉取,这样大大提升了吞吐量.</li><li>数据批量发送<br>顾名思义</li><li>消息压缩<br>provider 可以将消息压缩发送给broker</li><li>利用page cache<br>文件系统缓存，不直接写磁盘， </li></ul><h4 id="kafka的高可靠如何实现"><a href="#kafka的高可靠如何实现" class="headerlink" title="kafka的高可靠如何实现?"></a>kafka的高可靠如何实现?</h4><p>这个问题同样被问到过,和上面那个问题一样,都是基础问题,分几个角度吧</p><ul><li>zk<br>我们知道zk负责整个集群的信息注册和协调,所以保证zk的高可用也是kafka的一部分,这里zk也采用集群,节点数一般为2N+1,有自己的leader选举算法,之后再说</li><li>broker集群<ul><li>上面我们说到每个topic会有多个partition分区,那么partition的可靠性也就是整个topic的可靠性,这里kafka使用副本机制来保证,每个partition在broker集群中复制,形成<code>replica</code>副本,而每个replica副本会有一个leader分区,当leader挂了,会通过<code>ISR(In-Sync Replica 同步副本队列)</code>列表选举出一个leader.下面详细说一下ISR:  </li><li>副本并不是越多越好,虽然保证了可靠性,但是性能就下去了,在kafka中,replica默认是1,也就是没有副本,就一个leader,但是这个值可以设置. 所有的副本被称为<code>Assigned Replicas</code>,也就是AR,ISR时AR中的一个子集,由leader维护ISR列表,<code>follower(除leader的replica)</code>从leader同步数据有一点延迟,超过阀值的follower就会被踢出ISR,加入<code>OSR(outOf-Sync Replica)</code>列表,新加入的follower也会先存放在OSR中,我们就得到了<code>AR = ISR + OSR</code>  </li><li>接着说,现在我们有两个列表,再介绍一个概念,<code>HW(HighWatermark)</code>,俗称高水位,取一个partition对应的ISR中最小的<code>LEO(LogEndOffset,每一个partition的消费偏移量)</code>最为HW,consumer只能消费到HW的位置,没次leader写入新的消息,consumer并不能直接消费,而是等待所有ISR中的replica同步后更新HW,这条消息才能被消费.</li><li>这样,我们就有了ISR这样一个保证同步的列表,然后就是选举算法:  kafka选举算法类似PacificA算法,上面我们知道,只有ISR中的follower才可能称为leader,当ISR中至少有一个follower时,就可以了确保已经commit的消息没有丢失.  </li><li>具体的选举算法是依托于zk的,通过在zk上创建一个controller节点来实现leader选举,并在该节点中写入当前broker信息就完成了选举,根据zk的强一致性,一个节点只能被一个客户端创建成功,创建成功就代表该broker称为leader,也就是先到先得.</li><li>对于所有replica都不可用的情况，一般会等待一个replica醒过来，一种是等待isr中的一个，另一种是等待任意一个replica醒过来。可以通过参数设置，默认是第二种</li></ul></li><li>kafka producer<br>producer从zk中拉取到topic元数据（/brokers/…/state）后,选择对应topic的leader分区,进行消息发送写入,而Broker根据<code>request.required.acks</code>配置,选择是否同步,同步多少replica才完成响应.</li></ul><h4 id="kafka数据存储模型"><a href="#kafka数据存储模型" class="headerlink" title="kafka数据存储模型"></a>kafka数据存储模型</h4><p>之前我们说过kafka数据是保存在磁盘的额,而且是顺序IO,那我们就看一下这个文件是什么.<br>每个partition都会对应一个日志目录,在目录下面会对应多个日志分段,大概是这样子:<br><img src="1.png" alt><br>其中Topic名字是<code>Test</code>,Partition是<code>0</code>,所以文件目录是<code>Test-0</code>;<br><code>LogSegment</code>由两部分组成,分别是.index和.log文件,分别表示segment索引文件和数据文件,这两个文件的命令规则为partition全局第一个segemnt从0开始,后续每个segment文件名为上一个segemnt文件最后一条消息的offse值,假设有1000条消息,每个Logsegment大小为100,那内部就是这样的:<br><img src="2.png" alt><br>索引文件存储元数据,类似1,0  3,200 意思是在数据文件中第一个message的在数据文件中的偏移量是0,第三个message的偏移量是200.<br>如果是在partition中查找message,先假设每个segemnt的大小为100,然后900-1000的index和log如下:<br>我们全局寻找第911条数据,先定位是那一段,找到00000000…900.index|log文件,然后再其内部寻找(911-900)11索引,找到了[10,1367],然后再log文件中,从1367的偏移量开始顺序找,就可以了找到911的文件了.图有点问题</p><p>#### </p><h2 id="后"><a href="#后" class="headerlink" title="后"></a>后</h2><blockquote><p>内容是从网上搜罗而来</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 消息队列 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 消息队列 </tag>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库索引</title>
      <link href="/2019/09/02/shu-ju-ku-suo-yin/"/>
      <url>/2019/09/02/shu-ju-ku-suo-yin/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库索引"><a href="#数据库索引" class="headerlink" title="数据库索引"></a>数据库索引</h1><p>索引真的是绕不开的话题,今天开这个博客不是扫盲,而是说一点深入的东西.</p><h2 id="底层结构"><a href="#底层结构" class="headerlink" title="底层结构"></a>底层结构</h2><p>有这样一张图<br><img src="1.png" alt><br>是各个数据库引擎支持的索引类型,这里说一下Hash索引和B+Tree索引,剩下的自行了解,Hash索引比较简单,就是一个hash表,任何数据的查询都是O(1),但是只适合 <code>=</code>的查询.<br>然后就是B+ Tree索引,老生常谈了,至于为什么使用B+树不用B树,什么的面试题我就不说了.  </p><h4 id="InnoDb"><a href="#InnoDb" class="headerlink" title="InnoDb"></a>InnoDb</h4><p>当我们创建一个表的时候,如果不指定主键,是无法创建表的,因为数据库需要默认创建一个主键索引,而此时该表的存储结构也就不是简单的一行一行了,而是转变成树状结构存储,因为这样,叶子节点存储的就是行数据,所以主键索引也被称为聚集索引.<br>然后就是非聚集索引,也就是非主键索引,同样是采用B+树作为索引的数据结构,我们通常使用非主键建立索引,此时我们不可能再把保存的数据树形重新构造,而不可能取复制一份完全相同的数据,所以此时叶子节点保存的就是主键的值,所以当我们通过非主键索引查询值的时候,会先定位到主键,然后通过主键索引寻找到对应的数据行.<br>但事情又不全是这样,有一种覆盖索引,是这样,假定一个查询语句,<br><code>select name from students where sno = &#39;1627406006&#39;;</code><br>而我们的主键不是sno,而是一个id,我们创建sno的索引.<br><code>create index sno_index on students(sno);</code><br>此时我们的查询就是先通过sno在辅助索引中找到对应的id值,然后再到主键索引中找到对应的数据行,再返回name.<br>覆盖索引是什么呢?是这样的一种联合索引<br><code>create index full_index on students(sno,name);</code><br>也就是我们辅助索引处就有name的值,当通过sno找到对应的叶子节点时,就直接拿到name返回了,这也少了再次查询主键索引的时间.</p><h4 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h4><p>类似的,MyISAM也会默认创建主键索引,但是这个主键索引却有点不同,它的叶子节点保存的并不是行数据,而是行数据的物理地址,而MyISAM的主键索引和辅助索引没有什么区别,都被称为非聚集索引,只不过主键索引要求键唯一,辅助索引没有这个要求</p><h2 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h2><p>这是比较重要的一点吧,不能什么都是理论,何况谁又能确定别人说的就是对的,总得自己去试试看,这就得通过执行计划来看.<br>使用方法 : 在查询语句前添加 <code>EXPLAIN</code> 即可 .<br>返回的结果又很多参数,我就不复制过来了,<a href="https://juejin.im/post/5a52386d51882573443c852a" target="_blank" rel="noopener">看这里</a>.我们来实地操作一下:<br>建表语句:<br>InnoDb引擎,数据库sys</p><pre class="line-numbers language-SQL"><code class="language-SQL">CREATE TABLE `merchandise`  (  `id` int(11) NOT NULL,  `serial_no` varchar(20)  DEFAULT NULL,  `name` varchar(255) DEFAULT NULL,  `unit_price` decimal(10, 2) DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>插入数据:</p><pre class="line-numbers language-SQL"><code class="language-SQL">insert into sys.merchandise values(5,'000124','商品1',1000.00);insert into sys.merchandise values(7,'000159','商品2',2000.00);insert into sys.merchandise values(8,'000246','商品3',400.00);insert into sys.merchandise values(11,'000255','商品4',900.00);insert into sys.merchandise values(14,'000298','商品5',1000.00);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们先检查一个主键索引的存在,随便一个查询语句:<br><code>EXPLAIN select * from merchandise where id= 7 ;</code><br>然后看结果:<br><img src="2.png" alt><br>可以从key的值看出<code>PRIMARY</code>,使用了主键索引.type的值是<code>const</code>,代表使用了主键索引或者唯一索引,且匹配的结果只有一条记录;<br>接着我们使用用这个语句:<br><code>EXPLAIN select * from merchandise where name=&#39;商品1&#39; ;</code><br>然后看结果:<br><img src="3.png" alt><br>可以看到并没有使用主键索引,这也是当然的.而且是全表扫描</p><p>上面有点zz,下面我们验证一下覆盖索引;<br>首先创建普通的对name的索引 :<br><code>create index name_index on sys.merchandise(name);</code><br>然后查询一下:<br><code>EXPLAIN select serial_no from merchandise where name=&#39;商品1&#39; ;</code><br>看一下运行时间:<br><img src="t3.png" alt><br>然后我们删除索引,重新创建覆盖索引,再查询</p><pre class="line-numbers language-SQL"><code class="language-SQL">    drop index name_index on sys.merchandise;      create index name_index on sys.merchandise(name,serial_no);    EXPLAIN select serial_no from merchandise where name='商品1' ;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>再看运行时间<br><img src="t4.png" alt><br>这里有一点需要注意,当我们创建联合索引的时候,要注意字段的顺序,比如上面的name,serial_no,我们查询的条件是name,那么name就在前面,如果serial_no在前面,就无法使用到索引,这有一个联合索引的生效规则.可以自行了解.<br>这下验证了,当然还有很多sql的优化,我们都可以类似验证,如果有好玩的,我再补充.</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库事务与锁详解</title>
      <link href="/2019/09/02/shu-ju-ku-shi-wu-yu-suo-xiang-jie/"/>
      <url>/2019/09/02/shu-ju-ku-shi-wu-yu-suo-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库事务"><a href="#数据库事务" class="headerlink" title="数据库事务"></a>数据库事务</h1><h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><ul><li>A : Atomic:原子性:指数据库事务要么完成,要么不做.是一个不可分割的原子操作;</li><li>C:consistency: 一致性:指事务完成要保证业务逻辑数据一致;即业务是A账户向B账户转账,无论怎么转,事务完成后必须保证A账户和B账户的总额不变;</li><li>I:Isolation: 隔离性: 指不同事务有自己的执行空间,各自的操作不会影响到其他事务的执行;这里可以通过设置不同的隔离级别来控制事务的隔离强度,隔离级别越高,数据一致性越好,并发性能越低;</li><li>D: Durability:持久性: 一旦事务成功提交,对数据的操作必须写进数据库中,即使是事务刚提交,数据库就崩溃,也要保证下一次重启时,之前的数据操作可以写到数据库中;</li></ul><h3 id="InnoDB对ACID的实现"><a href="#InnoDB对ACID的实现" class="headerlink" title="InnoDB对ACID的实现"></a>InnoDB对ACID的实现</h3><blockquote><p>事务的ACID是通过InnoDB日志和锁来保证。事务的隔离性是通过数据库锁的机制实现的，持久性通过redo log（重做日志）来实现，原子性和一致性通过Undo log来实现。UndoLog的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。<br>和Undo Log相反，RedoLog记录的是新数据的备份。在事务提交前，只要将RedoLog持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。<br>对具体实现过程有兴趣的同学可以去自行搜索扩展。</p></blockquote><p>链接：<a href="https://juejin.im/post/5b5a0bf9f265da0f6523913b" target="_blank" rel="noopener">https://juejin.im/post/5b5a0bf9f265da0f6523913b</a></p><h3 id="数据库并发问题"><a href="#数据库并发问题" class="headerlink" title="数据库并发问题"></a>数据库并发问题</h3><ul><li>脏读: A事务读取了B事务尚未提交的更改数据,并使用这个数据进行后续操作,但是B事务回滚,撤销了事务,B事务更改的数据就会被恢复为原来的值,但是A事务使用了被修改的值后又进行了一系列的操作;</li><li>不可重复读: 指A事务分别在B事务开始和结束后读取了被B修改的值,造成A事务的操作数据不一致;</li><li>幻读: 本事务一次select的查询结果不支持后续的操作,例如A事务先查询id=1不存在,接着B事务插入了id=1的数据,然后提交,然后A事务的插入id=1但是失败.</li><li>不可重复读和幻读的区别有很多误解,一般的理解是不可重复读指两次读取读到修改数据,而幻读是读到新增和删除的数据,一开始我也是这样认为的,但是又有<a href="https://segmentfault.com/a/1190000016566788" target="_blank" rel="noopener">一篇博客</a>,说到,幻读并不是这样的,而是读到的不一致影响了后续操作才叫幻读,总之,点进去看吧</li><li>第一类丢失更新: 我觉得类似脏读,指A事务先读到一个值a,在后续操作前,B事务将该值修改为b,然后提交事务,然后A在原来读取到的值a的基础上继续执行,并做了修改为c,但是因为一些问题发生回滚,值被回滚到a,这时,B事务的操作就被丢失了,造成数据不一致;</li><li>第二类丢失更新: 类似第一类丢失更新,指A事务先读到一个值a,然后B事务开始并将a修改为b,提交事务,但是A事务继续执行,经a修改为c,这时丢失了B事务的更新;</li></ul><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th><th>第一类丢失更新</th><th>第二类丢失更新</th></tr></thead><tbody><tr><td>READ UNCOMMITED</td><td>可能</td><td>可能</td><td>可能</td><td>不可能</td><td>可能</td></tr><tr><td>READ COMMITED</td><td>不可能</td><td>可能</td><td>可能</td><td>不可能</td><td>可能</td></tr><tr><td>REPEATABLE READ</td><td>不可能</td><td>不可能</td><td>可能</td><td>不可能</td><td>不可能</td></tr><tr><td>SERIALIZABLE</td><td>不可能</td><td>不可能</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><ul><li>未提交读: 一个事务可以读到另一个未提交的事务修改的值;</li><li>提交读: 本事务读到的数据是最新的,也就是说一个事务内相同的query操作可以得到不同的结果(中间有其他事务提交)</li><li>可重复读: 本事务的相同的多次query操作得到的结果是一样的</li><li>串行读: 事务间有类似读写锁的锁机制,并发读允许,并发写不允许</li><li>READ UNCOMMITED拥有最高的并发度和吞吐量,而SERIALIZABLE并发量最低;</li><li>Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.</li></ul><h3 id="数据库如何实现隔离级别"><a href="#数据库如何实现隔离级别" class="headerlink" title="数据库如何实现隔离级别"></a>数据库如何实现隔离级别</h3><ol><li>Read Uncommited : 读不加锁,写操作会加排它锁,具体看 <a href="https://segmentfault.com/a/1190000012654564" target="_blank" rel="noopener">这里</a></li><li>Read Commited : 读使用MVCC,写加排他锁, 具体看 <a href="https://segmentfault.com/a/1190000012655091" target="_blank" rel="noopener">这里</a></li><li>Repeatable Read : 默认情况下无法避免幻读,效果和RC相同,需要手动添加排他锁 for update,但是内部为了提高性能,并没有全部使用排它锁保证幻读,而是使用next-key lock ,具体看<a href="https://segmentfault.com/a/1190000016566788" target="_blank" rel="noopener">这里</a></li></ol><h3 id="数据库锁机制"><a href="#数据库锁机制" class="headerlink" title="数据库锁机制"></a>数据库锁机制</h3><p>按所对象分可以分为表锁定和行锁定,前者对整张表锁定,后者对特定行锁定,从并发事务关系来看可以分为共享锁和独占锁;共享锁允许其他共享锁进入,排斥独占锁,而独占锁即防止共享锁也防止独占锁;</p><ul><li><p>行共享锁定:通过sql语句中<code>select ... for update</code>或者<code>lock table in row share mode</code>(oracle)获得共享锁定,</p></li><li><p>行独占锁定:通过sql语句<code>insert|update|delete</code> 或者 <code>lock table in row exclusive mode</code>这些语句都是;</p></li><li><p>表 共享锁定: 通过<code>lock table in share mode</code>,表共享可以防止行独占锁定和表独占锁定,允许表共享和行共享</p></li><li><p>表共享行锁定 通过<code>lock table in share row exclusive mode</code> 显式获得,这种锁定可以防止其他回话获取一个表共享,行独占,或者表独占;只允许行共享</p></li><li><p>表独占: 通过<code>lock table in exclusive mode</code>语句显示获得,什么都不允许</p></li><li><p>MyISAM使用的是表级锁, InnoDB使用的是行级锁</p></li></ul><h3 id="InnoDB行级锁算法"><a href="#InnoDB行级锁算法" class="headerlink" title="InnoDB行级锁算法"></a>InnoDB行级锁算法</h3><ul><li>Record Lock: 单行记录上的锁</li><li>Gap lock: 间隙锁,锁定一段距离,不包括记录本身</li><li>Next-key lock: record+gap,锁定一段距离,包括记录本身</li><li>三种锁的具体讲解,可以看这篇博客:<a href="https://www.cnblogs.com/zhoujinyi/p/3435982.html" target="_blank" rel="noopener">InnoDB锁机制</a></li><li>使用next-key lock主要是为了解决幻读的问题,首先看上面对幻读的理解,事务1在执行期间,先获得信息是没有id=1的数据,正准备插入id=1的数据时,发现事务2已经插入了id=1的数据,导致之后的操作失败了,整个事务也就失败了</li><li>RR解决幻读的问题是这样的的,还是上面的例子,事务1在查到id=1没有时,就会加上next-key lock锁住一段间隙,这样事务2就无法插入数据了,而如果数据存在,比如事务1先查数据存在,正准备删除时,会为这条记录加上写锁,导致其他事务无法先删除</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实现一个简单的RPC框架</title>
      <link href="/2019/09/02/shi-xian-yi-ge-jian-dan-de-rpc-kuang-jia/"/>
      <url>/2019/09/02/shi-xian-yi-ge-jian-dan-de-rpc-kuang-jia/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h4 id="什么是RPC"><a href="#什么是RPC" class="headerlink" title="什么是RPC"></a>什么是RPC</h4><p>全名 Remote Procedure Call 即远程过程调用,具体的我就不解释了,自行Google</p><h4 id="为什么使用Netty"><a href="#为什么使用Netty" class="headerlink" title="为什么使用Netty"></a>为什么使用Netty</h4><p>本次实现的RPC是基于socket通信的,在Java中如果使用原生的socket通信,真的是要命,如果使用BIO的模式,虽然简单,但是性能实在不行,如果使用NIO,繁琐的操作可能会使我自闭,既然有了Netty,还何必折磨自己,原理懂就行了。至于Netty有什么好处，我就随便贴一下：  </p><ul><li>使用简单：API 使用简单，开发门槛低。</li><li>功能强大：预置了多种编解码功能，支持多种主流协议。</li><li>定制能力强：可以通过 ChannelHandler 对通信框架进行灵活的扩展。</li><li>性能高：通过与其它业界主流的 NIO 框架对比，Netty 的综合性能最优。</li><li>成熟稳定：Netty 修复了已经发现的所有 JDK NIO BUG，业务开发人员不需要再为 NIO 的 BUG 而烦恼。</li><li>社区活跃：版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会被加入。</li><li>案例丰富：经历了大规模的商业应用考验，质量已经得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它可以完全满足不同行业的商业应用。</li></ul><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><ol><li>创建RPC的服务提供者,使用正常的Netty服务端即可,有两个重点,一个是channelPipelne,需要绑定自定义的编解码器和消息处理类,二是创建两个自定义的包含Map的类,内部Map的键都是标识要调用的接口的字符串,值分别是接口的输入类型和处理器对象.具体的我们后面再说。</li><li>创建RPC的服务消费者,也是正常的Netty客户端,重点在于我们在这个客户端中提供一个send方法,然后将连接服务端和其他细节都隐藏起来,当客户端和服务端建立连接后,就可以使用这个send方法发送远程调用请求,客户端同样有一个Map来保存我们要调用的远程接口实现和返回类型,具体下面再说</li><li>整体的顺序是 RPCClient调用send()方法,发送请求,服务端收到请求,进入channelHandler实现类中处理请求,然后将返回封装返回,客户端收到响应,进入自己的ChannelHandler中处理响应.<h2 id="show-code"><a href="#show-code" class="headerlink" title="show code"></a>show code</h2>看一下目录结构:<br><img src="1.png" alt>  </li></ol><h4 id="服务提供者"><a href="#服务提供者" class="headerlink" title="服务提供者"></a>服务提供者</h4><p>我们从服务端最上层开始看起,就是DemoServer.java.  </p><pre class="line-numbers language-Java"><code class="language-Java">class FibRequestHandler implements IMessageHandler<Integer> {    private List<Long> fibs = new ArrayList<>();    {        fibs.add(1L); // fib(0) = 1        fibs.add(1L); // fib(1) = 1    }    @Override    public void handle(ChannelHandlerContext ctx, String requestId, Integer n) {        for (int i = fibs.size(); i < n + 1; i++) {            long value = fibs.get(i - 2) + fibs.get(i - 1);            fibs.add(value);        }        ctx.writeAndFlush(new MessageOutput(requestId, "fib_res", fibs.get(n)));    }}class ExpRequestHandler implements IMessageHandler<ExpRequest> {    @Override    public void handle(ChannelHandlerContext ctx, String requestId, ExpRequest message) {        int base = message.getBase();        int exp = message.getExp();        long start = System.nanoTime();        long res = 1;        for (int i = 0; i < exp; i++) {            res *= base;        }        long cost = System.nanoTime() - start;        ctx.writeAndFlush(new MessageOutput(requestId, "exp_res", new ExpResponse(res, cost)));    }}public class DemoServer {    public static void main(String[] args) {        RPCServer server = new RPCServer("localhost", 8888, 2, 16);        server.service("fib", Integer.class, new FibRequestHandler()).service("exp", ExpRequest.class,new ExpRequestHandler());        server.start();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主方法看起,首先创建RPCServer对象,<br><code>RPCServer server = new RPCServer(&quot;localhost&quot;, 8888, 2, 16);</code><br>参数分别是<code>host</code>,<code>port</code>,<code>ioThread</code>,<code>workerThread</code>,前两个容易理解,<code>ioThread</code>是线程数,也就是我们创建Netty服务端时创建的<code>workerGroup(NioEventLoopGroup)</code>的大小,表明处理连接进来的请求的并发数,然后<code>workerThreads</code>是我们的处理器内部的线程池的最大线程数.<br>然后将处理器对象和参数类型注册入提供者,使用的就是service()这个方法,可以看一下这个方法.  </p><pre class="line-numbers language-Java"><code class="language-Java">    //RPCServer.java    public RPCServer service(String type, Class<?> reqClass, IMessageHandler<?> handler) {        registry.register(type, reqClass);        handlers.register(type, handler);        return this;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实就是将参数类型和处理器对象注册进入,registry就是保存参数类型的类,handlers是保存处理器对象的类,键都是标识处理器类的字符串,可以看上面使用service()方法的地方  </p><pre class="line-numbers language-Java"><code class="language-Java">server.service("fib", Integer.class, new FibRequestHandler()).service("exp", ExpRequest.class,new ExpRequestHandler());<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>fib就是标识符,Integer.class表明这个handler的参数是Integer,<code>new FibRequestHandler()</code>是处理器对象,具体的实现也在上面,就是一个斐波那契数列的求法(当然这不是一个好的解法),后面的也相同.<br>最后就是启动服务<code>server.start()</code>;  </p><p>然后看一下RPCServer.java:</p><pre class="line-numbers language-Java"><code class="language-Java">public class RPCServer {    private final static Logger LOG = LoggerFactory.getLogger(RPCServer.class);    private String ip;    private int port;    private int ioThreads;    private int workerThreads;    private MessageHandlers handlers = new MessageHandlers();    private MessageRegistry registry = new MessageRegistry();    {        handlers.defaultHandler(new DefaultHandler());    }    public RPCServer(String ip, int port, int ioThreads, int workerThreads) {        this.ip = ip;        this.port = port;        this.ioThreads = ioThreads;        this.workerThreads = workerThreads;    }    private ServerBootstrap bootstrap;    private EventLoopGroup bossGroup;    private EventLoopGroup workerGroup;    private MessageCollector collector;    private Channel serverChannel;    public RPCServer service(String type, Class<?> reqClass, IMessageHandler<?> handler) {        registry.register(type, reqClass);        handlers.register(type, handler);        return this;    }    public void start() {        bootstrap = new ServerBootstrap();        bossGroup = new NioEventLoopGroup(1);        workerGroup = new NioEventLoopGroup(ioThreads);        bootstrap.group(bossGroup,workerGroup);        collector = new MessageCollector(handlers, registry, workerThreads);        MessageEncoder encoder = new MessageEncoder();        bootstrap.channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer<SocketChannel>() {            @Override            public void initChannel(SocketChannel ch) throws Exception {                ChannelPipeline pipe = ch.pipeline();                pipe.addLast(new ReadTimeoutHandler(60));                pipe.addLast(new MessageDecoder());                pipe.addLast(encoder);                pipe.addLast(collector);            }        });        bootstrap.option(ChannelOption.SO_BACKLOG, 100).option(ChannelOption.SO_REUSEADDR, true)                .option(ChannelOption.TCP_NODELAY, true).childOption(ChannelOption.SO_KEEPALIVE, true);        serverChannel = bootstrap.bind(this.ip, this.port).channel();        LOG.warn("server started @ {}:{}\n", ip, port);    }    public void stop() {        // 先关闭服务端套件字        serverChannel.close();        // 再斩断消息来源，停止io线程池        bossGroup.shutdownGracefully();        workerGroup.shutdownGracefully();        // 最后停止业务线程        collector.closeGracefully();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重点是start()方法,是比较经典的Netty服务端启动,其中<code>MessageCollector collector</code>就是我们的处理器,然后看channelPipeline绑定的handlers,<code>ReadTimeoutHandler</code>是一个超时关闭的处理器,<code>MessageDecoder()</code>,<code>encoder</code>是编解码器,最后绑定我们的collector处理器对象.<br>接着我们从一条请求进来开始分析,首先一条请求进来是以channel的形式,然后绑定NioEventLoopGroup中的一个EventLoop.然后再进下面的链式请求,因为是进来的请求,所以不会经过编码器,只会通过解码器,将Bytebuf转换成我们需要的对象,那么久看一下这个编码器<code>MessageDecoder</code>: </p><pre class="line-numbers language-Java"><code class="language-Java">public class MessageDecoder extends ReplayingDecoder<MessageInput> {    @Override    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List< Object > out) throws Exception {        String requestId = readStr(in);        String type = readStr(in);        String content = readStr(in);        out.add(new MessageInput(type, requestId, content));    }    private String readStr(ByteBuf in) {        int len = in.readInt();        if (len < 0 || len > (1 << 20)) {            throw new DecoderException("string too long len=" + len);        }        byte[] bytes = new byte[len];        in.readBytes(bytes);        return new String(bytes, Charsets.UTF8);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到我们从ByteBuf中读取到到requestId,type和content构建了MessageInput对象,然后这个对象会跟随在<code>ChannelHandlersContext</code>中,然后我们看一下这个<code>MessageInput</code>,</p><pre class="line-numbers language-Java"><code class="language-Java">public class MessageInput {    private String type;    private String requestId;    private String payload;    public MessageInput(String type, String requestId, String payload) {        this.type = type;        this.requestId = requestId;        this.payload = payload;    }    public String getType() {        return type;    }    public String getRequestId() {        return requestId;    }    public <T> T getPayload(Class<T> clazz) {        if (payload == null) {            return null;        }        return JSON.parseObject(payload, clazz);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重点是getPayload()方法,就是将我们的传入的字符串转化成对应类型的对象,使用的是fastJson的方法,其实这就是一个反序列化的过程,通过Json的方式.</p><p>似乎绕的有点远,我们回到编解码器后,就是channel进入到<code>MessageCollector</code>,直接上代码吧 : </p><pre class="line-numbers language-Java"><code class="language-Java">@Sharablepublic class MessageCollector extends ChannelInboundHandlerAdapter {    private final static Logger LOG = LoggerFactory.getLogger(MessageCollector.class);    private ThreadPoolExecutor executor;    private MessageHandlers handlers;    private MessageRegistry registry;    public MessageCollector(MessageHandlers handlers, MessageRegistry registry, int workerThreads) {        BlockingQueue<Runnable> queue = new ArrayBlockingQueue<>(1000);        ThreadFactory factory = new ThreadFactory() {            AtomicInteger seq = new AtomicInteger();            @Override            public Thread newThread(Runnable r) {                Thread t = new Thread(r);                t.setName("rpc-" + seq.getAndIncrement());                return t;            }        };        this.executor = new ThreadPoolExecutor(1, workerThreads, 30, TimeUnit.SECONDS, queue, factory,                new CallerRunsPolicy());        this.handlers = handlers;        this.registry = registry;    }    public void closeGracefully() {        this.executor.shutdown();        try {            this.executor.awaitTermination(10, TimeUnit.SECONDS);        } catch (InterruptedException e) {        }        this.executor.shutdownNow();    }    @Override    public void channelActive(ChannelHandlerContext ctx) throws Exception {        LOG.debug("connection comes");    }    @Override    public void channelInactive(ChannelHandlerContext ctx) throws Exception {        LOG.debug("connection leaves");    }    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {        if (msg instanceof MessageInput) {            this.executor.execute(() -> {                this.handleMessage(ctx, (MessageInput) msg);            });        }    }    private void handleMessage(ChannelHandlerContext ctx, MessageInput input) {        // 业务逻辑在这里        Class<?> clazz = registry.get(input.getType());        if (clazz == null) {            handlers.defaultHandler().handle(ctx, input.getRequestId(), input);            return;        }        Object o = input.getPayload(clazz);        @SuppressWarnings("unchecked")        IMessageHandler< Object > handler = (IMessageHandler< Object >) handlers.get(input.getType());        if (handler != null) {            handler.handle(ctx, input.getRequestId(), o);        } else {            handlers.defaultHandler().handle(ctx, input.getRequestId(), input);        }    }    @Override    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {        LOG.warn("connection error", cause);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>想深入了解的最好先学习一下Netty的各个组件,尤其是<code>ChannelHandler</code>这个接口,这里我们就不仔细介绍了,看构造器,就是创建一个线程池,自定义线程池线程工厂,阻塞队列和拒绝策略,同时将上一层的两个Map类注入.<br>入口就是<code>channelRead()</code>这个方法时当有消息到时触发的,也就是Netty事件驱动的体现.我们可以看到,方法内,先判断msg的类型,然后用线程池执行处理这个消息.就是使用<code>handleMessage()</code>方法,看方法内部:<br>首先拿到输入中保存的标识符,从registry中拿到保存的输入类型,如果没有这个输入类型为null,代表着是非法输入,这里采用的方法是使用默认处理器处理,默认处理器的方法如下:  </p><pre class="line-numbers language-Java"><code class="language-Java">@Override    public void handle(ChannelHandlerContext ctx, String requesetId, MessageInput input) {        LOG.error("unrecognized message type {} comes", input.getType());        ctx.close();    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也就是直接报错,之所以扩展为一个处理器,而不是直接在<code>handleMessage</code>中直接写,体会一下用意.<br>然后我们从<code>messageInput</code>中拿到入参值,然后从handlers中拿到处理器对象,如果处理器非null,就使用处理器的handle方法处理输入的值,否则还是调用默认处理器.<br>然后我们看一下具体的处理器,也就是我们之前的<code>FibRequestHandler</code>: </p><pre class="line-numbers language-Java"><code class="language-Java">class FibRequestHandler implements IMessageHandler<Integer> {    private List<Long> fibs = new ArrayList<>();    {        fibs.add(1L); // fib(0) = 1        fibs.add(1L); // fib(1) = 1    }    @Override    public void handle(ChannelHandlerContext ctx, String requestId, Integer n) {        for (int i = fibs.size(); i < n + 1; i++) {            long value = fibs.get(i - 2) + fibs.get(i - 1);            fibs.add(value);        }        ctx.writeAndFlush(new MessageOutput(requestId, "fib_res", fibs.get(n)));    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一个简单的斐波那契求法,重点是最后一句,我们用<code>ctx.writeAndFlush()</code>将处理完的消息传回给client,MessageOutput和MessageInput一样,都是对数据的一个封装类.<br>这个时候我们需要看一个编码器,MessageEncoder.java:</p><pre class="line-numbers language-Java"><code class="language-Java">@Sharablepublic class MessageEncoder extends MessageToMessageEncoder<MessageOutput> {    @Override    protected void encode(ChannelHandlerContext ctx, MessageOutput msg, List< Object > out) throws Exception {        ByteBuf buf = PooledByteBufAllocator.DEFAULT.directBuffer();        writeStr(buf, msg.getRequestId());        writeStr(buf, msg.getType());        writeStr(buf, JSON.toJSONString(msg.getPayload()));        out.add(buf);    }    private void writeStr(ByteBuf buf, String s) {        buf.writeInt(s.length());        buf.writeBytes(s.getBytes(Charsets.UTF8));    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到,首先创建一块池化的堆外内存,然后取出MessageOutput中的数据,然后写入ByteBuf中,加入到ctx流中.</p><p>服务提供者的部分大致就是这样了,接下来就是服务消费者的部分</p><h2 id="服务消费者"><a href="#服务消费者" class="headerlink" title="服务消费者"></a>服务消费者</h2><p>还是从顶层看起: DemoClient.java : </p><pre class="line-numbers language-Java"><code class="language-Java">public class DemoClient {    private RPCClient client;    public DemoClient(RPCClient client) {        this.client = client;        this.client.rpc("fib_res", Long.class).rpc("exp_res", ExpResponse.class);    }    public long fib(int n) {        return (Long) client.send("fib", n);    }    public ExpResponse exp(int base, int exp) {        return (ExpResponse) client.send("exp", new ExpRequest(base, exp));    }    public static void main(String[] args) throws InterruptedException {        RPCClient client = new RPCClient("localhost", 8888);        DemoClient demo = new DemoClient(client);        for (int i = 0; i < 30; i++) {            try {                System.out.printf("fib(%d) = %d\n", i, demo.fib(i));                Thread.sleep(100);            } catch (RPCException e) {                i--; // retry            }        }        for (int i = 0; i < 30; i++) {            try {                ExpResponse res = demo.exp(2, i);                Thread.sleep(100);                System.out.printf("exp2(%d) = %d cost=%dns\n", i, res.getValue(), res.getCostInNanos());            } catch (RPCException e) {                i--; // retry            }        }        client.close();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看主方法,首先创建<code>RPCClient</code>,然后创建<code>DemoClient</code>对象,然后使用fib()方法,可以看到fib方法,调用<code>client.send()</code>方法,这个方法在RPCClient.java中,我们去看一下:</p><pre class="line-numbers language-Java"><code class="language-Java">public class RPCClient {    private final static Logger LOG = LoggerFactory.getLogger(RPCClient.class);    private String ip;    private int port;    private Bootstrap bootstrap;    private EventLoopGroup group;    private MessageCollector collector;    private boolean started;    private boolean stopped;    private MessageRegistry registry = new MessageRegistry();    public RPCClient(String ip, int port) {        this.ip = ip;        this.port = port;        this.init();    }    public RPCClient rpc(String type, Class<?> reqClass) {        registry.register(type, reqClass);        return this;    }    public <T> RpcFuture<T> sendAsync(String type, Object payload) {        if (!started) {            connect();            started = true;        }        String requestId = RequestId.next();        MessageOutput output = new MessageOutput(requestId, type, payload);        return collector.send(output);    }    public <T> T send(String type, Object payload) {        RpcFuture<T> future = sendAsync(type, payload);        try {            return future.get();        } catch (InterruptedException | ExecutionException e) {            throw new RPCException(e);        }    }    public void init() {        bootstrap = new Bootstrap();        group = new NioEventLoopGroup(1);        bootstrap.group(group);        MessageEncoder encoder = new MessageEncoder();        collector = new MessageCollector(registry, this);        bootstrap.channel(NioSocketChannel.class).handler(new ChannelInitializer<SocketChannel>() {            @Override            protected void initChannel(SocketChannel ch) throws Exception {                ChannelPipeline pipe = ch.pipeline();                pipe.addLast(new ReadTimeoutHandler(60));                pipe.addLast(new MessageDecoder());                pipe.addLast(encoder);                pipe.addLast(collector);            }        });        bootstrap.option(ChannelOption.TCP_NODELAY, true).option(ChannelOption.SO_KEEPALIVE, true);    }    public void connect() {        bootstrap.connect(ip, port).syncUninterruptibly();    }    public void reconnect() {        if (stopped) {            return;        }        bootstrap.connect(ip, port).addListener(future -> {            if (future.isSuccess()) {                return;            }            if (!stopped) {                group.schedule(this::reconnect, 1, TimeUnit.SECONDS);            }            LOG.error("connect {}:{} failure", ip, port, future.cause());        });    }    public void close() {        stopped = true;        collector.close();        group.shutdownGracefully(0, 5000, TimeUnit.SECONDS);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>那就从send方法看起吧,内部调用<code>sendAsync()</code>,异步的任务,返回的是一个Future,然后看snedAsync()方法,首先看客户端是否启动,如果没有启动,就使用连接方法connect(),内部也就是用<code>bootstrap.connect()</code>方法,接着使用<code>collector.send()</code>发送请求.我们就看collector对象具体是什么吧.</p><pre class="line-numbers language-Java"><code class="language-Java">@Sharablepublic class MessageCollector extends ChannelInboundHandlerAdapter {    private final static Logger LOG = LoggerFactory.getLogger(MessageCollector.class);    private MessageRegistry registry;    private RPCClient client;    private ChannelHandlerContext context;    private ConcurrentMap<String, RpcFuture<?>> pendingTasks = new ConcurrentHashMap<>();    private Throwable ConnectionClosed = new Exception("rpc connection not active error");    public MessageCollector(MessageRegistry registry, RPCClient client) {        this.registry = registry;        this.client = client;    }    @Override    public void channelActive(ChannelHandlerContext ctx) throws Exception {        this.context = ctx;    }    @Override    public void channelInactive(ChannelHandlerContext ctx) throws Exception {        this.context = null;        pendingTasks.forEach((__, future) -> {            future.fail(ConnectionClosed);        });        pendingTasks.clear();        // 尝试重连        ctx.channel().eventLoop().schedule(() -> {            client.reconnect();        }, 1, TimeUnit.SECONDS);    }    public <T> RpcFuture<T> send(MessageOutput output) {        ChannelHandlerContext ctx = context;        RpcFuture<T> future = new RpcFuture<T>();        if (ctx != null) {            ctx.channel().eventLoop().execute(() -> {                pendingTasks.put(output.getRequestId(), future);                ctx.writeAndFlush(output);            });        } else {            future.fail(ConnectionClosed);        }        return future;    }    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {        if (!(msg instanceof MessageInput)) {            return;        }        MessageInput input = (MessageInput) msg;        // 业务逻辑在这里        Class<?> clazz = registry.get(input.getType());        if (clazz == null) {            LOG.error("unrecognized msg type {}", input.getType());            return;        }        Object o = input.getPayload(clazz);        @SuppressWarnings("unchecked")        RpcFuture< Object> future = (RpcFuture< Object>) pendingTasks.remove(input.getRequestId());        if (future == null) {            LOG.error("future not found with type {}", input.getType());            return;        }        future.success(o);    }    @Override    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {    }    public void close() {        ChannelHandlerContext ctx = context;        if (ctx != null) {            ctx.close();        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>send方法内部就是用ctx发送<code>MessageOutput</code>对象,同时创建一个future保存到<code>pendingTasks</code>,是为了断开连接后,销毁这些异步的线程阻塞状态.<br>接着我们就看服务端处理完后,客户端如何处理返回消息,<code>channelRead()</code>方法,取出远程调用的返回类型对象,然后从使用<code>future.success()</code>方法告诉future远程调用已经成功,我们可以看到sned方法中有future.get(),这个方法在调用<code>future.success()</code>和fail()方法前会一直阻塞,具体我们可以看一下RpcFuture类:</p><pre class="line-numbers language-Java"><code class="language-Java">public class RpcFuture<T> implements Future<T> {    private T result;    private Throwable error;    private CountDownLatch latch = new CountDownLatch(1);    @Override    public boolean cancel(boolean mayInterruptIfRunning) {        return false;    }    @Override    public boolean isCancelled() {        return false;    }    @Override    public boolean isDone() {        return result != null || error != null;    }    public void success(T result) {        this.result = result;        latch.countDown();    }    public void fail(Throwable error) {        this.error = error;        latch.countDown();    }    @Override    public T get() throws InterruptedException, ExecutionException {        latch.await();        if (error != null) {            throw new ExecutionException(error);        }        return result;    }    @Override    public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {        latch.await(timeout, unit);        if (error != null) {            throw new ExecutionException(error);        }        return result;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中用的就是<code>CountDownLatch</code>这个并发控制工具,但实现的其实是一个信号量的工作,所以也可以用<code>Semaphore</code>.<br>整体的流程就是这样了.多看看,理解一下</p><h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><ol><li>心跳机制,这个比较简单,就是加一个IdleChannelHandler</li><li>各类接口兼容,现在只兼容一个IMessageHandler<t></t></li><li>…</li></ol>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Netty </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中间件 </tag>
            
            <tag> Netty </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务（一）</title>
      <link href="/2019/08/30/fen-bu-shi-shi-wu-yi/"/>
      <url>/2019/08/30/fen-bu-shi-shi-wu-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为一个还没有正式工作的学生,分布式的真正场景我还没有接触过,所以这篇博客完全作为理论知识的学习,也就是在网上寻找各种介绍和问题的解释,写个总结类的博客,也当做一个学习的过程</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>事务的概念是我在学习数据库的时候接触的,本地事务相对而言还是比较简单的,前有数据库本身对ACID的保证,后有各大框架对事务的封装,不论是理解还是使用起来都是比较简单的,我之前有一篇在CSDN的关于事务的博客,<a href="https://blog.csdn.net/qq_36865108/article/details/86758807" target="_blank" rel="noopener">点这里</a>,有时间转过来<br>相比而言,分布式事务就要难很多了,主要是在微服务、SOA等服务架构被使用后，一个项目被分为多个服务，而一般而言，每个服务都拥有自己的数据库，即时我们不使用微服务的架构，当单个项目的数据量过于大的时候，一个数据库肯定扛不住，这个时候需要分库分表，再说不需要分库分表，我们也会遇到使用缓存的情况，DB和缓存的一致性问题。<br>这些都属于分布式事务的场景，是福不是祸，躲不过就要拿下它。</p><h2 id="分布式事务基础"><a href="#分布式事务基础" class="headerlink" title="分布式事务基础"></a>分布式事务基础</h2><p>ACID是本地事务的基础，那么分布式事务的基础是什么呢？有两个，CAP和BASE，分别介绍一下：  </p><ul><li><p>CAP理论</p><ul><li>C ： 一致性，指在分布式系统中的所有数据备份，是否在同一时刻拥有相同的值，也就是客户端操作完成后,所有节点的数据保持完全一致,这里是指强一致性</li><li>A ： 可用性，指在服务一直可用,而且是正常的响应时间</li><li>P ： 分区容错性，指在某节点或者网络分区发生故障后,系统整体还是能够向外提供满足条件的服务，这个是分布式的基础，是不能放弃的</li></ul></li><li><p>CAP选择</p><ul><li>什么是选择呢,也就是说我们只能在CAP中选择其二,而无法同时满足三个条件</li><li>CA : 不要求P是不行的,上面也说了,P是分布式基础</li><li>CP : 也就是说不要求可用性,但保证了强一致性,不同server之间就需要强制同步数据,这样一旦发生网络故障或者消息丢失,就要牺牲用户的体验,等待数据完全同步再进行提供服务,常见的就是分布式数据库,Zookeeper就是一个CP,即再任何时候对于Zookpeeper的访问请求都能得到一致的数据,这是由zk的作用决定的,我们都知道的是,Dubbo使用zk做注册中心,kafka使用zk做服务的协调.zk的职责就是保证数据在其管辖下的所有服务之间保持同步,一致</li><li>PA : 抛弃了强一致性,保证高可用,为了保证用户的访问可以马上得到回复,但是无法保证全局数据的一致性,常见的场景是业务系统,比如购票系统,经常购买的时候显示是有票的,但是当你输入验证码,下单的时候,才告诉你没有票了,但是是要保证最终一致性的,也就说,虽然下单的瞬间,票的数目可能存在不一致,但是最终票的总量是确定的,不能出现多卖的情况</li></ul></li><li><p>BASE理论</p><ul><li>BA: 基本可用(Basically Available): 是指分布式系统出现故障的时候,允许损失部分可用性,保证核心可用,比如双11,为了应对访问量激增,部分用户可能会被引导至降级页面</li><li>S : 软状态(Soft State): 是指允许系统存在中间状态,而改中间状态不会影响系统整体可用性,体现在如果我们的数据有多个副本,那么副本之间同步的延时就是软状态的体现</li><li>E : 最终一致性(Eventual Consistency) : 是指系统中的所有副本在一定时间后,都会达到一致的情况</li></ul></li></ul><h2 id="分布式事务协议"><a href="#分布式事务协议" class="headerlink" title="分布式事务协议"></a>分布式事务协议</h2><h4 id="XA规范"><a href="#XA规范" class="headerlink" title="XA规范"></a>XA规范</h4><p>X/Open组织定义了分布式事务的处理模型,X/Open DTP模型包括应用程序(AP)、事务管理器（TM）、资源管理器（RM）、通信资源管理器（CRM）四部分。一般，常见的事务管理器是交易中间件，常见的资源管理器是数据库，常见的通信资源管理器是消息中间件。 通常把一个数据库内部的事务管理，如对多个表的操作，当做本地事务。分布式事务处理的对象是全局事务，所谓全局事务，是指分布式事务处理环境中，多个数据库需要共同完成一个工作，例如，一个事务可能更新几个不同的数据库，对数据库的操作发生在系统的各处但必须全部被提交或者回滚，此时一个数据库对自己内部多操作的提交不仅依赖本身操作是否成功，还有依赖于全局事务的其他操作是否成功，如果任一数据库操作失败，所有该全局事务的操作必须回滚</p><h4 id="2PC-二阶段提交协议"><a href="#2PC-二阶段提交协议" class="headerlink" title="2PC 二阶段提交协议"></a>2PC 二阶段提交协议</h4><p>二阶段提交的重点是我们需要引入一个协调者的组件，由他来指示这些节点是否要把操作结果真正的提交。<br>所谓的二阶段提交是指： 第一阶段： 准备阶段（投票阶段） 和 第二阶段： 提交阶段（执行阶段）</p><ul><li>准备阶段<br>  事务协调者给每个参与者发送Prepare消息，每个暗语者要吗直接返回失败，要吗在本地执行事务，写本地redo和undo日志，但不提交，到一种万事俱备，只欠东风的状态</li><li>提交阶段<br>  如果协调这都参与者的失败消息或者超时，直接给每个参与者发送回滚消息，否则，发送提交消息，参与者根据协调者的指定执行提交或者回滚，释放所有事务过程中使用的锁资源</li><li>缺点<ul><li>同步阻塞： 执行过程中，所有参与的节点都是事务阻塞的，当参与者占用公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态</li><li>单点故障： 由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去，尤其是第二阶段，</li><li>数据不一致，在阶段而中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求，发生数据不一致</li></ul></li><li>实现<br>  蚂蚁中间件 DTS （distributed transaction service）tech.antfin.com/docs/46887</li></ul><h4 id="3PC-三阶段提交协议"><a href="#3PC-三阶段提交协议" class="headerlink" title="3PC 三阶段提交协议"></a>3PC 三阶段提交协议</h4><p>三阶段提交协议是二阶段的一个改进版本，与二阶段相比，多了两个改动点：</p><ol><li>引入超时机制。同时在协调者和参与者中都引入超时机制</li><li>在第一阶段和第二阶段中插入一个准备阶段，保证在最后提交阶段之前各参与阶段的状态是一致的。</li></ol><ul><li>CanCommit阶段<br>协调者向请求者发送commit请求,参与者如果可以提交就返回Yes响应,否则返回No响应</li><li>PreCommit阶段<br>协调者根据参与者的反应情况来决定是否可以记性事务的PreCommit操作,两种可能:<ul><li>假如协调者从所有的参与者获得的反馈都是Yes响应,那么就会执行事务的预执行</li><li>如果有任何一个No响应,或者等待超时之后,协调者都没有接到参与者则的响应,执行事务的中断,即向所有参与者发送abort请求,参与者收到abort请求之后,执行事务的中断</li></ul></li><li>doCommit阶段<br>该阶段进行真正的事务提交,可以分为以下两种情况<ul><li>执行提交 , 协调者收到ACK响应,从预提交到提交状态,并向所有参与者发送doCommit请求,参与者收到doCommit,进行事务提交,</li><li>中断事务, 协调者没有接收到参与者发送的ACK响应,会执行中断事务,但是如果参与者没有即时收到doCommit请求,会在等待超时后,进行事务的提交,这样会减少阻塞,但是增加了</li></ul></li></ul><h4 id="2PC-3PC区别"><a href="#2PC-3PC区别" class="headerlink" title="2PC,3PC区别"></a>2PC,3PC区别</h4><p>相对于2PC,3PC主要解决了单点故障并减少了阻塞,但是同时也导致了数据一致性的问题,也就说两种提交方案都无法彻底解决一致性的问题.</p><h4 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h4><ul><li>将业务分为try/confirm/cancel<ul><li>try： 尝试执行，完成业务检查，预留业务资源（一般是在表中添加冻结字段）</li><li>confirm ： 确定执行，不做业务检查，只使用try阶段预留的业务资源，confirm需要满足幂等性，可重试</li><li>cancel： 取消执行，释放try阶段的业务资源，满足幂等，可重试</li></ul></li><li>参考实现<ul><li>byteTCC github</li></ul></li><li>一般不用，实现比较复杂</li></ul><h4 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h4><p>由ebay提出的方案，方案核心是将需要分布式处理的任务通过消息日志的方式来异步执行，消息可以存储在本地，数据库，消息队列。再通过业务规则自动或人工发起重试。<br>例如跨行转账，用户a向用户b转账，首先系统扣掉a账户的金额，把转账消息写入到消息表里，如果事务执行失败则转账失败，如果成功，系统由定时轮训消息表，往mq中写入转账消息，失败重试，mq消息被消费并往用户b账户中增加转账金额，执行失败并重试。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 理论知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 理论知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java SPI 加载Mysql驱动源码分析</title>
      <link href="/2019/08/29/java-spi-jia-zai-mysql-qu-dong-yuan-ma-fen-xi/"/>
      <url>/2019/08/29/java-spi-jia-zai-mysql-qu-dong-yuan-ma-fen-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我记得在我刚学Java的时候,需要连接Mysql的时候,还是需要Class.forName(“驱动名”);来手动的来加载驱动(可能现在还有人是这么加载的),再后来就使用框架了,什么Mybatis,Hibernate等一系列ORM框架,这些底层的东西就没人用了,可能也不太清楚现在是什么样子.事实是现在不再需要手动的加载驱动了,但是我们还是要知道为什么</p><h2 id="Class-forName-与-SPI"><a href="#Class-forName-与-SPI" class="headerlink" title="Class.forName 与 SPI"></a>Class.forName 与 SPI</h2><h4 id="为什么需要用Class-forName"><a href="#为什么需要用Class-forName" class="headerlink" title="为什么需要用Class.forName"></a>为什么需要用Class.forName</h4><p>这里说的是Mysql驱动之前的版本(4.0.0),为什么需要使用Class.forName来手动加载呢?正常触发类加载不行吗?我们知道,触发类初始化的方法有6个,也就是我们常说的<code>主动使用</code>,而最常见的就是使用new创建对象来触发初始化了,那为什么这里不能使用new呢?从我的理解来看,数据库有很多,而JDBC只是一个规范,它要求每个想要和Java交互的数据库必须按照我的规范编写驱动,而我们真正使用驱动的时候应该是使用<br><code>DriverManager.getConnection(&quot;jdbc:xxxx:xxxxx&quot;);</code><br>在获得连接的传入的string中,我们会指定我们要连接的数据库和host,port等等, 问题在于<code>DriverManager</code>这个类是Java提供的,它总不能在你使用的时候去全局寻找你的外部驱动在哪里?并且使用一个import语句导入这个包,所以我们只能自己告诉Java我们的驱动名是什么,然后把它加载到JVM中.</p><h4 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h4><p>上面说到我们不用再用Class.forName()来加载类,那么现在使用的是什么呢?这也是我们今天的主题: SPI.SPI是一个很重要的东西,这里默认就是指Java原生的SPI,不仅仅在Mysql驱动中. 如果想要了解下面的源码,就必须先了解SPI,我就不献丑了,提供一个链接,是我觉得不错的介绍SPI的 <a href="https://blog.csdn.net/top_code/article/details/51934459" target="_blank" rel="noopener">SPI介绍</a></p><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>从哪里说起呢?应该是<code>DriverManager</code>中的一段静态代码块  </p><pre class="line-numbers language-Java"><code class="language-Java">    static {        loadInitialDrivers();        println("JDBC DriverManager initialized");    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>顾名思义,<code>loadInitialDrivers()</code>就是加载驱动的方法,点进去看一下:  </p><pre class="line-numbers language-Java"><code class="language-Java">private static void loadInitialDrivers() {        String drivers;        try {            drivers = AccessController.doPrivileged(new PrivilegedAction<String>() {                public String run() {                    return System.getProperty("jdbc.drivers");                }            });        } catch (Exception ex) {            drivers = null;        }        AccessController.doPrivileged(new PrivilegedAction<Void>() {            public Void run() {                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);                Iterator<Driver> driversIterator = loadedDrivers.iterator();                try{                    while(driversIterator.hasNext()) {                        driversIterator.next();                    }                } catch(Throwable t) {                // Do nothing                }                return null;            }        });        println("DriverManager.initialize: jdbc.drivers = " + drivers);        if (drivers == null || drivers.equals("")) {            return;        }        String[] driversList = drivers.split(":");        println("number of Drivers:" + driversList.length);        for (String aDriver : driversList) {            try {                println("DriverManager.Initialize: loading " + aDriver);                Class.forName(aDriver, true,                        ClassLoader.getSystemClassLoader());            } catch (Exception ex) {                println("DriverManager.Initialize: load failed: " + ex);            }        }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>除去前面的判断之类的,看了上面介绍SPI的同学应该可以定位到重点的一句,<br><code>ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);</code><br>这就是通过SPI的方式将驱动类加载到JVM中,看一下效果<br><img src="1.png" alt><br>可以看到,驱动被放在<code>driversIterator</code>的<code>knownProviders</code>中,那就简单了,我们找到这个<code>driversIterator</code>,看一下:</p><pre class="line-numbers language-Java"><code class="language-Java">public Iterator< S   iterator() {        return new Iterator< S >() {            Iterator<Map.Entry<String,S>> knownProviders                = providers.entrySet().iterator();            public boolean hasNext() {                if (knownProviders.hasNext())                    return true;                return lookupIterator.hasNext();            }            public S next() {                if (knownProviders.hasNext())                    return knownProviders.next().getValue();                return lookupIterator.next();            }            public void remove() {                throw new UnsupportedOperationException();            }        };}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后看到这个<code>knownProviders</code>其实是从<code>providers</code>转换来的,那我们继续看<code>providers</code>是什么:<br><code>private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();</code><br>是个<code>LinkedHashMap</code> 然后再这个类中搜一下,看哪里有<code>put</code>方法,找到了,只有一个地方,是在<code>ServiceLoader</code>下的<code>LazyIterator</code>内部类的<code>nextService()</code>方法中的两句:  </p><pre class="line-numbers language-Java"><code class="language-Java">    S p = service.cast(c.newInstance());    providers.put(cn, p);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以看到,这里就是一个实例化驱动类并放在providers中,然后我们找一下,什么地方调用了这个<code>nextService()</code>方法,还是在<code>LazyIterator</code>内部类中:  </p><pre class="line-numbers language-Java"><code class="language-Java">        public S next() {            if (acc == null) {                return nextService();            } else {                PrivilegedAction< S> action = new PrivilegedAction< S>() {                    public S run() { return nextService(); }                };                return AccessController.doPrivileged(action, acc);            }        }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后再看一下什么地方创建了这个内部类,很容易找到了,还是在<code>ServiceLoader</code>类中的<code>reload()</code>方法,那么什么地方调用了<code>reload()</code>方法呢?在构造方法中,什么地方构造了ServiceLoader实例了,<code>load()</code>方法.</p><p>现在找到了所有的路线,但是肯定很晕,绕来绕去的,我们正向理一下<br>我们调用<code>ServiceLoader.load()</code>方法,<code>ServiceLoader.load()</code>内部构造了实例对象,然后调用了<code>reload()</code>方法,在<code>reload()</code>方法中,我们创建了<code>LazyIterator</code>内部类,并将类变量<code>lookupIterator</code>指向了这个内部类实例,当我们调用<code>lookupIterator</code>的next()方法时,就会将驱动类实例化并至于<code>providers</code>中,现在很清楚了,最后我们找到什么地方调用了<code>lookupIterator.next()</code>方法,其实上面也看到了,就在<code>driversIterator</code>中.</p><p>这里的东西可能很绕,但是仔细看是能看懂的.</p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>之所以分析这个源码,纯粹是因为好奇,在这里记录一下,希望可以帮助到你</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入探究 volatile</title>
      <link href="/2019/08/28/shen-ru-tan-jiu-volatile/"/>
      <url>/2019/08/28/shen-ru-tan-jiu-volatile/</url>
      
        <content type="html"><![CDATA[<h2 id="volatile介绍"><a href="#volatile介绍" class="headerlink" title="volatile介绍"></a>volatile介绍</h2><p>刚说了synchronized 关键字,那就肯定一定要说一下volatile关键字,关于volatile我是非常”痛恨”的,因为这个关键字导致去年春招的一次面试失败了,所以还是要好好看看这个关键字,深入的探究一下.<br>大部分人都知道volatile是保证了可见性和禁止重排序, 具体怎么保证,我们就好好说一下</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h4 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h4><p>Java的内存模型大致的内容就是说,每个线程会将共享变量从主内存中拷贝到工作内存,然后在各个线程内部对数据进行操作.但是问题就是,每个线程的持有的共享变量只是一份拷贝,和主内存中的变量的值并不是实时一致的,而工作内存何时将操作后的结果写回主内存却没有人知道,这在多线程的情况下,就会发生数据不一致和线程不安全的问题</p><h4 id="volatile实现原理"><a href="#volatile实现原理" class="headerlink" title="volatile实现原理"></a>volatile实现原理</h4><p>将视角移到计算机指令的层面,根据volatile的描述,在生成汇编代码的时候,被volatile描述的变量在写操作的指定前会被添加lock前缀(使用javap 可以看到), 这个lock指定会做什么呢?<br>再看操作系统的层面,每个CPU都有自己的缓存,CPU会将内存中的数据保存到内部缓存中,这个内部缓存是个大学问,需要好好再另说. 和Java内存模型一样,我们并不知道什么时候缓存中的数据会被写回内存,而这个lock指令就会指定将缓存中的数据写回系统内存,那么问题又来了,你一个线程写回了,但是其他缓存中可能还有旧的数据,这就需要操作系统出马了,操作系统为了保证缓存一致性,每个处理器会通过<code>嗅探</code>在总线上传播的数据来检查自己的缓存是不是过期了,当发现自己缓存行的对应的内存地址呗修改,就会将缓存视为无效状态,当处理器对这个数据进行操作的时候,就会从内存中重新读取.<br>在著名的<code>happens-before</code>规则中有一条: <code>对一个volatile变量的写,happens-before于任何对volatile的读</code>,<code>happens-before</code>, 有人翻译为发生前,但是真正的意思应该是 对..可见 ,上面的话也就是<code>对一个volatile变量的写,对于任何对volatile的读 可见</code>  </p><h4 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h4><p>上面说到了底层是怎么样的,但是仔细一看是有问题的,我们说volatile保证可见性和有序性,但是不保证原子性,但是从我们上面说的,每一个线程修改共享变量都会使其他线程所在cpu的缓存失效,那咋一看不是保证了原子性吗?那最经典的自增操作来看,<br>自增操作i++分为三个部分:  </p><ol><li>取出i值</li><li>令i = i + 1</li><li>写回i的值</li></ol><p>volatile可以保证写到缓存中的值可以马上写回主内存,同时使其他cpu的缓存失效,既然每个线程可以实时看到最新的值,那每次取到的i值都是最新的,操作不就没什么问题了吗?<br>这个问题困扰了我很久,也就是我之前说的面试遇到的问题,解决这个问题还是对于计算机组成不熟悉,我们知道缓存是为了解决CPU计算和读取内存之间的速度差异存在的,但是CPU还有寄存器的存在,寄存器存放暂时的指令,数据,位址信息,我们的线程切换保存上下文就有寄存器的信息,这下就清楚了,volatile无法保证原子性就是因为CPU操作的是寄存器中信息,而寄存器无法和内存和缓存同步,这才导致的线程不一致</p><h4 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h4><p>上面说了volatile如何保证可见性,下面说一下有序性的相关.<br>重排序已经不是什么秘密了, 这属于处理器优化,JMM允许处理器会将指令按照适合自己的执行顺序进行排序,如果是单线程的情况下,是没有什么问题的(重排序原则就是不改变单线程下的运行结果),但是在多线程的情况,一切都说不一定了.<br>所以出现了为了实现volatile的禁止重排序,有内存屏障的概念,java编译器会在生成指令的适当位置插入内存屏蔽来禁止特定类型的处理器重排序,有四个屏障指令:   </p><ul><li>StoreStore屏障：禁止上面的普通写和下面的volatile写重排序； </li><li>StoreLoad屏障：防止上面的volatile写与下面可能有的volatile读/写重排序  </li><li>LoadLoad屏障：禁止下面所有的普通读操作和上面的volatile读重排序  </li><li>LoadStore屏障：禁止下面所有的普通写操作和上面的volatile读重排序  </li></ul><blockquote><p>参考<br>《Java 并发编程的艺术》</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入探究 synchronized </title>
      <link href="/2019/08/28/shen-ru-tan-jiu-synchronized/"/>
      <url>/2019/08/28/shen-ru-tan-jiu-synchronized/</url>
      
        <content type="html"><![CDATA[<h2 id="前情"><a href="#前情" class="headerlink" title="前情"></a>前情</h2><p>如何使用这个关键字和类锁对象锁什么的,老生常谈了,就不在这里说了,先声明,这篇博客的内容只能算是我从很多博客中总结出的自己的观点,无法保证全部是自己的话,也无法保证绝对正确性,望以谨慎</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h4 id="存在"><a href="#存在" class="headerlink" title="存在"></a>存在</h4><ul><li>synchronized在一个程序中以字节码中的指令的形式存在,使用javap工具可以看到synchronized关键字在字节码文件中的存在形式,如果是同步代码块,是<code>monitorenter</code>和<code>monitorexit</code>两个指令来划分一段临界区,锁定的是一个对象的monitor,即对象监视器.而同步方法是依靠方法修饰符<code>ACC_SYNCHRONIZED</code>实现</li><li>以上是字节码中的存在,从设计逻辑来看,synchronized用的锁存在与对象头中,所谓Java对象头,就是Java堆中的对象的头部,详情不在这里说了,对象头主要包括两部分,即: 标记字段和类型指针,类型指针是用来指向这个对象的类型,而标记字段就很多了,有这个对象的hashcode,cg年龄,锁状态标记,线程持有锁,偏向所ID,偏向时间戳等,一般的对象头两个机器码,数组类型为3个机器码.</li></ul><h4 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h4><blockquote><p>Monitor Record 是线程私有的数据结构，每一个线程都有一个可用 Monitor Record 列表，同时还有一个全局的可用列表。<br>每一个被锁住的对象都会和一个 Monitor Record 关联（对象头的 MarkWord 中的 LockWord 指向 Monitor 的起始地址），Monitor Record 中有一个 Owner 字段，存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下：<br>Owner<br>EntryQ<br>RcTHis<br>Nest<br>HashCode<br>Candidate<br>Owner : 初始时为Null表示没有任何线程有所该Monitor,当线程拥有该锁后保存线程为唯一标识,当锁被释放时有设置为Null<br>EntryQ: 关联一个系统互斥锁,阻塞所有试图锁住Monitor Record失败的线程<br>RcThis:表示blocked或waiting在该Monitor Record上的所有线程的个数<br>Nest:用来实现重入锁的计数<br>HashCode:从对象头拷贝而来的<br>Candidate:用来避免不必要的阻塞或等待线程唤醒,因为每一次只有一个线程能够成功获得锁,如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程,会引起不必要的上下文切换,,candidate只有两种可能的值:0:表示没有需要唤醒的线程1:表示要唤醒一个继任线程来竞争锁</p></blockquote><h4 id="synchronized优化和锁分类"><a href="#synchronized优化和锁分类" class="headerlink" title="synchronized优化和锁分类"></a>synchronized优化和锁分类</h4><p>synchronized在1.6以后进行了很多优化,使得它和ReentrantLock相比也不落下风.</p><ul><li>锁分类<ul><li>偏向锁,想象一下,如果在一个单线程的情况下使用了synchronized关键字,每一次进入相关临界区时,其实并没有必要加锁,但是由于synchronized关键字的存在,造成了多余的操作和消耗.偏向锁就是解决这个问题的,如果这是一个单线程的情况,在获取锁前会检查对应的对象头部信息,查看偏向状态,如果是可偏向状态,就直接执行代码块内容,如果不是,就去修改这个标记,这个过程是一个CAS,如果成功,也就验证了这是个无竞争状态,如果失败,就代表存在多线程竞争.这时,会执行撤销偏向锁的操作,进入轻量级锁<br>总的来说,偏向锁就是为了没有多线程竞争的情况下,减少加锁的损耗</li><li>轻量级锁<ul><li>轻量级锁的存在意义在于”对于绝大部分的锁,在整个生命周期内是不会有竞争的”</li><li>轻量级锁主要的实现还是CAS和自旋锁(自适应自旋锁),也就是在获取锁失败时,不是马上转入内核态将线程挂起,而是通过一个自旋的过程,如果获取锁的线程马上释放了锁,那么这个自旋的过程就是很有意义的,</li><li>轻量级锁的实现过程就是通过一系列的对上面说到的Minitor Record中字段的CAS修改来实现的</li><li>自旋锁的次数是可以通过JVM参数设置的,’-xx:preBlockSpin`来调整,默认是10次,但是这个并不常用,因为无法用一个统一的次数衡量所有程序,所有又有了自适应的自旋锁,通过一个自适应算法来智能的计算自旋次数,一般是由前一次在同一个锁上的自旋次数及拥有者的状态来决定.</li></ul></li><li>重量级锁<ul><li>这里说的重量级锁主要针对那些没有获得锁的线程,如果超过了轻量级锁的自旋次数,就会换到重量级锁,这是一个硬件级别的操作,也就是将线程由用户态切换到内核态,执行挂起等操作,这是个成本很高的操作</li></ul></li></ul></li></ul><h4 id="锁消除和锁粗化"><a href="#锁消除和锁粗化" class="headerlink" title="锁消除和锁粗化"></a>锁消除和锁粗化</h4><ul><li>锁消除,其实是类似偏向锁的设计思路,不过应该要更高一些,就是如果JVM分析出一个同步操作并不会发生共享数据竞争的情况,就会将锁消除掉,比如我们在单线程情况下使用StringBuffer或者Vector,因为其内部是有锁的,但是我们并不需要,所以就会将这个锁消除掉</li><li>锁粗化, 如果我们的锁粒度没有控制好,导致有一段连续的加锁解锁的代码,这样频繁的加解锁操作并没有带来更好的效率,反而降低了效率,jvm会将这些锁连接起来,编程一个范围更大的锁.</li><li>这一部分的内容其实并没有看上去那么简单,其内部的实现其实和JIT相关,JIT就是Java即时编译,会再开一个博客说说,锁消除和其中的一个逃逸分析相关,想深入了解的可以看我下一篇博客或者自行寻找</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决git clone 速度缓慢的问题</title>
      <link href="/2019/08/28/jie-jue-git-clone-su-du-huan-man-de-wen-ti/"/>
      <url>/2019/08/28/jie-jue-git-clone-su-du-huan-man-de-wen-ti/</url>
      
        <content type="html"><![CDATA[<blockquote><p>从多个博客中总结来的</p></blockquote><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>先说一下效果20k左右 -&gt; 200k左右<br>虽然200也不快,但有总比没有好</p><h2 id="办法"><a href="#办法" class="headerlink" title="办法"></a>办法</h2><h4 id="间接提速"><a href="#间接提速" class="headerlink" title="间接提速"></a>间接提速</h4><p>网上很多办法,先说一下知乎看到的除了间接提速的办法<br>在<code>git clone url</code>后加上<code>--depth=1</code>,原因是,<code>git clone</code>默认会下载该项目所有版本,加上这个命令后只下载最新版本</p><h4 id="直接提速"><a href="#直接提速" class="headerlink" title="直接提速"></a>直接提速</h4><p>其实就是大多数博客中的,但有些有用,有些没有,先说一下我的电脑<br><code>Archlinux manjaro</code><br>有ss(有些博客说没有ss不行,但是我没试过,如果不行可能是这个原因)<br>然后就是在<code>https://www.ipaddress.com/</code>里找到<code>github.com</code>和<code>github.global.ssl.fastly,net</code>的ip,然后以<br>151.101.185.194 global-ssl.fastly.net<br>192.30.253.112 github.com<br>的形式写到/etc/hosts文件中,(上面的ip是我使用的时候查到的,可以先试试,如果不行再到网站上查,那个网站需要梯子)</p><p>然后在命令行使用</p><pre class="line-numbers language-shell"><code class="language-shell">git config --global http.proxy socks5://127.0.0.1:1080git config --global https.proxy socks5://127.0.0.1:1080<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>将这些变量设置到git的全局控制文件中,然后查看~/.gitconfig文件,看有没有这样的几行</p><pre class="line-numbers language-shell"><code class="language-shell">[http]        proxy = socks5://127.0.0.1:1080[https]        proxy = socks5://127.0.0.1:1080<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果有就退出来,如果没有就加上去</p><p>这样就结束了,我其实对于这样做的原理也是一知半解,如果你不行的话,看一下和我的配置有什么区别,实在不行就去用gitee吧,就酱</p>]]></content>
      
      
      <categories>
          
          <category> 开发问题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次Leetcode解题 - 最长斐波那契数列的长度 - dp解法</title>
      <link href="/2019/08/28/ji-yi-ci-leetcode-jie-ti-zui-chang-fei-bo-na-qi-shu-lie-de-chang-du-dp-jie-fa/"/>
      <url>/2019/08/28/ji-yi-ci-leetcode-jie-ti-zui-chang-fei-bo-na-qi-shu-lie-de-chang-du-dp-jie-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p><a href="https://leetcode-cn.com/problems/length-of-longest-fibonacci-subsequence/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/length-of-longest-fibonacci-subsequence/</a></p><h2 id="解题"><a href="#解题" class="headerlink" title="解题"></a>解题</h2><p>两种办法:</p><ul><li><p>暴力破解, 这个没什么好说的,记得优化二分查找的范围</p></li><li><p>动态规划, dp有几种写法,先看代码:</p><pre class="line-numbers language-Java"><code class="language-Java">class Solution {   public static int lenLongestFibSubseq(int[] A) {      int size = A.length;      int[][] dp = new int[size][size] ;      for(int i = 0 ; i < size ; i++){          for(int j = 0 ; j < size ;j++){              dp[i][j] = 2 ;          }      }      int left , right ;      int res = 0 ;      for(int i = 2 ; i < size ;i++){          left = 0 ;          right = i - 1 ;          while(left < right){              int sum = A[left] + A[right] ;              if(sum == A[i]){                  dp[right][i] = dp[right][i] > (dp[left][right]+1)?dp[right][i] : (dp[left][right]+1) ;                  res = res >dp[right][i]?res:dp[right][i] ;                  left++;                  right--;              }else if(sum > A[i] ){                  right -- ;              }else{                  left ++ ;              }          }      }      return res ;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>最重要的是这一段,也就是状态转移方程  </p><pre class="line-numbers language-Java"><code class="language-Java"> if(sum == A[i]){                    dp[right][i] = dp[right][i] > (dp[left][right]+1)?dp[right][i] : (dp[left][right]+1) ;                    res = res >dp[right][i]?res:dp[right][i] ;                    left++;                    right--;                }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这道题的dp,dp[i][j]代表以i和j为序列的最后两个下标的序列的最大长度,举个例子:<br><code>int[] a = {1,2,3,4,5,6,7,8}</code>,那么dp[1][2] 就代表以2和3为序列的最后两位的长度,这个序列就是<code>1,2,3</code>,长度为3;<br>dp[2][4]就是以3,5为最后两位的序列,序列是<code>1,2,3,5</code>,序列长度是4<br>理解了dp[i][j]的意思,这段代码就很容易看懂了.</p>]]></content>
      
      
      <categories>
          
          <category> Leetcode </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客开始了</title>
      <link href="/2019/08/27/blog-start/"/>
      <url>/2019/08/27/blog-start/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=407679465&auto=1&height=66"></iframe></div><h2 id="重新开始写博客了"><a href="#重新开始写博客了" class="headerlink" title="重新开始写博客了"></a>重新开始写博客了</h2><p>大一的时候就弄了一个hexo的博客,后来换了linux,就一直没有把博客迁过来,就用cdns一直写写东西,最近还是决定再次拾起这个博客,希望可以一直写下去,博客内容大部分还是技术相关,也会把这些年在cdns上的,有营养的东西迁过来,也会写写自己的生活</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
